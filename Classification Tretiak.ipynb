{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the dataset\n",
    "df = pd.read_csv('marketing_prep.csv', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Необхідно виконати певні перетворення данних. Необхідно додати новий стовпець до нашого датафрейму. В даному стовпці буде записано вихідне значення порівняння витрат користувачів на вино з сумою значень трат користувача на інші категорії товарів. Оскільки на етапі підготовки даних, виконувалось логарифмування даних, то при порівнянні та сумуванні даних необхідно скористатись зворотною функцією - еспоненціюванням. Якщо трати на вино користувача будуть більшими, ніж трати на інші продукти, то в стовпці споживачів вина буде записуватись 1, в зворотньому випадку - 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['WineCons']=np.where((np.exp(df['MntWines'])-1) > ((np.exp(df['AllSpends'])-1)-(np.exp(df['MntWines'])-1)), 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для класифікації в якості залежної змінної буде використовуватись останній стовпець, який демонструє чи є користувачем переважно споживачем вина чи ні. Тобто задача класифікації полягає в тому, щоб за віком, освітою, статусом особистого життя, доходом, кількістю дітей, місяцем здійснення першої покупки визначити чи буде користувач витрачати більше коштів на вино чи ні."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "X = df.iloc[:, :-8].values\n",
    "y = df.iloc[:, -1].values\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler().fit(X_train)\n",
    "X_train = sc_X.transform(X_train)\n",
    "X_test = sc_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.581826\n",
      "         Iterations 6\n",
      "                         Results: Logit\n",
      "=================================================================\n",
      "Model:              Logit            Pseudo R-squared: 0.150     \n",
      "Dependent Variable: y                AIC:              2092.6100 \n",
      "Date:               2020-10-20 16:37 BIC:              2125.5431 \n",
      "No. Observations:   1788             Log-Likelihood:   -1040.3   \n",
      "Df Model:           5                LL-Null:          -1223.7   \n",
      "Df Residuals:       1782             LLR p-value:      4.1311e-77\n",
      "Converged:          1.0000           Scale:            1.0000    \n",
      "No. Iterations:     6.0000                                       \n",
      "--------------------------------------------------------------------\n",
      "        Coef.     Std.Err.       z       P>|z|      [0.025    0.975]\n",
      "--------------------------------------------------------------------\n",
      "x1      0.3424      0.0563     6.0816    0.0000     0.2321    0.4528\n",
      "x2      0.6574      0.0587    11.1905    0.0000     0.5422    0.7725\n",
      "x3     -0.0111      0.0532    -0.2084    0.8350    -0.1153    0.0931\n",
      "x4      0.5199      0.0631     8.2459    0.0000     0.3964    0.6435\n",
      "x5      0.5775      0.0632     9.1417    0.0000     0.4537    0.7013\n",
      "x6      0.0496      0.0530     0.9360    0.3493    -0.0542    0.1534\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Baseline model\n",
    "import statsmodels.api as sm\n",
    "lr = sm.Logit(y_train, X_train).fit()\n",
    "print(lr.summary2())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Як бачимо з побудованої базової моделі, статистично значимими є 1-ша, 2-га, 4-та, 5-та змінні, так як у них значення p-value менше 1. При побудові моделей в якості класифікаторів буде використовувати виключно ці фактори. Перетворимо наші тренувальну та тестові вибірки таким чином, щоб в них залишились виключно ті дані, які будуть використовуватись при побудові моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features selection\n",
    "X_train = X_train[:,[0,1,3,4]]\n",
    "X_test = X_test[:,[0,1,3,4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Logistic Regression to the Training set (2 variables)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "slr = LogisticRegression(random_state = 13).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7114093959731543"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = slr.predict(X_test)\n",
    "slr.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[200  48]\n",
      " [ 81 118]]\n"
     ]
    }
   ],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дана модель має точність прогнозу 71.14%. Має 10.88% хибно негативних значень та 18.37% хибно негативних значень. Вцілому модель є досить непоганою."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum error:- 0.25279642058165547 at K = 42\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmcAAAGDCAYAAABuj7cYAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAABS90lEQVR4nO3deXxU5dn/8c+VhZCETWWpGyhRay2iVWqD/Po8VtFKq7gU24pLa1WURZFqqXRfrF2oUimIVbQtWupTqQtVaRVrtS1gRUWoO0FBRTatQgIZArl+f9xJCWEymUlm5kwy3/frNa9hzrnPOdecmYmX9zn3dZu7IyIiIiK5oSDqAERERERkFyVnIiIiIjlEyZmIiIhIDlFyJiIiIpJDlJyJiIiI5BAlZyIiIiI5RMmZiEgnZma/MbProo5DRJKn5ExEEjKzN8xsm5lVN3nMyHIMfzOz2oZjbzKze81s3yS3PcHM3sp0jKkws4PMzM2sqOG1mdkvzexlM9u/WdtzGz4Da7a8yMw2mNlp2YxdRDJPyZmIJON0d+/W5DEhXqPGZKPZssJUDpSg/QR37wYcAnQDfp7KfnNVQ9L1K+AE4H/d/e1mTe4DegH/22z5qYADf85wiCKSZUrORKTNzOzLZvZPM5tmZu8B32u4jDbLzB42sxrgU2b2kYber/fN7AUzG9lkH3u0T3RMd38fuB84usk+LjKzl8xsi5mtMrPLGpaXAwuA/Zr0+u1nZgVmdq2ZVZnZu2b2BzPbu4X3+FLT3qmGHqtNZnaMmXU1s7sa9vG+mT1tZv1SOIWFwG+AIcAJ7r4+zvutBf4AXNhs1YXA79x9h5ndY2brzOwDM3vSzD7awnv5spn9o9kyN7NDGv5dYmY/N7M1ZrbezG4xs9IU3o+IpIGSMxFpr08Aq4C+wI8alo1u+Hd34CngT8AjDW2uAH5nZh9uso+m7XdLHpozs32As4GVTRZvAE4DegAXAdPM7Bh3rwFGAGub9PqtBa4EziT0Ru0H/AeY2cIhfw+c2+T1p4FN7v4s8CWgJ3AgsA9wObAtUfzN/A44HDjR3d9N0O63wKjGRMnMegKnA3Ma1i8ADiWc32cb9tsWPwUOIyS+hwD7A99p475EpI2UnIlIMu5v6BlqfFzaZN1ad/+lu+9w98bE5AF3/6e71xP+Q98N+Im7b3f3vwIPsnvC89/2DT1F8Uw3sw+ATUBvQpIHgLs/5O5VHjxBSAQ/meD9XAZ8093fcvcY8D1C8rPHZVlgLjDSzMoaXo9uWAZQR0jKDnH3ne7+jLtvTnDc5k4B/tDQG9gid/8nsB44q2HR54FX3X1Zw/o73H1Lk/dyVEMCl7SGy6uXApPc/T133wJcD3wxlf2ISPspORORZJzp7r2aPG5rsu7NOO2bLtsPeLMhUWu0mtArk2gfzV3p7j2BwcBewAGNK8xshJktMbP3zOx94DOEBK4lA4D7GpNN4CVgJ7DHJUl3X9mw/vSGBG0ku5KzO4G/AHeb2Voz+5mZFSfxXhqdBnzXzL6SRNs57Lq0eQGhNw0zKzSznzRcot0MvNHQJtH7j6cPUAY80+S8/LlhuYhkkZIzEWkvb2XZWuBAM2v696Y/8HYL7RMfzH0FcB0ws2GUYwnwR8IAgX7u3gt4GGgc3Rhv328CI5olnF3j3IzfqPHS5hnAiw0JG+5e5+7fd/cjgOMJyVbze8MSWUS4PHmTmY1upe0c4CQzGwpUsitBHN0Q13DCJdaDGpZb8x0ANYQELDQw+1CTdZsIl2Q/2uSc9GwYhCEiWaTkTEQy7SlCUjDZzIrN7ARCQnJ3O/b5W8L9VSOBLkAJsBHYYWYjCJcLG60H9ml2me8W4EdmNgDAzPqY2RkJjnd3wz7Hsispwsw+ZWZHNoww3Uy4zLkzlTfScBn2bOBWMxuVoN1qwv14vwcedfd1Dau6AzHgXULidX2Cwz0PfNTMjjazroRLoI37rwduI9yv17fh/e1vZp9O5f2ISPspORORZPzJdq9zdl+yG7r7dkISNYLQO3MzcKG7v9zWYBr2OR34dsO9UVcSRjT+h9CTNL9J25cJCc2qhst1+wE3NbR5xMy2AEsIAxtaOt47wGJC79j/NVn1IWAeITF7CXgCuAugYaTjLUm+n0eBLwC/MbPTEzT9LeGS7Jwmy+YQLhO/DbzY8F5aOs6rwA+AhcBr7Dn44uuEgRZLGi6RLgQ+jIhklbknfTVBRERERDJMPWciIiIiOUTJmYiIiEgOUXImIiIikkOUnImIiIjkECVnIiIiIjkk3lQlHVbv3r39oIMOijoMERERkVY988wzm9x9j1k4OlVydtBBB7F06dKowxARERFplZmtjrdclzVFREREcoiSMxEREZEcouRMREREJIcoORMRERHJIUrORERERHKIkjMRERGRHKLkTERERCSHKDnLU1VVMGlcjH49tlFYUE+/HtuYNC5GVVXUkYmIiOQ3JWd5aMECqBxcQ+ns6SzaMoiYd2HRlkGUzp5O5eAaFiyIOkIREZH8Ze4edQxpM2TIENcMAYlVVYXEbP7W4QxlyR7rF1PJyLKFLFleTkVFBAGKiIjkCTN7xt2HNF+unrM8M+OGGJfW3Rw3MQMYyhIuqZvFzGmxLEcmIiIioOQs78y9q56L625J2OaSulnMvXNnliISERGRppSc5ZlN1SUMIO48q//VnzVsqu6apYhERESkKSVneaZ3txirGZCwzRr607tbbZYiEhERkaaUnOWZ0ecXcHvx5QnbzC4ey+gLCrMUkYiIiDSl5CzPTLi6hNuKx7GYyrjrF1PJ7OKxjJ9UkuXIREREBJSc5Z2KCpgzr5yRZQuZUjyVKgZSRxFVDGRK8VRGli1kzjyV0RAREYmKkrM8NGIELFlezuunXcGQkhV0tRjDeqwgNuYKliwvZ8SIqCMUERHJX0VRByDRqKiAfy0r4f0Y7L8/vPVWWdQhiYiICOo5y1uxGKxuqKjx/vuRhiIiIiJNKDnLU6tWQX09HHYY1NTAjh1RRyQiIiKg5CxvvfZaeB7SMKPX5s3RxSIiIiK7KDnLU6++Gp4//nEwgw8+iDYeERERCZSc5anzzoMFC2DChHBJ8+CDo45IREREQKM189a++4aHiIiI5Bb1nOWpW2+F55+HtWthzBh4+umoIxIRERFQcpaXamrgssvgwQdh2za47TZ48cWooxIRERFQcpaXVq4Mz4cdBr16hX+r1pmIiEhuUHKWhxpHah56KPToEf6t0ZoiIiK5QclZHmqscXbIIVBcDGVlSs5ERERyhZKzPPTqq7DfftCtW3i9337gHm1MIiIiEqiURh66+WZYt27X68aeNBEREYmees7yUFkZDBwYdRQiIiISj5KzPPPBB3DNNaHGWaOf/xyuvjq6mERERGQXJWd55pVX4IYb4I03di1bujTUPBMREZHoKTnLM433lx122K5lvXqpzpmIiEiuUHKWZ159FQoKdr/nrGdPldIQERHJFUrO8sxrr8GAAVBSsmtZz54Qi0FtbXRxiYiISKDkLM9s2BBmBmhq331DT9rWrdHEJCIiIruYd6Lqo0OGDPGlS5dGHUbOi8V27zkTERGR7DOzZ9x9SPPl6jnLQ0rMREREcpeSszzy3HPwxS/CypW7L3/5ZRg+HJ56Kpq4REREZBclZ3nkuefg//4PzHZfXlcHjz0Gb74ZTVwiIiKyi5KzPPLaa1BcHEZrNtWrV3hWrTMREZHoKTnLI6++GkZlFjWb7r5nz/CsWmciIiLRU3KWR157bfeZARp16xYudSo5ExERiZ6SszzSvTscddSeywsK4BOfgL32yn5MIiIisrui1ptIZ/HPf7a8bvHi7MUhIiIiLVPPWZpVVcGkcTH69dhGYUE9/XpsY9K4GFVVUUcmIiIiHYGSszRasAAqB9dQOns6i7YMIuZdWLRlEKWzp1M5uIYFC6KL7c47YdiwlkdkTpgAF12U1ZBEREQkDl3WTJOqKrhwVA3ztw5nKEv+u7yCVVxfN5nT6+5l5KiFLFleTkVF9uN77rnw6NEj/vo1a1TnTEREJBeo5yxNZtwQ49K6m3dLzJoayhIuqZvFzGmxLEcWvPZamPC8oIVPvFcv1TkTERHJBUrO0mTuXfVcXHdLwjaX1M1i7p07sxTR7l59NSRnLenZU6U0REREcoGSszTZVF3CAFYnbNOfNWyq7pqliHbZsQNWrYpf46xRY3Lmnr24REREZE9KztKkd7cYqxmQsM0a+tO7W22WItpl82YYMQKOO67lNocfDieeCLForrqKiIhIAyVnaTL6/AJuL748YZvZxWMZfUFhliLaZe+9Yf58OPPMltucfz48+ih0zX7HnoiIiDSh5CxNJlxdwm3F41hMZdz1i6lkdvFYxk8qyXJkulQpIiLSkSg5S5OKCpgzr5yRZQv5mk2lioHUUUQVA5lSPJWRZQuZMy+aMhoTJ8LgwYnbLFoUJkX/17+yE5OIiIjEp+QsjUaMgCXLy/m/vldwdOEKSgtiDOuxgtiYK1iyvJwRI6KJ6+WXoaSVDruCAnj9ddi0KTsxiYiISHwqQptmFRVQXF5C9Xo48khYvrws6pB47TU4/vjEbXr1Cs+qdSYiIhIt9ZxlwIYN4XndumjjAKithdWrE9c4g1BKA1TrTEREJGpKztJs+3bYd1/o3h3efRfq66ONZ9WqMCAgUY0zUHImIiKSK5ScpVmXLqEa/3XXhcTsvfeijaekBMaOhWOOSdyutBTOOAMOPjg7cYmIiEh8uucsQ/r0Cc8bNkDv3tHFUVEBN9/cejszuP/+jIcjIiIirVDPWZo98USotF9WBhMmQHl5tPFs2hSmbxIREZGOIaPJmZmdamavmNlKM7s2zvozzGy5mS0zs6Vm9v8alh9oZo+b2Utm9oKZTcxknOm0ciU8/jh87GPwy1/CgMQzOmXc5z4XksVknHpqaC8iIiLRyVhyZmaFwExgBHAEcK6ZHdGs2WPAUe5+NPAVYHbD8h3A1e7+EaASGB9n25y0fn147ts3DA7YujXaeF57jaQL39bV5cYIUxERkXyWyZ6z44CV7r7K3bcDdwNnNG3g7tXu/51cqBzwhuXvuPuzDf/eArwE7J/BWNNm/Xro0QMKC8PN+FOnRhfLli3wzjutj9Rs1KuX6pyJiIhELZPJ2f7Am01ev0WcBMvMzjKzl4GHCL1nzdcfBHwMeCreQcxsTMMl0aUbN25MR9ztsmFD6DUrLg7JTpQV91euDM+t1Thr1LOnSmmIiIhELZPJmcVZtscU3O5+n7sfDpwJ/HC3HZh1A/4IXOXum+MdxN1vdfch7j6kT+MQyQjttx9UNsx93qcPRJkvvvpqeE6250zJmYiISPQyWUrjLeDAJq8PANa21NjdnzSzCjPr7e6bzKyYkJj9zt3vzWCcaXXDDbv+3bdvtMnZ4MFw/fVwyCHJtR82LNwj5x5Ka4iIiEj2ZTI5exo41MwOBt4GvgiMbtrAzA4BqtzdzewYoAvwrpkZcDvwkrvfmMEYM6pPH6iqiu74H/lIeCRr1KjwEBERkehk7LKmu+8AJgB/IdzQ/wd3f8HMLjezyxuafQ74t5ktI4zs/ELDAIFhwAXAiQ1lNpaZ2WcyFWu67NgRkqHbbw+vR4+Gyy5r/36rqmDSuBj9emyjsKCefj22MWlcrNXE79lnd83zmaz6+uinnBIREclnGa1z5u4Pu/th7l7h7j9qWHaLu9/S8O+fuvtH3f1odx/q7v9oWP4Pdzd3H9yw7mh3fziTsabDpk3w8ssQi4XX55wD48e3b58LFkDl4BpKZ09n0ZZBxLwLi7YMonT2dCoH17BgQcvbnnIKfOc7yR/rT3+CoiJYvrx9MYuIiEjbafqmNGrsperbNzzHYqGUxf77h9GbqaqqggtH1TB/63CGsuS/yytYxfV1kzm97l5GjlrIkuXle9Qye/fd8Eh2pCaE2QzcNShAREQkSpq+KY0aC9D26xee580LE4mvWtW2/c24IcaldTfvlpg1NZQlXFI3i5nTYnuse+218JzsSE0IpT9Atc5ERESipOQsjZr3nDVW9mjriM25d9Vzcd0tCdtcUjeLuXfu3GN5Y3KWSs9Zz57hWT1nIiIi0VFylkZ77w0nnwwf+lB43d7kbFN1CQNYnbBNf9awqbrrHstffRUKCmDgwOSPp+RMREQkerrnLI1GjAiPRu1Nznp3i7F6ywAqaPm66Br607tbLVC22/ILLgiTr3fpkvzxevaEK6+EI49sW7wiIiLSfuo5y6D2Jmejzy/g9uLLE7a5xcbyuXMK91h+2GFw9tmpHa+4GG66CU44IbXtREREJH2UnKXROefA6afvel1SEpKdU05p2/4mXF3CbcXjWExl3PWLqeRmH8v8v5TwzDPN6qFZPX26J1cPranaWtgcd6IsERERyQYlZ2n0+uuhEG1TV14JH/942/ZXUQFz5pUzsmwhU4qnUsVA6iiiioFMKZ7KyLKF/PCGciDM53ncoCb10OjCkurk6qE1dcwxcPHFbYtXRERE2k/JWRpt2LCrjEajNWvghRfavs8RI2DJ8nJiY65gWI8VlBbEGNZjBbExV7BkeTlf/Srcey+UWw0P1g7n+rrJVLCKInb+tx7a/K3DuXBUTVI9aJr8XEREJFpKztLEPX5yNn48nHde+/ZdUQGvvF7Cly4vY8fOAtZ9UMaNM0r+W3h27q9jjKNt9dCa69VLdc5ERESipOQsTTZvDjMCNNY4a9SnT9sHBDT1r3+1fC9Ye+qhNaeeMxERkWgpOUuTHTvgoovCPVtN9e0bkjP3tu97+/Ywb+d++8Vf3556aM0pORMREYmW6pylyT77wB137Lm8Tx+oqwu9Xo1FXlO1bl143nff+OvbUw+tuTPPTG3KJxEREUkv9Zylyc6d8XvH2lvrDGDt2vDcUs9ZMvXQZhePZfQFe9ZDa27ECLj66lQjFBERkXRRcpYmt94KXbvuml+z0f/+L9x9964krS26dIHPfKblqZiSqYc2u3gs4yeVtHqsbdtCSZC6urbHKyIiIm2n5CxN1q8P94btvffuywcMgC98oe2XNCHcx/bQQ3D44fHXJ1MPbc688v+O7kzk3ntDEvj6622PV0RERNpOyVmabNgQ7jsranYXX10d/PWvsKrl28HSorV6aE3n/ExEk5+LiIhES8lZmqxfv2eNMwjJ2UknwR/+0PZ9jxkDQ4e23q6iAm6cUcK6D+LXQ0tGr17hWbXOREREoqHkLE3Wr9+zxhlAWVl4NL8XLRVvvNG+UhypUM+ZiIhItFRKI00+/3koLY2/rr2FaNeuzV55CyVnIiIi0VJyliZXXtnyunQkZyec0PbtU9GnD/ziF/CJT2TneCIiIrI7JWdpUF8P774bBgQUxLlQ3LfvrkKyqdq2Df7zH9h///bFmKzSUpg4MTvHEhERkT3pnrM0ePvtkIDdfnv89T/4AfzqV23bdywWBgQcd1zb40vVK6+E+9xEREQk+9Rzlgbr14fneKM1AY49tu377tWr7YldW51ySriM+tvfZve4IiIiop6ztGgciRlvtCaEgq533QW1tanve/v2MDVUNmnycxERkegoOUuD1nrO/vY3uOACeOed1Pc9cyaUlGS37livXqpzJiIiEhUlZ2nQWs9ZeyY/f+edMOtAe6Z/SpV6zkRERKKj5CwN/ud/4LrroLw8/vr2JGdr18J++4FZ2+NLlZIzERGR6GhAQBoMHZp4eqV0JGfZNHYsjBqV3WOKiIhIoOQsDaqqoHv31i9rtmUKp7VrYfDgtsfWFsOGZfd4IiIisouSszQ46yw4+GB44IH467t1g6eegoEDU9/3JZdA//7tiy9V69bBiy/CJz8JxcXZPbaIiEi+U3KWBhs2QGVly+vN2l5E9ppr2rZde8yfD5ddBm+9lb2ZCURERCTQgIB2qq8P95K1dEmz0fz5cM89qe27tjZc1oyizhloUICIiEgUlJy107vvhgStpRpnjW6+GaZOTW3fS5aEnqsnnmh7fG3Rq1d4Vq0zERGR7FNy1k6NN/m3lpz16ZP6aM21a8NztkdrqudMREQkOkrO2qlfvzDh+Sc+kbidkjMRERFJhgYEtFPv3vCVr7Terk8fqKmBbdugtDS5fa9dGwrbdu/evhhT1b9/GHk6ZEh2jysiIiLqOWu311+Hf/0r3HeWSFsK0b7zDuy7b3ZnB4CQEI4cmf0eOxEREVFy1m6zZ8Pxx7fe7vOfT700xYUXwne+0/bY2mPBAli2LJpji4iI5DNd1myn9etDGY2CVtLcHj3CIxUjRrQ9rva68EI455wwylRERESyRz1n7bRhQ+s1zgC2bIEf/jBcAk2Ge2j73nvti6+tNPm5iIhINJSctdP69a2X0YBwT9p3vgN//3ty+928OYwA/fWv2xdfW/XqpTpnIiIiUVBy1k4bNiSXnPXoEeapTHZAQFRlNBqp50xERCQauuesnWbP3lVRPxGz1Gqd5UJy9tpr0RxbREQknyk5a6eTTkq+bSrJ2dtvh+eoJh6/7jqoq4vm2CIiIvlMyVk7vP8+PP44DBuW3KCAPn1g06bk9t3Yc7bvvm0Or12OOCKa44qIiOQ73XPWDi+9BGefDc8+m1z7++5LfkDAmWfCXXeFgrBRePHFcMl2585oji8iIpKvlJy1w/r14TmZXjOAbt2gsDC5tocfDued17a40uGRR+DSS8OoUREREckeJWft0JicJTNaE+CJJ+DyyyEWa73t3/4Weq+iosnPRUREoqHkrB02bAjPjfNmtubll+FXv0puUMCXvww//nGbQ2u3xhGoqnUmIiKSXUrO2mH9ethrL+jSJbn2jZc/W0vO3MOk51FOPK6eMxERkWgoOWuHyZPhoYeSb9/Yw9Zacvbee7B9u5IzERGRfKRSGu3Qv394JCvZ5CzqArQQSmmsWAEHHRRdDCIiIvlIPWftcNddsGhR8u379AlTONXUJG6XC8lZaSkMGhRGmIqIiEj2KDlrh4kTYe7c5NvvtVcYqTlmTOJ2xx0Hjz0GRx7Zvvjawx2mT0++LhtAVRVMGhejX49tFBbU06/HNiaNi1FVlbk4RUREOhslZ21UVxfuDUu2xhmE+TXNWm+3115w4olhsvSomMG118IDDyTXfsECqBxcQ+ns6SzaMoiYd2HRlkGUzp5O5eAaFizIbLwiIiKdhe45a6PGMhrJ1jhr9N3vhtGd3/xmy20efxyqq+H009seXzr07JncgICqKrhwVA3ztw5nKEv+u7yCVVxfN5nT6+5l5KiFLFleTkVFBgMWERHpBNRz1kaNyVkqPWcQLhM+/HDiNtOnwze+0ba40qlXr+TqnM24IcaldTfvlpg1NZQlXFI3i5nTkqi+KyIikueUnLVRqlM3NerTJ7nRmlEOBmiUbM/Z3LvqubjuloRtLqmbxdw7NVGniIhIa3RZs41OOCFU/D/wwNS2SzY5O+KINoeWNj17Jtdztqm6hAGsTtimP2vYVN01PYGJiIh0YkrO2qhrV/jwh1Pfrm/fkPDU1YWyGs3V10c/O0CjOXPix9hc724xVm8ZQAWrWmyzhv707lYLlKUvQBERkU5IlzXb6OGHYebM1Lc74IBQ2HXz5vjrN26EnTtzIznr1w/23rv1dqPPL+D24ssTtpldPJbRFxSmKTIREZHOK6PJmZmdamavmNlKM7s2zvozzGy5mS0zs6Vm9v+S3TZqd98NP/tZ6tt95Svw+uuwzz7x1++zD7zyCnzhC+2LLx3+9jf49rdbbzfh6hJuKx7HYirjrl9MJbOLxzJ+Ukl6AxQREemEWk3OLDjfzL7T8Lq/mR2XxHaFwExgBHAEcK6ZNb+T6jHgKHc/GvgKMDuFbSO1YUPqZTSSUVQEhx0GvXunf9+p+uc/4brrQuHcRCoqYM68ckaWLeQaplLFQOooooqBXFs8lZFlC5kzT2U0REREkpFMz9nNwFDg3IbXWwiJU2uOA1a6+yp33w7cDZzRtIG7V7u7N7wsBzzZbaO2fn3qIzUh3Oz/6U/DX/4Sf/1TT8G0abBtW/viS4dUJj8fMQKWLC/nicFX8PGSFZRajCNZwerTr2DJ8nJGjMhsrCIiIp1FMsnZJ9x9PFAL4O7/Aboksd3+wJtNXr/VsGw3ZnaWmb0MPEToPUt62yi1teesuBgeeQRefTX++j//Gb761dCDFrVevcJzMiM2IfSgPf18Ce/VlrFhUwF77VfGOeeVqMdMREQkBcmkAHUNlxkdwMz6APVJbBdvoiLfY4H7fcB9ZvY/wA+B4clu2xDPGGAMQP/+/ZMIq/3cQ3LWlp6zvfcOUyO1VE5j7dqw32RGSWZaKj1nEHr7SkqgoCC8z7feSm66KhEREdklmZ6z6cB9QF8z+xHwD+DHSWz3FtC0CtgBwNqWGrv7k0CFmfVOZVt3v9Xdh7j7kD59+iQRVvuZhd6kKVNS37awMNz0nyg5y4WRmpB6cnb99eFeubq68NosJLIeN60WERGReFpNztz9d8BkQkL2DnCmu/8hiX0/DRxqZgebWRfgi8D8pg3M7BCz0LdiZscQLpe+m8y2USsvb/vE5H367Jr+qblcSs6OPx5qauCkk5Jr/9xzsP/+u3r9XnoJDj645fvrREREZE/JjNa8091fdveZ7j7D3V8ysztb287ddwATgL8ALwF/cPcXzOxyM2ssivU54N9mtowwyOALHsTdtk3vMANeegmuvhpWJy6K36Jjj4V9942/LpeSs6IiKCtL/tLksmVw9NG7Xg8YEArqLlyYiehEREQ6p2TuOfto0xcN958dm8zO3f1h4OFmy25p8u+fAj9NdttcsWIF3HgjfPnLbdv+zgSpbVVV66UrsmX7dvj61+HUU8MI00Q2boS33949OSsrg2HD4LHHMhqmiIhIp9Jiz5mZTTGzLcBgM9tsZlsaXm8AHshahDmo8ZJkJuqclZXBXnulf79tUVQEN90Eixa13vb558Pzxz62+/KTTgo9aq3NJyoiIiJBi8mZu//Y3bsDU929h7t3b3js4+5tuBW+81i/PoxIbKnKf2t+/Ws48sgwTVNTK1eGy6VVVe2PMR0KCqB79+QGBBx4IHzrW3smZ8OHh+fHH09/fCIiIp1RMgMCppjZXmZ2nJn9T+MjG8Hlqg0bwqjEwjZOFVlTA//+N7z77u7LX3ghXC5Ntq5YNvTqlVw8H/4w/PCHe/b6HXssjBsXBgaIiIhI61q958zMLgEmEspZLAMqgcXAiRmNLIdt2dK+S5qNFT82bty9Vto774TnlgYLRKFnz+R6zp5+OiRozUewFhW1bYJ4ERGRfJVMnbOJwMeB1e7+KeBjQF7fQTR3Ljz7bNu3b5qcNbV2bbiU2JbitpnSq1cYGJDItm1QWQk//3n89fX14Z605j2FIiIisqdkkrNad68FMLMSd38Z+HBmw8p97ZleKVFy1q9fbkzd1OiJJ+ChhxK3WbEiJGBNR2o29corYd1996U7OhERkc4nmeTsLTPrBdwPPGpmD5Cg0n8++NKX2pdofOhD8KlP7XkJcPPm3Klx1iiZGmfLloXnlpKzww8P70v1zkRERFqXzICAs9z9fXf/HvBt4HbgjEwHlqu2boU5c0JvUFv16QN//euetcP+8AdYsqR98aXb3XfDJZckbrNsWUg0Dzoo/nqzUFLjr38NPWwdSVUVTBoXo1+PbRQW1NOvxzYmjYvlzIhaERHpfJLpOfsvd38CqCVHi8NmQyZrnEFuXdKEcMnyN79JPD9m48wABQm+TSedFC7jrliR5gAzaMECqBxcQ+ns6SzaMoiYd2HRlkGUzp5O5eAaFiyIOkIREemMEhWhPdHMXjWzajO7y8yOMLOlhDk2Z2UvxNzSmJy196b9ESPg4ot3vY7F4POfz715KHv2DPXYtm5tuc0vfgHXXZd4P43zc3aU2QKqquDCUTXM3zqc6+smU8EqithJBau4vm4y87cO58JRNepBExGRtEvUc3YDMAbYB5gHLAHudPdj3f3ebASXi9avD8/tTc6qq2HVql2v162De+6BN99s337TrVev8Jyo1tlxx8EnP5l4PwccAI8+2vol0lwx44YYl9bdzFDiX2ceyhIuqZvFzGk5MteWiIh0GomSM3f3v7l7zN3vBza6+01Ziitnbd8eCtC297Jmnz67j9Zc2zDEItcGBPTsGZ5bqnX2/PPhXrlk5gMdPnzPQRC5au5d9Vxcd0vCNpfUzWLunTsTthEREUlVouSsl5md3fgArNnrvPS5z4Wkqn//9u2noyRn++wTEtGWkq+774bzz09uVOe774ZZBBpHd+ayTdUlDGB1wjb9WcOm6q5ZikhERPJFotvPnwBOb+G1A3l7aTMd+vQJyUp9fbiRPleTs+HDwyXXljz3HBxxBHTp0vq+Cgvhe9+DHTtaLruRK3p3i7F6ywAqWNVimzX0p3e3WqAse4GJiEin12Jy5u4XZTOQjuL734dNm+CXv2zffj7+cTj33NAjVVoakrR99w2XTDuSZcvg1FOTa9urFwwZEgYFfP/7mYyq/UafX8Dtsy/n+rrJLbaZXTyW0Re0cYJVERGRFqRUSkNCxfznnmv/fs44A+68MyRmABMn7pq+KZd88EGIdf78PdetWxcGSKTSC3bSSaGW2+bNaQsxIyZcXcJtxeNYTGXc9YupZHbxWMZPKslyZCIi0tnlWCqQ+zZsSO/cl4nqh+WC4uKQmL300p7rnn8+PH/sY8nvb/jwUJrjySfTE1+mVFTAD35ezkksZHLBVKoYSB1FVDGQKcVTGVm2kDnzyqmoiDpSERHpbBImZ2ZWYGbHZyuYjmD9+vQUoH3xRSgvh3sb7tw7/3yYOrX9+0230tJQGDfeaM1TToHXX4dPfCL5/R1/POy1F6xZk74YM+WZZ6C+pJzqi65gWI8VlBbEGNZjBZsvvIIly8sZMSLqCEVEpDNKWI/e3evN7AZgaJbiyWk7doSb+NPRc9arVyjs2jhi8+GHd9UUyyVmIa54dc7MWp6yqSVdu4bex1ybCaG5DRvgrrvgoovg5lkl3Dw7LP/858tYugL1mImISMYkc1nzETP7nFkyxRI6t+pqOOqo9PyHufHG/40bYds2+M9/cm+kZqOePeP3nH396/Dgg6nvL9cTM4Bf/zoM1rjyyt2XH3MM/OtfsDpxlQ0REZE2SyY5+ypwD7DdzDab2RYzy/HbuTOjV68wGODCC9u/ry5dQtKzcSO8805YlqvJ2RFHwN57776spiZchn322dT39847YbTq//1feuLLhEmT4JFH4CMf2X35qFHh+Y9/zH5MIiKSH1pNzty9u7sXuHuxu/doeN1B6rzntsZCtLla46zR/Pl7lg5ZvjwMZmhLvbK+fWHlypD85KouXeDkk/dcfsgh4T3Pm5f1kEREJE8kNVrTzEaa2c8bHqdlOqhc9cAD4eb3xmSqvS66KIxedA8jHts760A2NVb5b0tyVlgIJ54ICxfm3mhVdzjzzFDmpCWjRsHixbk3D6qIiHQOrSZnZvYTYCLwYsNjYsOyvFFVBZPGxfjyF7bx9L/qOfrwbUwaF6Oqqn37/cY34OKLw6Thzz4Lhx+ennjT7ec/h5Ejd1+2bFkYdXngganvr6oKNm+MsWHNNooK6+nXo+Xz2Xju+/XYRmFB4rbp8OSTIQlPNFfo+efD3LlhaisREZF0S6bn7DPAye5+h7vfAZzasCwvLFgAlYNrKJ09naWxQWynC4u3DKJ09nQqB9ewYEHb9+2e+8VYAd56C/72t92Xvf8+HHtscnNqNtV4Pocsns6/GUTMu7CohfPZ9Nwv2pK4bbpMmxaSrvPOa7nNgAFhdocyzdokIiKZ4O4JH8ByYO8mr/cGlre2XRSPY4891tNp5Ur33mXVvohK95BL7fZYRKX3Lqv2lSvbtv8pU9yLitwnTnQ/++y0hp5W3/lOeMs7duy+vPnr1qRyPjN97luKz8z9m99sve369e4//an72rXpO76IiOQXYKnHyWeS6Tm7HnjOzH5jZr8FnmlY1unNuCHGpXU3M5QlcdcPZQmX1M1i5rQE18AS6N071E574olQ3DZXNdZfa97LV5jitJLJnM+L62Yx48YYv8zwuY9n+vRQ5mPcuNbbvvtuKCWiUZsiIpJurc4QANQDlcC9DY+h7n53FmKL3Ny76rm47paEbS6pm8XcO3e2af99+oTn55/P3ZGaEEp+wK5aZw88AJ/+dCjUmopkzueldbP41c07+d2czJ77eE47Da6/PrnP4iMfCSVGNGpTRETSLWFy5u71wAR3f8fd57v7A+6+LkuxRW5TdQkDSFxttD9r2FTdtU37b5xpwD23k7MDD4TKSqivD6//+c/Q27fXXqntJ9nzGbOuvLc1s+c+npNPhmuuSb79OeeEAQTr8uYXISIi2ZDMZc1HzewaMzvQzPZufGQ8shzQu1uM1QxI2GYN/endrbZN+2/sOYPcTs5OPjmUjhg4MLx+7jkYNChMip6KZM9nn+61GT/3Te3cCT/6Ebz9dmrbjRoVEuv77mt3CCIiIv+VTHL2FWA88CThfrNngKWZDCpXjD6/gNuLL0/YZnbxWEZfkOLNVw0GDIDLLoODD4Yjj2zTLrLOPZTRaEt9s1TOZ6bPfVP33w/f+laYlikVH/1oSFLfeKPdIYiIiOwSb5RA44OQvH0hUZtcenSk0ZorV7pfNbbW+3bf6gW20/t23+pXja1N6+jDdHnzTfcjj3S/9173t94Kb3/GjNT3kyujNZuf+26FW71391p/5ZXU97V9e+rbiIiIuLdxtKaHe87GZyFHzEkVFTBnXjkjyxYypXgqVQykjiKqGMiU4qmMLFvInHnlKU+EHkX9rvYoKYEVK8Jlv82b4VOfCnNjpiqV85mo7bVF6T33y3YO4is10xn2sdTPfeOl3R07UttORESkRfEytqYP4NvANcCBhBpne9Ok7lkuPdLdc9Zo5Ur3SeNrvV+PGi8s2On9etT4pPFt6+WKon5Xe8ViIbzrrkvP/lI5n83bdius8YP3z61zf9FF7qeemno8IiKS32ih58zCupaZ2evxczofmN40sf2GDBniS5fm9u1wk8bFKJ09nevrJrfYZkrxVGJjruDGGSVZjCyx0lK44gr48Y9Tr2+WTt/6VojhnXd2jXZNVqbO/Te/CT/9aRi12bt3ajGJiEj+MrNn3H1I8+WtDghw94PjPHIuMesoMl07LVN69QpTNg0aBFdfHV0c55wTSnrcf3/q22bq3I8aFUZ8PvBA6jGJiIg012JyZmaTm/z7nGbr8mKGgEzIdO20TPn0p+FDH4KXX452wu/Bg+GQQ9pW/DVT5/7oo0OZkXvuST0mERGR5hL1nH2xyb+nNFt3agZiyQvZrN+VTr/5Tah3Bm0ro5EuZqH37K9/hU2bUts2U+feLPSePfYYvPdeajGJiIg0lyg5sxb+He+1JCmb9bvSbdmy8BxlcgYwZkyYoWDvFEshZ/LcX3ghTJ0a7f14IiLSOSRKzryFf8d7LUmacHUJtxWPYzGVcdcvppLZxWMZPyk3BgNUVYUb6Xt22cbEK+sps2387LoYVVXRxXTQQTBsGBQkU0K5iUye+65dYfWrMQ47cBuFBfX067GNSeOiPU8iItIxJfrP21FmttnMtgCDG/7d+LqD1LPPPZmqnZYJTWuCPVs3iO10YbkPoiwH6rGtXAlXXpnaZcTGc39KwUKuIf1167p2kLp1IiKS21otpdGRdIRSGo2qqmDmtBhz79zJpuqu9O5Wy+gLChk/qSQnErOqqpBwzN86nKEs2WP9YioZWbaQJcujSSSXLg2FcH/9a/jyl5PfbuPGMG3WkMExXn2p/ec+18+TiIjkrpZKaSg5k7hyvR6bexghecQR8NBDqW37n/+Ee8N69Gh/HLl+nkREJHcpOZOU9OuxjUVbBlHBqhbbVDGQYT1WsO6DsixGtsvXvgY33QQbNoQ6bK2pq4OiojC6Ml06wnkSEZHc1OYitJKfOkI9tlGjQsL1pz8l137q1HApdOvW9MXQEc6TiIh0LErOJK6OUI/tuONCWY8PPmi97fbtMGNGKKBblsYOrI5wnkREpGNRciZxdYR6bGbw7LMwYULrbe+5J8zHedVV6Y2hI5wnERHpWHTPmcTVkUYhusOWLS3f4O8eLmfW1MALL6ReHy2RjnSeREQkt+ieM0lJR6rH9qlPhQr9LfnnP+GZZ2DixPQmZtCxzpOIiHQMSs6kRSNGwJLl5cTGXMGwHisoLYgxrMcKYmOuYMnyckaMiDrC4Kij4M9/Dr1n8Rx7LNx+e+IErj2an6euxBhsuXeeRESkY9BlTenw/vEP+OQn4fe/hy9+Mepo4IYb4Jpr4N13U5//U0RE8ocua0qndfzxsO++4ab/5qZOhZkzsxvPoYeG59dey+5xRUSkc1ByJh1eQQGcfTY8/DBUV+9avnkz/PCHsGhRduM57LDwrORMRETaoijqAETS4fLL4YQToLh417Jf/zrch5bu8hmtGTgQystTm5RdRESkkZIz6RQGDQqPRjt3hqmdhg0LZTSyqUuX0GuX7pGhIiKSH/SfD+k0/vEP+J/KGP16bKNLcT3vvL6NvctjVFVlPxYlZiIi0lb6T4h0CgsWwMiTazjuqeks2jKImHfh3wzio49Pp3JwDQsWZDeeu++GU08NBXBFRERSoeRMOryqKrhwVA0P1Q7n50ymglUUsZMKVvHjusnM3zqcC0fVZLUHbeNG+MtfYP367B1TREQ6ByVn0uHNuCHGpXU3x50+CWAoS7ikbhYzp8WyFpNGbIqISFspOZMOb+5d9Vxcd0vCNpfUzWLunTuzFNGuWmevvpq1Q4qISCeh5Ew6vE3VJQxgdcI2/VnDpuquWYoIBgwIZT3UcyYiIqlSciYdXu9uMVYzIGGbNfSnd7faLEUEhYVw4omh3pmIiEgqlJxJhzf6/AJuL748YZvZxWMZfUFhliIK/vxn+Pa3s3pIERHpBDKanJnZqWb2ipmtNLNr46w/z8yWNzwWmdlRTdZNMrMXzOzfZvZ7M8veNSnpUCZcXcJtxeNYTGXc9YupZHbxWMZPKslyZCIiIqnLWHJmZoXATGAEcARwrpkd0azZ68D/uvtg4IfArQ3b7g9cCQxx90FAIfDFTMUqHVtFBcyZV87IsoVMKZ5KFQOpo4gqBjKleCojyxYyZ145FRXZjevhh0Nsa9Zk97giItKxZbLn7DhgpbuvcvftwN3AGU0buPsid/9Pw8slwAFNVhcBpWZWBJQBazMYq3RwI0bAkuXlxMZcwbAeKygtiDGsxwpiY65gyfJyRozIfkylpbBqlUZsiohIajKZnO0PvNnk9VsNy1pyMbAAwN3fBn4OrAHeAT5w90cyFKd0EhUVcOOMEtZ9UMaOnQWs+6CMG2eUZL3HrJFqnYmISFtkMjmzOMviTmZjZp8iJGdfb3i9F6GX7WBgP6DczM5vYdsxZrbUzJZu3LgxLYGLpMN++0FZmXrOREQkNZlMzt4CDmzy+gDiXJo0s8HAbOAMd3+3YfFw4HV33+judcC9wPHxDuLut7r7EHcf0qdPn7S+AZH2MAvFaNVzJiIiqSjK4L6fBg41s4OBtwk39I9u2sDM+hMSrwvcvWn/whqg0szKgG3AScDSDMYqkhFnnQU7szcxgYiIdAIZS87cfYeZTQD+QhhteYe7v2BmlzesvwX4DrAPcLOZAexo6AV7yszmAc8CO4DnaBjJKdKRfPe7UUcgIiIdjbnHvQ2sQxoyZIgvXaoONskt9fXhUZTJfmoRSaiqCmbcEGPuXfVsqi6hd7cYo88vYMLV0Q0aEjGzZ9x9SPPlmiFAJIOWLQuDAh7RWGORyCxYAJWDayidPZ1FWwYR8y4s2jKI0tnTqRxcw4IFUUcosjslZyIZdMABEItpxKZIVKqq4MJRNczfOpzr6yZTwSqK2EkFq7i+bjLztw7nwlE1VFVFHanILkrORDJon32gVy+N2BSJyowbYlxadzNDWRJ3/VCWcEndLGZOi2U5MpGWKTkTySCzUIxWPWci0Zh7Vz0X192SsM0ldbOYe6eGVUvuUHImkmGqdSYSnU3VJQxgdcI2/VnDpuquWYpIpHUaPyaSYaNGweGHg3voSROR7OndLcbqLQOoYFWLbdbQn97dagnTOItETz1nIhl25pnwrW8pMROJwjlfKOAWLk/YZnbxWEZfUJiliERap+RMJMPcYcMGeO+91LarqoJJ42L067GNwoJ6+vXYxqRxMY0qk04v2e9+onYPPQQ1NTDp2hJ+UzaOxVTGPdZiKpldPJbxk0qy8M5EkqPkTCTDtmyBfv3gttuS30Z1mSRfJfvdb6ld19nTOebwGk47DW68ESoqYM68ckaWLWRK8VSqGEgdRVQxkK/ZVEaWLWTOvHIVopWcohkCRLLgQx+Cz34Wbr+99bZVVeE/OvO3Do87/H8xlYwsW8iS5foPinQuyX73/+9P5Xzh9MTtTi0Kv5GPfGTXvmdOizH3zp1squ5K9+JaamKFPPxoCcOHZ/qdicSnGQJEInTYYcmP2FRdJslXyX73r524tdV242wWt83c9RupqIAbZ5Sw7oMyduws4OXVZViXEu6/PxPvRKR91HMmkgUXXxzugVm3rvW2/XpsY9GWQQlHl1UxkGE9VrDuA40uk84j2e/+kaxgBUe2+zdy0UXw2GOhV624uF2hi7SJes5EInTYYbB+PWze3Hpb1WWSfJXsd7+Wrmn5jfzkJ/DSS0rMJPcoORPJgs9+Fu64AwqS+MX17hZjNQMSttlVl0mk80j2u19KbVp+I/36QXk51NfDTk0QIDlEyZlIFgwaFC6hdOvWetvR5xdwe7HqMkn+Sfa7/9FBpO03smYNfOQj8Mc/phSqSEYpORPJkueegxdeaL3dhKtLuK1YdZkyIeracVEfP9cl+93/yU1lafuN7L9/6DWbNq1doaeNviMCSs5EsubMM8M9Lq1pWpfpGnavyzS5cConsZCzz1cZjVRFXTsu6uN3BE2/+18v3P27P6V4V02yE09suXZZ03bJ/EYKC2HiRFiyJDyipO+I/Je7d5rHscce6yK56qST3I87Lvn2jz7q3oVa37trjRcW7PR+PWr8qnG1Pny4+w9+kLk4O6OVK917l1X7Iirdw6QNuz0WUem9y6p95crOefyOZuVK90nja71fj13f/Unja/c4P8m2a82WLe49e7p/4Qtpewsp03ckPwFLPU4+o1IaIlkybhz8/vdhGqdk59ncuBFKS3e/V62+PrmBBbLLpHExSmdP5/q6yS22mVI8ldiYK7hxRvovF0d9/I7k8cfhz3+Gb3wDevbM3nGvuQZ+8QtYtQr698/ecRvpO5KfWiqloeRMJEumTYOvfjUkXL17t39/jz4a5uw877z276uzi7p2XNTH70guvBAefDCUnslmiYs33wyXNc86C4qKsnfcRvqO5CfVOROJ2GGHhedkZgp4/nk48UR48cX4693h5z+Hyy6DN95IW4idVtS146I+fkcRi8H8+XDGGdmvPXbggXDOOdEkZqDviOxOyZlIlgwdCo88Ah/9aOtt77kHnnwS+vSJv94Mbr01PI8ZE5I1aVnUteOiPn5H8dhj8MEHMGpUNMffsQN++EO4667sH1vfEWlKyZlIluy9N5x8MvTokbide0jOTjih5eQMYMAA+NnPwuXNZCZUz2ejzy9gdlHiuli32Fg+d05masclU7/rtuKxnHt+fteuu+eecJ9ZVBORFxbCn/4EP/hBuLczm1TfUJpSciaSRX/9a7hsk8i//w2vvppc78Fll4UkbtIkuOzL+VkbKVFdqOeegy9/GS6fWMLsLonrYt3sY5n/lxKeeab1/aZqwtUl3Ezi48/ysSx/uYT33svfWlelpeEeypKI7nc3g9GjYfVrMfp0y+65V33D1HT630i8IZwd9aFSGpLrPvMZ96OPTtzm2992LyhwX7cuuX3efrt7ry7Vfm3xz3wlA72OQl/JQJ9S/DPvXVbtDz/c/rhz1cMPh/IDU5q992uLf+a9ulR7UZH7/vu7V1Xtantt8VRfyUDfTlFD26neu6zab7jB/YAD3Lt0cR8/Pv5+23pOFy4MFRF6FLV8/Msvdy8udu/b133vruk7tiSv8TtyDdk/99u2uR96aONveffvyOTCqfrsm2jpd98RfyO0UEoj8oQqnQ8lZ5LrJk50Ly93r69vuc2dd7pfcUVy+8vn2kjJvPduBdX+1FO7b5OoLtbGje7/8z/u3QvTd063bHE/6CD3ww5z//e/Ex//j390L7f8/Dw3boz2+FH/lq69Nhzqjjt2/46UF9T4QfulXruts4r6c0o3JWciOWDmzPCre/vt9OzvqrG1PqX4Z3H/SDU+ri2e6pPG16bngDkkmff+9Ta894mX1/q1aTynEya4m7n/4x/Jvad0Hruj2L7dfZ993L/2tehiiPK39PTT7oWF7l/5yp7rvvvd1HrSO7vO9jdPyZlIDnjkkfCre/zx+OuXL3d///3k99e3+1ZfycCEf6hWMtD79ahJS/y5JFPvPZ37XbEibDJxYrTvKdc1/i7uuy+6GKI697W17oMGue+3n/t//rPn+sbv0KxZaT1sh9XZfiMtJWcqQiuSRatXw0EHhTIYl1665/ojjwwjNP/61+T2V1hQT8y7UMTOFtvUUURpQYwdOzvX+J9Mvfd07tcd7r8fTjkFysuze+yO5LLL4He/2zUjRhSiOveNdd0efBA++9k917vDRz4SJmh/7LG0HbbD6my/ERWhFckBBx4IL70EX/rSnutefjmM1DzzzOT3l8+1kTL13tO13//8J4z+O+us5BKzdB67I9mxA+67D047LbrEDKI79yNHht99vMQMwnfonHOguhrq6tJ66A4pX34jSs5EsqigAA4/HLp02XPdvHnh+XOfS35/ydZG6oz1s46rLGAW6a8LlY56U4sWhUQ81Z6OfKx19eSTocfsnHOijSPb576uLswEAq0Xpv7e9+Cpp7I/a0IuSuZzusU6wW8k3rXOjvrQPWfSETz8sPt11+25/Kij3I8/PrV9JTNyaZ+u1X7YYe5Ll+7a5qqxtd63+1YvsJ3et/tWv2ps7o0GSxTnunXupaXu3QrSP2or2dFgV1wR7heKF2ffnrW+777umzdn5tiZ/qyy+R354AP3OXPcayK+RSjT5775Oe1VstVLqPU//zn5fcRibTt2Z7JyZSg1k+hz2qtk988p2e9zFH8b0YAAkdwweXKopbVjx65lq1aFX+O0aanvr7X6Xb/4xa76XePGdYz6QC3WLyvaFefTT7vPn5/4vbf1/bR2TidPDp/XIYe471O6Z5xX8zPfq6Rtx2/p2NcUTPUyqn3OnLa9p1SPn+vfkUxo6dx/rWCql1Lt117bvv02P6dfs+TP6Z13unfvHn3JkajV1ITBE+VW7V9v5Xc/bZr7JZck932O6nuv5EwkR9x2W/jlrVq1+/IXX2z7H95k63eVEn2vTDLvJZUejNbee3viSLTfWbPcyzJ0PuMde8KY2ownRtnuuXvmGfcbb0y9hzGT4p37iWNr/aqr3N99t237S8c5feaZsMns2W17X53FNdeE8zBnTuLfZ319KPqdzN+8xx6LrsdayZlIjnjiifDL+8tfsnvciZfX+uSC3K8P1FHqGF01ttavLYomzhdeSPsu3T37537ChHB5esuWtOwuK5r2eCcjXee0vt594ED3U09tR/CdwO9+F64+JGPi2OT+5n18UE1kf3OUnInkiLVrwy/vl78Mr6uq3M891/2VVzJ73I5SH0hxJnbHHaGo7aJFad2tu2f3Pe3c6b7vvu5nn52GwLNk7Vr3Y45xv+ee5LdJ5zmdPNm9qMj9vffa8SbySLLnvpSayP7mtJScabSmSJZ96EPQvTusXRtez5sHv/995id73lRdwgBWJ2zTnzVsqu6a2UBaoTgTGzUqjAT9ylegNs3VArL5nhYtgnfeCe+no+jTJ5S2GDcONm1Kbpt0ntNzzgmlRx54ILljdybXXQfTp4dMKVnJnvtauubc3xwlZyJZZgbr18P114fX8+bBxz8OAwZk9rgdpT6Q4kyse3e47bZQF+9730vrrrP6nubNC/9Dctpp7d5V1hQVwR13wPvvw8SJyW2zT3n6zumxx8JPfgLDhiV37M7imWfCd/2558Lfz2Ql+30upTbn/uYoOROJQGOxzTfegKefzk6Np45SQ2v0+QXM7iBxRnU+TzkFLr4Ypk4N35902LwZBh/d+rm/tWgso77Q/ve0aVMovNq9e7t3lVWDB8M3vwlz54bq/oksXAixHemrx2cGX/86HHpoKhF3bNu3w0UXQd++cOONqW2b7G/0o4PIvb+N8a51dtSH7jmTjmDlSvfPnVbr3Yu2egE7vStb/SvnZb7OWK7U0Eomzl5dOkacUZ7P9993P/JI91tuaX8Np2XLQlmQgoLWa0iVUe0VFbsGJbSnhtSVl+defb1kxGLugweHuoTx3vtrr7l///vh3sBDDnHfp5Vzmsr3ZOdO9wcfdP/HPzL7HqPS/HvSs8tW70Kt/+pXbdtXMr9RjdZUciZ5rrGWzuTCaGpItVa/KxdqWK1a5V5SEgrMtlbHKGpRn88HH2xfDadri3/mvbpUe1FRqB3197+3/p6uv969b1/3sjL3q6/O7RpSmfSb3yR+T2ed5X7BBe7V1en9ntTXux94oPvpp2fuvUUlHfXgWtpna+c+qt+ykjORiEXd09I0jsb6QAXs9G6F6akLlg719e4nnRSKbT75ZGbql6VbpuqsJXPcdPUKdCuo9qeeSv49rV3rftxxuV9DKlOSPfevvbb7Nun6nlx1VSgq/cEH6XtPUcvk38dkz30Uv2UlZyIRy8X6Xe+/HxKiXPGrX4VTccstUUeS+5L9PiVTw+nrbfjeXXlZrX8tx2tIZUrUv+V//jMc5q67MrL7SER9TqPSUnJmYV3nMGTIEF+6dGnUYYjE1a/HNhZtGUQFq1psU8VAhvVYwboPyrIYWe647Tb405/g/vvDJPHSsmS/T0eyghUcmfbvXbLHH8wKlmfg+FGK+rdcXw/9+4dR3vfdl/bdRyLqcxoVM3vG3YfssVzJmUh2FBbUE/MuFLGzxTZ1FFFaEGPHzuxlJpMnw86dcMMNWTtkQu6pDZfPV8l+n0qIsZ30f++iPn6UcuG3PHEiPPxwKKlSGO3A5bTIhXMahZaSs87zDkVyXK7W73r7bfjd71Ir7phud98Nd92lxCwVUddwivr4UcqF3/KPfgSvvNI5EjPIjXOaS5SciWRJrtYZGz48FMV94YWsHva/1q6FsWPh1lujTRA7mqhrOEV9/Cjlwm+5W7dw6b+z/GZGn1/A7KLO9T1pl3g3onXUhwYESC7LldGaza1eHUKYNq3t+2hPravDBtR6ly7ur77arreRd6Ku4RT18aOUK7/lm25y792j9d9dR7BypfteJdGf02xDozVFohd1XayWHHqo+2c/27Ztk61h1VK7q/mZ9yzumLWuohZ1Daeojx+lqN/Tww+HgsFX03lqx0V9TqOg5EwkR0RVFyuRH/zA/atfTX27fO49yRVR13CK+vhRyvUadx3l3K5c6X7vvbv+3dm+J4m0lJxptKaItNmkcTFKZ0/n+rrJLbaZUjyVxz48juGvzGy1XWzMFdw4oyQToYp0Gsn+7jrC76m+Hk48MUxqvmoV7LNP1BFll0ppiEhC9fXw7rvQp0/y20Rda0skH3WmmmA33wzjx4cah5dcEnU02afkTEQSOvlk2L4dnngi+W3yudaVSFQ6S02wN96AQYPg+OPhL3/JzzI6qnMmIgkdcwwsXgzV1clvk8+1rkSi0hlqgrnDmDEhIbvttvxMzBJRciYiQKh3VlcHf/978tvkc60rkajkQp21dPjyl2HGDBiQOM/MS0rORASAYcOgSxd47LHkt5lwdQm3FY9jMZVx1y+mktnFY/nJTWVJtRs/KbdvXhbJBcn+7nLl91RVFQYx9OuxjcKCevr12MZXx8f4xCfgS1+KOrrcpORMRAAoKwsJ2sKFyW9TUQG3/76ckWULmVI8lSoGUkcRVQxkSvFURpYtZM68ck48EebMa71dRUXm3p9IZ1FR0fLv6WqmcmpR7vyeFiyAysE1lM6ezqItg4h5FxZtGUSXW6dTObiGBQuijjA3aUCAiPzXwoVhUMBnPpP8NtdcA488AicOi3H33J1squ5K7261jL6gkPGTSnb7D0RVFcycFmPunYnbiUjr4v2eBhxcyL+eL+Gxx0KJiqjjqxxcw/ytwxnKkj3WL6aSkWULWbI8NxLJKGi0poik3ZYtcOCBMGIE/P73UUcjItu2wVFHhXphixZFe6N9Z6rHlikarSkiSfnXv+DBB5Nr+5vfwAcfwFVXZTIiEUlWaSncey889FD0IyDn3lXPxXW3JGxzSd0s5t7ZckmQfKWeMxHZzZlnwooV4ZJEIjt3woc/DH37hv9DF5HcsmMHvPUWHHRQNMfvLPXYMkk9ZyKSlJNOCtOorGq5+DgADz8cEjj1monkpnPPDcWlt26N5vidoR5bVJScichuhg8Pz62V1Dj5ZLjzTjj77MzHJCKpGzsWVq6Eb387muN3lnpsUchocmZmp5rZK2a20syujbP+PDNb3vBYZGZHNVnXy8zmmdnLZvaSmQ3NZKwiEhx+OOy7b+vJWdeucP75UFSUnbhEJDUnngiXXQY33gjnnr17nbFJ42Kt3rrQXhOuLuGWgo5Tjy2XZCw5M7NCYCYwAjgCONfMjmjW7HXgf919MPBD4NYm624C/uzuhwNHAS9lKlYR2cUs9J4tXhymWInnm9+EWxLf5ysiOeDkk6Hcajjgvt3rjJXOznydsZ49ob5rOacULORa1TdMScYGBDT0dH3P3T/d8HoKgLv/uIX2ewH/dvf9zawH8Dww0FMIUAMCRNJjw4bwh7Ukzv/QrlsXplu59NIw9YqI5Kao64yddx7ccw/cdx88tkD1DeOJYkDA/sCbTV6/1bCsJRcDjTn8QGAj8Gsze87MZptZebyNzGyMmS01s6UbN25MR9wiea9v3/iJGcCsWaFQ7cSJ2Y1JRFIz44YYl9bdHDcxAxjKEi6pm8XMabG0H3v+fJg7N/Syf/azcOOMEtZ9UMaOnQWs+6CMG2coMUskk8lZvAorcXvBzOxThOTs6w2LioBjgFnu/jGgBtjjnjUAd7/V3Ye4+5A+ffq0P2oRAeCmm2DSpN2X1daG5Oy00+DQQ6OJS0SSE2WdsbVr4bjjYMqUtO86L2QyOXsLOLDJ6wOAtc0bmdlgYDZwhru/22Tbt9z9qYbX8wjJmohkyWuvwa23hl6yRnPnwsaNeyZtIpJ7NlWXMIDVCdv0Zw2bqrum/diXXx7qH3bpkvZd54VMJmdPA4ea2cFm1gX4IjC/aQMz6w/cC1zg7q82Lnf3dcCbZvbhhkUnAS9mMFYRaWb48FAf6amndi0bODDca/apT0UXl4gkJ4o6YwsXhhkKAApVIaPNMpacufsOYALwF8JIyz+4+wtmdrmZNRY++Q6wD3CzmS0zs6Z3818B/M7MlgNHA9dnKlYR2dMJJ0BBQfhj23TZrbdGPy2MiLQu23XGPvgALroIvvUtqKtLyy7zlqZvEpG4qqrghONj/OfderbVl9CzJMaozxfw9e/oRl6RjiCTozWrqsKAg7l31bOpuoTe3WLsd2ABz79UwuLF8IlPpOlNdHKavklEkrZgQfijPnrTdJ7fGWojPV07iL3uynxtJBFJj4oKmDOvnJFlC5nSrM7Y16ztdcYa/z6Uzt69dtpJL06ne2EN772XmfeTT9RzJiK7ibo2koikV1UVzJyWnjpj+vuQXuo5E5GkRFkbSUTSr6Iifp0x91AeJxX6+5AdSs5EZDdR1kYSkex4/nk47DD4/e9T205/H7JDlzVFZDeFBfXEvAtFtPzHtY4iSgti7Nip/78T6Yjc4aijwsjrZcuSH4Gtvw/ppcuaIpKUKGojiUh2mcFVV8Hy5fD448lvp78P2aHkTER2k+3aSCISjdGjoU8f+MUvUthGfx+yQsmZiOxmwtUl3FY8jsVUxl2/mEpmF49l/KQWZkYXkQ6ha1cYOzYUmt60Kblt9PchO5ScichuEtVGmlLc9tpIIpJ7rroK3ngDevdOrn1FBYy9upzhLOTrhfr7kCkaECAicaWzNpKI5L76+jBlWzIeewweuk9/H9qrpQEBSs5ERETy2NatcPLJcNZZcM01LbeLxcIAgo9/PHuxdXYarSkiIiJ7KCuDLl3gl7+EHTtabnfddVBZCS+/nL3Y8pWSMxERkTw3aRKsWQP33ht//XPPwY9/DOefD4cfnt3Y8pGSMxERkTx32mnhZv94ZTW2b4eLLgplN6ZNy3poeUnJmYiISJ4rKICJE2HxYnjqqd3X/eQnYbqnW26BvfeOJr58UxR1ACIiIhK9iy6C996DO2fHGHlyPZuqS+jdLcZHjyzgc58r4Ywzoo4wf6jnTERERPj732HGz2ro8dvpLNoyiJh3YdGWQVQ+PZ0nFtSwYEHUEeYPldIQERHJc1VVUDm4hvlbhzOUJXusX0wlI8sWsmS5Csymk0ppiIiISFwzbohxad3NcRMzgKEs4ZK6WcycFstyZPlJyZmIiEiem3tXPRfX3ZKwzSV1s5h7584sRZTflJyJiIjkuU3VJQxgdcI2/VnDpuquWYoovyk5ExERyXO9u8VYzYCEbdbQn97darMUUX5TciYiIpLnRp9fwO3FlydsM7t4LKMvKMxSRPlNyZmIiEiem3B1CbcVj2MxlXHXL6aS2cVjGT+pJMuR5SclZyIiInmuogLmzCtnZNlCphRPpYqB1FFEFQOZUjyVkWULmTNPZTSyRcmZiIiIMGIELFleTmzMFQzrsYLSghjDeqwgNuYKliwvZ8SIqCPMHypCKyIiIhIBFaEVERER6QCUnImIiIjkECVnIiIiIjlEyZmIiIhIDlFyJiIiIpJDlJyJiIiI5BAlZyIiIiI5RMmZiIiISA7pVEVozWwjsLoNm/YGNqU5HEk/fU4dgz6n3KfPqGPQ59QxtOdzGuDufZov7FTJWVuZ2dJ4FXolt+hz6hj0OeU+fUYdgz6njiETn5Mua4qIiIjkECVnIiIiIjlEyVlwa9QBSFL0OXUM+pxynz6jjkGfU8eQ9s9J95yJiIiI5BD1nImIiIjkkLxPzszsVDN7xcxWmtm1UccjgZndYWYbzOzfTZbtbWaPmtlrDc97RRljvjOzA83scTN7ycxeMLOJDcv1OeUQM+tqZv8ys+cbPqfvNyzX55RjzKzQzJ4zswcbXuszyjFm9oaZrTCzZWa2tGFZ2j+nvE7OzKwQmAmMAI4AzjWzI6KNShr8Bji12bJrgcfc/VDgsYbXEp0dwNXu/hGgEhjf8PvR55RbYsCJ7n4UcDRwqplVos8pF00EXmryWp9RbvqUux/dpHxG2j+nvE7OgOOAle6+yt23A3cDZ0QckwDu/iTwXrPFZwC/bfj3b4EzsxmT7M7d33H3Zxv+vYXwH5X90eeUUzyobnhZ3PBw9DnlFDM7APgsMLvJYn1GHUPaP6d8T872B95s8vqthmWSm/q5+zsQEgOgb8TxSAMzOwj4GPAU+pxyTsPlsmXABuBRd9fnlHt+AUwG6pss02eUexx4xMyeMbMxDcvS/jkVtXcHHZzFWabhqyIpMLNuwB+Bq9x9s1m8n5VEyd13AkebWS/gPjMbFHFI0oSZnQZscPdnzOyEiMORxIa5+1oz6ws8amYvZ+Ig+d5z9hZwYJPXBwBrI4pFWrfezPYFaHjeEHE8ec/MigmJ2e/c/d6GxfqccpS7vw/8jXA/pz6n3DEMGGlmbxBurznRzO5Cn1HOcfe1Dc8bgPsIt0el/XPK9+TsaeBQMzvYzLoAXwTmRxyTtGw+8KWGf38JeCDCWPKehS6y24GX3P3GJqv0OeUQM+vT0GOGmZUCw4GX0eeUM9x9irsf4O4HEf479Fd3Px99RjnFzMrNrHvjv4FTgH+Tgc8p74vQmtlnCNf6C4E73P1H0UYkAGb2e+AEoDewHvgucD/wB6A/sAY4x92bDxqQLDGz/wf8HVjBrvtkvkG470yfU44ws8GEm5QLCf9D/gd3/4GZ7YM+p5zTcFnzGnc/TZ9RbjGzgYTeMgi3hc119x9l4nPK++RMREREJJfk+2VNERERkZyi5ExEREQkhyg5ExEREckhSs5EREREcoiSMxEREZEcouRMRCQOM6tu8u/PmNlrZtY/yphEJD/k+/RNIiIJmdlJwC+BU9x9TdTxiEjnp+RMRKQFZvZJ4DbgM+5eFXU8IpIfVIRWRCQOM6sDtgAnuPvyqOMRkfyhe85EROKrAxYBF0cdiIjkFyVnIiLx1QOfBz5uZt+IOhgRyR+650xEpAXuvtXMTgP+bmbr3f32qGMSkc5PyZmISALu/p6ZnQo8aWab3P2BqGMSkc5NAwJEREREcojuORMRERHJIUrORERERHKIkjMRERGRHKLkTERERCSHKDkTERERySFKzkRERERyiJIzERERkRyi5ExEREQkh/x/6/XKIOIfdy0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Optimal K \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "error_rate = []\n",
    "for i in range(1,50):\n",
    "     knn = KNeighborsClassifier(n_neighbors=i)\n",
    "     knn.fit(X_train,y_train)\n",
    "     pred_i = knn.predict(X_test)\n",
    "     error_rate.append(np.mean(pred_i != y_test))\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(range(1,50),error_rate,color='blue', linestyle='dashed', \n",
    "         marker='o',markerfacecolor='red', markersize=10)\n",
    "plt.title('Error Rate vs. K Value')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Error Rate')\n",
    "print(\"Minimum error:-\",min(error_rate),\"at K =\",error_rate.index(min(error_rate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting K-NN to the Training set (4 variables)\n",
    "knn = KNeighborsClassifier(n_neighbors = 42, metric = 'minkowski', p = 2).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7404921700223713"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred1 = knn.predict(X_test)\n",
    "knn.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[207  41]\n",
      " [ 75 124]]\n"
     ]
    }
   ],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred1)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель KNN є краще, ніж попередня модель логістичної регресії. Так як коефіцієнт точності розпізнавання збільшився майже на 3%, а кількість помилково розпізнаних даних скоротилась 13. Стало менше як хибно позитивних, так і хибно негативних."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting SVM to the Training set (4 variables)\n",
    "from sklearn.svm import SVC\n",
    "svm = SVC(kernel = 'rbf', random_state = 10).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7114093959731543"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred2 = svm.predict(X_test)\n",
    "svm.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[195  53]\n",
      " [ 76 123]]\n"
     ]
    }
   ],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred2)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дана модель є гіршою, ніж KNN як за коефіцієнтом детермінації, так і за кількістю помилково розпізнаних даних.\n",
    "А от якщо порівнювати з моделлю логістичної регресії, то в них коефіцієнт розпізнавання даних є однаковим. Також однакова загальна кількість помилково розпізнаних даних. Але SVM має меншу кіл-сть хибно негативних значень, проте має більшу кіл-сть хибно позитивних значень."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Naive Bayes to the Training set (4 variables)\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb = GaussianNB().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70917225950783"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred3 = nb.predict(X_test)\n",
    "nb.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[196  52]\n",
      " [ 78 121]]\n"
     ]
    }
   ],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred3)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "З усіх розглянутих на даний момент моделей, дана модель є найгіршою. Про це свідчить найменше значення точності та найбільша кіль-сть помилково розізнаних даних."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function Max Leaf\n",
    "def max_leaf_nodes(X_train, X_test, y_train, y_test, n):\n",
    "    mse_train = []\n",
    "    mse_test = []\n",
    "    for i in n:\n",
    "        rf = DecisionTreeRegressor(max_leaf_nodes = i, random_state=10).fit(X_train, y_train)\n",
    "        mse_train.append(mean_squared_error(y_train, rf.predict(X_train)))\n",
    "        mse_test.append(mean_squared_error(y_test, rf.predict(X_test)))\n",
    "    fig, ax = plt.subplots(figsize=(8, 4))\n",
    "    ax.plot(n, mse_train, alpha=0.5, color='blue', label='train')\n",
    "    ax.plot(n, mse_test, alpha=0.5, color='red', label='test')\n",
    "    ax.set_ylabel(\"MSE\")\n",
    "    ax.set_xlabel(\"max_leaf_nodes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The optimal number of max_leaf_nodes\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "max_leaf_nodes(X_train, X_test, y_train, y_test, [2, 4, 6, 8, 10, 12, 14])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так як найменше значення помилки на тестовій вибіркі спостерігається при max_leaf_nodes=10, то візбмемо в якості даного параметро саме число 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Classification Tree to the Training set (2 variables)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "ct = DecisionTreeClassifier(max_leaf_nodes = 10, criterion = 'entropy', random_state = 10).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7158836689038032"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred4 = ct.predict(X_test)\n",
    "ct.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[187  61]\n",
      " [ 66 133]]\n"
     ]
    }
   ],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred4)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дана модель не є найкращою з усіх розглянутих. За коефіцієнтом детермінації вона поступається моделі KNN. В порівнянні з усіма іншими моделаями вона є трохи кращою за точністю прогнохування класу. Що стосується кіл-сті помилково розпізнаних данних, то вона має максимальну кількість хибно позитивних значень та мінімальну кіл-сть хибно негативних значень в порівнянні з усіма іншими моделями\n",
    "\n",
    "Тепер побудуємо модель випадкового лісу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_best_n_estimator(X_train, X_test, y_train, y_test, n):\n",
    "    mse_train = []\n",
    "    mse_test = []\n",
    "    for i in n:\n",
    "        rf = RandomForestRegressor(n_estimators=i, random_state=10).fit(X_train, y_train)\n",
    "        mse_train.append(mean_squared_error(y_train, rf.predict(X_train)))\n",
    "        mse_test.append(mean_squared_error(y_test, rf.predict(X_test)))\n",
    "    fig, ax = plt.subplots(figsize=(8, 4))\n",
    "    ax.plot(n, mse_train, alpha=0.5, color='blue', label='train')\n",
    "    ax.plot(n, mse_test, alpha=0.5, color='red', label='test')\n",
    "    ax.set_ylabel(\"MSE\")\n",
    "    ax.set_xlabel(\"N_estimators\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The optimal number of trees \n",
    "from sklearn.ensemble import RandomForestRegressor    \n",
    "rf_best_n_estimator(X_train, X_test, y_train, y_test, [2, 4, 6, 8, 10, 12, 14, 16, 18, 20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для моделі випадкового лісу в якості кількості дерев можна обрати 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_max_leaf_nodes(X_train, X_test, y_train, y_test, n):\n",
    "    mse_train = []\n",
    "    mse_test = []\n",
    "    for i in n:\n",
    "        rf = RandomForestRegressor(n_estimators=6, max_leaf_nodes =i, random_state=10).fit(X_train, y_train)\n",
    "        mse_train.append(mean_squared_error(y_train, rf.predict(X_train)))\n",
    "        mse_test.append(mean_squared_error(y_test, rf.predict(X_test)))\n",
    "    fig, ax = plt.subplots(figsize=(8, 4))\n",
    "    ax.plot(n, mse_train, alpha=0.5, color='blue', label='train')\n",
    "    ax.plot(n, mse_test, alpha=0.5, color='red', label='test')\n",
    "    ax.set_ylabel(\"MSE\")\n",
    "    ax.set_xlabel(\"max_leaf_nodes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The optimal number of max_leaf_nodes\n",
    "rf_max_leaf_nodes(X_train, X_test, y_train, y_test, [2, 4, 6, 8, 10, 12, 14])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так як найменше значення помилки на тестовій вибіркі при відносно невеликій розбіжності значень помилок на тренувальній та тестовій вибірках спостерігається при max_leaf_nodes=4, то візбмемо в якості даного параметро саме число 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Random Forest to the Training set\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor(n_estimators = 6, max_leaf_nodes = 4, random_state = 10).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23634731722325408"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred5 = rf.predict(X_test)\n",
    "y_pred5 = (y_pred5 > 0.5)\n",
    "rf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[185  63]\n",
      " [ 66 133]]\n"
     ]
    }
   ],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred5)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "За коефіцієнтом правильно розпізнаних данних, дана модель є найгіршою і взагалі не може бути застосована на практиці через своє дуже мале значення"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Install Tensorflow\n",
    "# Install Keras\n",
    "# Importing the Keras libraries and packages\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Побудуємо декілька нейронних мереж для класифікації. Будемо розглядати 5 різних архітектур - '4-3-1', '4-2-1', '4-3-2-1', '4-2-2-1', '4-4-1'. Кількість спостережнь в тренувальній вибірці дозволяє нам проекспериментувати з вказаними архітектурами моделі. Також кількість нейронів на прихованих шарах в даних моделях не перевищує подвоєнної кіл-сті пояснюючих змінних"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\38095\\anaconda3\\envs\\labvika\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=4, units=3, kernel_initializer=\"uniform\")`\n",
      "  \"\"\"\n",
      "C:\\Users\\38095\\anaconda3\\envs\\labvika\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Initialising the ANN 4-3-1\n",
    "cnn1 = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "cnn1.add(Dense(output_dim = 3, init = 'uniform', activation = 'relu', input_dim = 4))\n",
    "\n",
    "# Adding the output layer\n",
    "cnn1.add(Dense(output_dim = 1, init = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "# Compiling the ANN\n",
    "cnn1.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\38095\\anaconda3\\envs\\labvika\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1788/1788 [==============================] - 0s 266us/step - loss: 0.6854 - accuracy: 0.5638\n",
      "Epoch 2/100\n",
      "1788/1788 [==============================] - 0s 132us/step - loss: 0.6394 - accuracy: 0.6521\n",
      "Epoch 3/100\n",
      "1788/1788 [==============================] - 0s 143us/step - loss: 0.5967 - accuracy: 0.6868\n",
      "Epoch 4/100\n",
      "1788/1788 [==============================] - 0s 136us/step - loss: 0.5765 - accuracy: 0.6946\n",
      "Epoch 5/100\n",
      "1788/1788 [==============================] - 0s 131us/step - loss: 0.5679 - accuracy: 0.6969\n",
      "Epoch 6/100\n",
      "1788/1788 [==============================] - 0s 150us/step - loss: 0.5641 - accuracy: 0.6991\n",
      "Epoch 7/100\n",
      "1788/1788 [==============================] - 0s 131us/step - loss: 0.5618 - accuracy: 0.7025\n",
      "Epoch 8/100\n",
      "1788/1788 [==============================] - 0s 124us/step - loss: 0.5604 - accuracy: 0.7047\n",
      "Epoch 9/100\n",
      "1788/1788 [==============================] - 0s 134us/step - loss: 0.5592 - accuracy: 0.7058\n",
      "Epoch 10/100\n",
      "1788/1788 [==============================] - 0s 134us/step - loss: 0.5576 - accuracy: 0.7081\n",
      "Epoch 11/100\n",
      "1788/1788 [==============================] - 0s 125us/step - loss: 0.5563 - accuracy: 0.7114\n",
      "Epoch 12/100\n",
      "1788/1788 [==============================] - 0s 130us/step - loss: 0.5548 - accuracy: 0.7136\n",
      "Epoch 13/100\n",
      "1788/1788 [==============================] - 0s 147us/step - loss: 0.5530 - accuracy: 0.7148\n",
      "Epoch 14/100\n",
      "1788/1788 [==============================] - 0s 135us/step - loss: 0.5508 - accuracy: 0.7148\n",
      "Epoch 15/100\n",
      "1788/1788 [==============================] - 0s 132us/step - loss: 0.5490 - accuracy: 0.7164\n",
      "Epoch 16/100\n",
      "1788/1788 [==============================] - 0s 131us/step - loss: 0.5468 - accuracy: 0.7148\n",
      "Epoch 17/100\n",
      "1788/1788 [==============================] - 0s 151us/step - loss: 0.5444 - accuracy: 0.7181\n",
      "Epoch 18/100\n",
      "1788/1788 [==============================] - 0s 129us/step - loss: 0.5423 - accuracy: 0.7192\n",
      "Epoch 19/100\n",
      "1788/1788 [==============================] - 0s 121us/step - loss: 0.5403 - accuracy: 0.7254\n",
      "Epoch 20/100\n",
      "1788/1788 [==============================] - 0s 126us/step - loss: 0.5387 - accuracy: 0.7248\n",
      "Epoch 21/100\n",
      "1788/1788 [==============================] - 0s 160us/step - loss: 0.5368 - accuracy: 0.7260\n",
      "Epoch 22/100\n",
      "1788/1788 [==============================] - 0s 140us/step - loss: 0.5350 - accuracy: 0.7276\n",
      "Epoch 23/100\n",
      "1788/1788 [==============================] - 0s 153us/step - loss: 0.5336 - accuracy: 0.7271\n",
      "Epoch 24/100\n",
      "1788/1788 [==============================] - 0s 142us/step - loss: 0.5324 - accuracy: 0.7254\n",
      "Epoch 25/100\n",
      "1788/1788 [==============================] - 0s 148us/step - loss: 0.5313 - accuracy: 0.7282\n",
      "Epoch 26/100\n",
      "1788/1788 [==============================] - 0s 126us/step - loss: 0.5303 - accuracy: 0.7237\n",
      "Epoch 27/100\n",
      "1788/1788 [==============================] - 0s 124us/step - loss: 0.5294 - accuracy: 0.7282\n",
      "Epoch 28/100\n",
      "1788/1788 [==============================] - 0s 121us/step - loss: 0.5286 - accuracy: 0.7293\n",
      "Epoch 29/100\n",
      "1788/1788 [==============================] - 0s 120us/step - loss: 0.5281 - accuracy: 0.7327\n",
      "Epoch 30/100\n",
      "1788/1788 [==============================] - 0s 132us/step - loss: 0.5273 - accuracy: 0.7321\n",
      "Epoch 31/100\n",
      "1788/1788 [==============================] - 0s 126us/step - loss: 0.5269 - accuracy: 0.7315\n",
      "Epoch 32/100\n",
      "1788/1788 [==============================] - 0s 130us/step - loss: 0.5262 - accuracy: 0.7321\n",
      "Epoch 33/100\n",
      "1788/1788 [==============================] - 0s 123us/step - loss: 0.5257 - accuracy: 0.7360\n",
      "Epoch 34/100\n",
      "1788/1788 [==============================] - 0s 127us/step - loss: 0.5256 - accuracy: 0.7304\n",
      "Epoch 35/100\n",
      "1788/1788 [==============================] - 0s 125us/step - loss: 0.5251 - accuracy: 0.7304\n",
      "Epoch 36/100\n",
      "1788/1788 [==============================] - 0s 127us/step - loss: 0.5247 - accuracy: 0.7293\n",
      "Epoch 37/100\n",
      "1788/1788 [==============================] - 0s 123us/step - loss: 0.5248 - accuracy: 0.7293\n",
      "Epoch 38/100\n",
      "1788/1788 [==============================] - 0s 124us/step - loss: 0.5244 - accuracy: 0.7293\n",
      "Epoch 39/100\n",
      "1788/1788 [==============================] - 0s 130us/step - loss: 0.5243 - accuracy: 0.7282\n",
      "Epoch 40/100\n",
      "1788/1788 [==============================] - 0s 127us/step - loss: 0.5238 - accuracy: 0.7293\n",
      "Epoch 41/100\n",
      "1788/1788 [==============================] - 0s 147us/step - loss: 0.5238 - accuracy: 0.7287\n",
      "Epoch 42/100\n",
      "1788/1788 [==============================] - 0s 127us/step - loss: 0.5234 - accuracy: 0.7265\n",
      "Epoch 43/100\n",
      "1788/1788 [==============================] - 0s 123us/step - loss: 0.5234 - accuracy: 0.7282\n",
      "Epoch 44/100\n",
      "1788/1788 [==============================] - 0s 119us/step - loss: 0.5233 - accuracy: 0.7304\n",
      "Epoch 45/100\n",
      "1788/1788 [==============================] - 0s 125us/step - loss: 0.5231 - accuracy: 0.7287\n",
      "Epoch 46/100\n",
      "1788/1788 [==============================] - 0s 133us/step - loss: 0.5231 - accuracy: 0.7321\n",
      "Epoch 47/100\n",
      "1788/1788 [==============================] - 0s 128us/step - loss: 0.5232 - accuracy: 0.7265\n",
      "Epoch 48/100\n",
      "1788/1788 [==============================] - 0s 132us/step - loss: 0.5226 - accuracy: 0.7276\n",
      "Epoch 49/100\n",
      "1788/1788 [==============================] - 0s 125us/step - loss: 0.5226 - accuracy: 0.7282\n",
      "Epoch 50/100\n",
      "1788/1788 [==============================] - 0s 122us/step - loss: 0.5227 - accuracy: 0.7310\n",
      "Epoch 51/100\n",
      "1788/1788 [==============================] - 0s 121us/step - loss: 0.5224 - accuracy: 0.7287\n",
      "Epoch 52/100\n",
      "1788/1788 [==============================] - 0s 123us/step - loss: 0.5223 - accuracy: 0.7271\n",
      "Epoch 53/100\n",
      "1788/1788 [==============================] - 0s 122us/step - loss: 0.5223 - accuracy: 0.7271\n",
      "Epoch 54/100\n",
      "1788/1788 [==============================] - 0s 127us/step - loss: 0.5221 - accuracy: 0.7276\n",
      "Epoch 55/100\n",
      "1788/1788 [==============================] - 0s 139us/step - loss: 0.5222 - accuracy: 0.7282\n",
      "Epoch 56/100\n",
      "1788/1788 [==============================] - 0s 120us/step - loss: 0.5220 - accuracy: 0.7237\n",
      "Epoch 57/100\n",
      "1788/1788 [==============================] - 0s 121us/step - loss: 0.5220 - accuracy: 0.7260\n",
      "Epoch 58/100\n",
      "1788/1788 [==============================] - 0s 119us/step - loss: 0.5219 - accuracy: 0.7260\n",
      "Epoch 59/100\n",
      "1788/1788 [==============================] - 0s 122us/step - loss: 0.5218 - accuracy: 0.7293\n",
      "Epoch 60/100\n",
      "1788/1788 [==============================] - 0s 123us/step - loss: 0.5218 - accuracy: 0.7271\n",
      "Epoch 61/100\n",
      "1788/1788 [==============================] - 0s 133us/step - loss: 0.5217 - accuracy: 0.7276\n",
      "Epoch 62/100\n",
      "1788/1788 [==============================] - 0s 125us/step - loss: 0.5215 - accuracy: 0.7287\n",
      "Epoch 63/100\n",
      "1788/1788 [==============================] - 0s 133us/step - loss: 0.5218 - accuracy: 0.7310\n",
      "Epoch 64/100\n",
      "1788/1788 [==============================] - 0s 128us/step - loss: 0.5215 - accuracy: 0.7271\n",
      "Epoch 65/100\n",
      "1788/1788 [==============================] - 0s 123us/step - loss: 0.5215 - accuracy: 0.7276\n",
      "Epoch 66/100\n",
      "1788/1788 [==============================] - 0s 127us/step - loss: 0.5213 - accuracy: 0.7327\n",
      "Epoch 67/100\n",
      "1788/1788 [==============================] - 0s 129us/step - loss: 0.5213 - accuracy: 0.7293\n",
      "Epoch 68/100\n",
      "1788/1788 [==============================] - 0s 130us/step - loss: 0.5212 - accuracy: 0.7299\n",
      "Epoch 69/100\n",
      "1788/1788 [==============================] - 0s 122us/step - loss: 0.5212 - accuracy: 0.7293\n",
      "Epoch 70/100\n",
      "1788/1788 [==============================] - 0s 127us/step - loss: 0.5212 - accuracy: 0.7293\n",
      "Epoch 71/100\n",
      "1788/1788 [==============================] - 0s 122us/step - loss: 0.5211 - accuracy: 0.7310\n",
      "Epoch 72/100\n",
      "1788/1788 [==============================] - 0s 124us/step - loss: 0.5210 - accuracy: 0.7310\n",
      "Epoch 73/100\n",
      "1788/1788 [==============================] - 0s 124us/step - loss: 0.5211 - accuracy: 0.7299\n",
      "Epoch 74/100\n",
      "1788/1788 [==============================] - 0s 137us/step - loss: 0.5211 - accuracy: 0.7282\n",
      "Epoch 75/100\n",
      "1788/1788 [==============================] - 0s 130us/step - loss: 0.5210 - accuracy: 0.7282\n",
      "Epoch 76/100\n",
      "1788/1788 [==============================] - 0s 124us/step - loss: 0.5208 - accuracy: 0.7287\n",
      "Epoch 77/100\n",
      "1788/1788 [==============================] - 0s 123us/step - loss: 0.5210 - accuracy: 0.7276\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1788/1788 [==============================] - 0s 130us/step - loss: 0.5209 - accuracy: 0.7276\n",
      "Epoch 79/100\n",
      "1788/1788 [==============================] - 0s 121us/step - loss: 0.5208 - accuracy: 0.7276\n",
      "Epoch 80/100\n",
      "1788/1788 [==============================] - 0s 125us/step - loss: 0.5210 - accuracy: 0.7293\n",
      "Epoch 81/100\n",
      "1788/1788 [==============================] - 0s 128us/step - loss: 0.5212 - accuracy: 0.7299\n",
      "Epoch 82/100\n",
      "1788/1788 [==============================] - 0s 121us/step - loss: 0.5207 - accuracy: 0.7287\n",
      "Epoch 83/100\n",
      "1788/1788 [==============================] - 0s 123us/step - loss: 0.5207 - accuracy: 0.7287\n",
      "Epoch 84/100\n",
      "1788/1788 [==============================] - 0s 123us/step - loss: 0.5211 - accuracy: 0.7271\n",
      "Epoch 85/100\n",
      "1788/1788 [==============================] - 0s 130us/step - loss: 0.5209 - accuracy: 0.7271\n",
      "Epoch 86/100\n",
      "1788/1788 [==============================] - 0s 133us/step - loss: 0.5208 - accuracy: 0.7304\n",
      "Epoch 87/100\n",
      "1788/1788 [==============================] - 0s 143us/step - loss: 0.5205 - accuracy: 0.7282\n",
      "Epoch 88/100\n",
      "1788/1788 [==============================] - 0s 123us/step - loss: 0.5206 - accuracy: 0.7299\n",
      "Epoch 89/100\n",
      "1788/1788 [==============================] - 0s 126us/step - loss: 0.5206 - accuracy: 0.7299\n",
      "Epoch 90/100\n",
      "1788/1788 [==============================] - 0s 125us/step - loss: 0.5206 - accuracy: 0.7315\n",
      "Epoch 91/100\n",
      "1788/1788 [==============================] - 0s 130us/step - loss: 0.5206 - accuracy: 0.7304\n",
      "Epoch 92/100\n",
      "1788/1788 [==============================] - 0s 125us/step - loss: 0.5207 - accuracy: 0.7315\n",
      "Epoch 93/100\n",
      "1788/1788 [==============================] - 0s 127us/step - loss: 0.5205 - accuracy: 0.7293\n",
      "Epoch 94/100\n",
      "1788/1788 [==============================] - 0s 120us/step - loss: 0.5206 - accuracy: 0.7287\n",
      "Epoch 95/100\n",
      "1788/1788 [==============================] - 0s 128us/step - loss: 0.5206 - accuracy: 0.7315\n",
      "Epoch 96/100\n",
      "1788/1788 [==============================] - 0s 128us/step - loss: 0.5204 - accuracy: 0.7315\n",
      "Epoch 97/100\n",
      "1788/1788 [==============================] - 0s 128us/step - loss: 0.5207 - accuracy: 0.7315\n",
      "Epoch 98/100\n",
      "1788/1788 [==============================] - 0s 132us/step - loss: 0.5205 - accuracy: 0.7304\n",
      "Epoch 99/100\n",
      "1788/1788 [==============================] - 0s 132us/step - loss: 0.5203 - accuracy: 0.7310\n",
      "Epoch 100/100\n",
      "1788/1788 [==============================] - 0s 127us/step - loss: 0.5206 - accuracy: 0.7304\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x22efb16a6c8>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the ANN to the Training set\n",
    "cnn1.fit(X_train, y_train, batch_size = 10, nb_epoch = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred6 = cnn1.predict(X_test)\n",
    "y_pred6 = (y_pred6 > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[190  58]\n",
      " [ 68 131]]\n"
     ]
    }
   ],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm1 = confusion_matrix(y_test, y_pred6)\n",
    "print(cm1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\38095\\anaconda3\\envs\\labvika\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=4, units=2, kernel_initializer=\"uniform\")`\n",
      "  \"\"\"\n",
      "C:\\Users\\38095\\anaconda3\\envs\\labvika\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Initialising the ANN 4-2-1\n",
    "cnn2 = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "cnn2.add(Dense(output_dim = 2, init = 'uniform', activation = 'relu', input_dim = 4))\n",
    "\n",
    "# Adding the output layer\n",
    "cnn2.add(Dense(output_dim = 1, init = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "# Compiling the ANN\n",
    "cnn2.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\38095\\anaconda3\\envs\\labvika\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1788/1788 [==============================] - 0s 168us/step - loss: 0.6861 - accuracy: 0.5666\n",
      "Epoch 2/100\n",
      "1788/1788 [==============================] - 0s 123us/step - loss: 0.6531 - accuracy: 0.6572\n",
      "Epoch 3/100\n",
      "1788/1788 [==============================] - 0s 123us/step - loss: 0.6140 - accuracy: 0.6885\n",
      "Epoch 4/100\n",
      "1788/1788 [==============================] - 0s 124us/step - loss: 0.5878 - accuracy: 0.6924\n",
      "Epoch 5/100\n",
      "1788/1788 [==============================] - 0s 124us/step - loss: 0.5745 - accuracy: 0.6946\n",
      "Epoch 6/100\n",
      "1788/1788 [==============================] - 0s 127us/step - loss: 0.5677 - accuracy: 0.69850s - loss: 0.5739 - accuracy: 0.\n",
      "Epoch 7/100\n",
      "1788/1788 [==============================] - 0s 135us/step - loss: 0.5643 - accuracy: 0.6980\n",
      "Epoch 8/100\n",
      "1788/1788 [==============================] - 0s 127us/step - loss: 0.5624 - accuracy: 0.7013\n",
      "Epoch 9/100\n",
      "1788/1788 [==============================] - 0s 127us/step - loss: 0.5612 - accuracy: 0.7092\n",
      "Epoch 10/100\n",
      "1788/1788 [==============================] - 0s 128us/step - loss: 0.5603 - accuracy: 0.7092\n",
      "Epoch 11/100\n",
      "1788/1788 [==============================] - 0s 131us/step - loss: 0.5593 - accuracy: 0.7136\n",
      "Epoch 12/100\n",
      "1788/1788 [==============================] - 0s 133us/step - loss: 0.5584 - accuracy: 0.7103\n",
      "Epoch 13/100\n",
      "1788/1788 [==============================] - 0s 128us/step - loss: 0.5577 - accuracy: 0.7125\n",
      "Epoch 14/100\n",
      "1788/1788 [==============================] - 0s 128us/step - loss: 0.5571 - accuracy: 0.7097\n",
      "Epoch 15/100\n",
      "1788/1788 [==============================] - 0s 127us/step - loss: 0.5564 - accuracy: 0.7120\n",
      "Epoch 16/100\n",
      "1788/1788 [==============================] - 0s 122us/step - loss: 0.5558 - accuracy: 0.7092\n",
      "Epoch 17/100\n",
      "1788/1788 [==============================] - 0s 134us/step - loss: 0.5553 - accuracy: 0.7058\n",
      "Epoch 18/100\n",
      "1788/1788 [==============================] - 0s 123us/step - loss: 0.5545 - accuracy: 0.7081\n",
      "Epoch 19/100\n",
      "1788/1788 [==============================] - 0s 136us/step - loss: 0.5542 - accuracy: 0.7064\n",
      "Epoch 20/100\n",
      "1788/1788 [==============================] - 0s 134us/step - loss: 0.5542 - accuracy: 0.7075\n",
      "Epoch 21/100\n",
      "1788/1788 [==============================] - 0s 124us/step - loss: 0.5534 - accuracy: 0.7097\n",
      "Epoch 22/100\n",
      "1788/1788 [==============================] - 0s 128us/step - loss: 0.5531 - accuracy: 0.7092\n",
      "Epoch 23/100\n",
      "1788/1788 [==============================] - 0s 130us/step - loss: 0.5526 - accuracy: 0.7109\n",
      "Epoch 24/100\n",
      "1788/1788 [==============================] - 0s 138us/step - loss: 0.5522 - accuracy: 0.7086\n",
      "Epoch 25/100\n",
      "1788/1788 [==============================] - 0s 133us/step - loss: 0.5519 - accuracy: 0.7109\n",
      "Epoch 26/100\n",
      "1788/1788 [==============================] - 0s 168us/step - loss: 0.5517 - accuracy: 0.7120\n",
      "Epoch 27/100\n",
      "1788/1788 [==============================] - 0s 164us/step - loss: 0.5511 - accuracy: 0.7148\n",
      "Epoch 28/100\n",
      "1788/1788 [==============================] - 0s 181us/step - loss: 0.5506 - accuracy: 0.7142\n",
      "Epoch 29/100\n",
      "1788/1788 [==============================] - 0s 182us/step - loss: 0.5505 - accuracy: 0.7181\n",
      "Epoch 30/100\n",
      "1788/1788 [==============================] - 0s 155us/step - loss: 0.5500 - accuracy: 0.7164\n",
      "Epoch 31/100\n",
      "1788/1788 [==============================] - 0s 169us/step - loss: 0.5495 - accuracy: 0.7142\n",
      "Epoch 32/100\n",
      "1788/1788 [==============================] - 0s 161us/step - loss: 0.5492 - accuracy: 0.7170\n",
      "Epoch 33/100\n",
      "1788/1788 [==============================] - 0s 212us/step - loss: 0.5487 - accuracy: 0.7181\n",
      "Epoch 34/100\n",
      "1788/1788 [==============================] - 0s 219us/step - loss: 0.5482 - accuracy: 0.7226\n",
      "Epoch 35/100\n",
      "1788/1788 [==============================] - 1s 410us/step - loss: 0.5481 - accuracy: 0.7187\n",
      "Epoch 36/100\n",
      "1788/1788 [==============================] - 1s 419us/step - loss: 0.5476 - accuracy: 0.7215\n",
      "Epoch 37/100\n",
      "1788/1788 [==============================] - 1s 411us/step - loss: 0.5473 - accuracy: 0.7237\n",
      "Epoch 38/100\n",
      "1788/1788 [==============================] - 1s 301us/step - loss: 0.5467 - accuracy: 0.7237\n",
      "Epoch 39/100\n",
      "1788/1788 [==============================] - 0s 167us/step - loss: 0.5462 - accuracy: 0.7220\n",
      "Epoch 40/100\n",
      "1788/1788 [==============================] - 1s 283us/step - loss: 0.5457 - accuracy: 0.7232\n",
      "Epoch 41/100\n",
      "1788/1788 [==============================] - 1s 408us/step - loss: 0.5453 - accuracy: 0.7260\n",
      "Epoch 42/100\n",
      "1788/1788 [==============================] - 1s 453us/step - loss: 0.5444 - accuracy: 0.7243\n",
      "Epoch 43/100\n",
      "1788/1788 [==============================] - 1s 371us/step - loss: 0.5441 - accuracy: 0.7220\n",
      "Epoch 44/100\n",
      "1788/1788 [==============================] - 1s 400us/step - loss: 0.5436 - accuracy: 0.7226\n",
      "Epoch 45/100\n",
      "1788/1788 [==============================] - 1s 365us/step - loss: 0.5434 - accuracy: 0.7243\n",
      "Epoch 46/100\n",
      "1788/1788 [==============================] - 1s 361us/step - loss: 0.5429 - accuracy: 0.7209\n",
      "Epoch 47/100\n",
      "1788/1788 [==============================] - 1s 359us/step - loss: 0.5425 - accuracy: 0.7220\n",
      "Epoch 48/100\n",
      "1788/1788 [==============================] - 1s 342us/step - loss: 0.5422 - accuracy: 0.7209\n",
      "Epoch 49/100\n",
      "1788/1788 [==============================] - 1s 312us/step - loss: 0.5417 - accuracy: 0.7232\n",
      "Epoch 50/100\n",
      "1788/1788 [==============================] - 1s 314us/step - loss: 0.5415 - accuracy: 0.7215\n",
      "Epoch 51/100\n",
      "1788/1788 [==============================] - 1s 308us/step - loss: 0.5412 - accuracy: 0.7226\n",
      "Epoch 52/100\n",
      "1788/1788 [==============================] - 0s 269us/step - loss: 0.5407 - accuracy: 0.7204\n",
      "Epoch 53/100\n",
      "1788/1788 [==============================] - 0s 220us/step - loss: 0.5403 - accuracy: 0.7220\n",
      "Epoch 54/100\n",
      "1788/1788 [==============================] - 1s 292us/step - loss: 0.5398 - accuracy: 0.7237\n",
      "Epoch 55/100\n",
      "1788/1788 [==============================] - 1s 304us/step - loss: 0.5394 - accuracy: 0.7248\n",
      "Epoch 56/100\n",
      "1788/1788 [==============================] - 1s 301us/step - loss: 0.5386 - accuracy: 0.7265\n",
      "Epoch 57/100\n",
      "1788/1788 [==============================] - 1s 306us/step - loss: 0.5383 - accuracy: 0.7237\n",
      "Epoch 58/100\n",
      "1788/1788 [==============================] - 1s 304us/step - loss: 0.5379 - accuracy: 0.7226\n",
      "Epoch 59/100\n",
      "1788/1788 [==============================] - 1s 309us/step - loss: 0.5375 - accuracy: 0.7287\n",
      "Epoch 60/100\n",
      "1788/1788 [==============================] - 1s 313us/step - loss: 0.5370 - accuracy: 0.7287\n",
      "Epoch 61/100\n",
      "1788/1788 [==============================] - 1s 306us/step - loss: 0.5365 - accuracy: 0.7260\n",
      "Epoch 62/100\n",
      "1788/1788 [==============================] - 1s 306us/step - loss: 0.5359 - accuracy: 0.7271\n",
      "Epoch 63/100\n",
      "1788/1788 [==============================] - 1s 306us/step - loss: 0.5357 - accuracy: 0.7260\n",
      "Epoch 64/100\n",
      "1788/1788 [==============================] - 1s 301us/step - loss: 0.5354 - accuracy: 0.7265\n",
      "Epoch 65/100\n",
      "1788/1788 [==============================] - 1s 305us/step - loss: 0.5351 - accuracy: 0.7254\n",
      "Epoch 66/100\n",
      "1788/1788 [==============================] - 1s 305us/step - loss: 0.5348 - accuracy: 0.7243\n",
      "Epoch 67/100\n",
      "1788/1788 [==============================] - 1s 305us/step - loss: 0.5344 - accuracy: 0.7248\n",
      "Epoch 68/100\n",
      "1788/1788 [==============================] - 1s 311us/step - loss: 0.5342 - accuracy: 0.7254\n",
      "Epoch 69/100\n",
      "1788/1788 [==============================] - 1s 308us/step - loss: 0.5338 - accuracy: 0.7254\n",
      "Epoch 70/100\n",
      "1788/1788 [==============================] - 1s 306us/step - loss: 0.5337 - accuracy: 0.7237\n",
      "Epoch 71/100\n",
      "1788/1788 [==============================] - 1s 310us/step - loss: 0.5335 - accuracy: 0.7220\n",
      "Epoch 72/100\n",
      "1788/1788 [==============================] - 1s 307us/step - loss: 0.5334 - accuracy: 0.7243\n",
      "Epoch 73/100\n",
      "1788/1788 [==============================] - 1s 309us/step - loss: 0.5330 - accuracy: 0.7248\n",
      "Epoch 74/100\n",
      "1788/1788 [==============================] - 1s 309us/step - loss: 0.5327 - accuracy: 0.7232\n",
      "Epoch 75/100\n",
      "1788/1788 [==============================] - 1s 304us/step - loss: 0.5326 - accuracy: 0.7220\n",
      "Epoch 76/100\n",
      "1788/1788 [==============================] - 1s 306us/step - loss: 0.5325 - accuracy: 0.7248\n",
      "Epoch 77/100\n",
      "1788/1788 [==============================] - 1s 325us/step - loss: 0.5324 - accuracy: 0.7215\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1788/1788 [==============================] - 1s 303us/step - loss: 0.5321 - accuracy: 0.7232\n",
      "Epoch 79/100\n",
      "1788/1788 [==============================] - 1s 305us/step - loss: 0.5320 - accuracy: 0.7220\n",
      "Epoch 80/100\n",
      "1788/1788 [==============================] - 1s 305us/step - loss: 0.5320 - accuracy: 0.7232\n",
      "Epoch 81/100\n",
      "1788/1788 [==============================] - 1s 302us/step - loss: 0.5321 - accuracy: 0.7209\n",
      "Epoch 82/100\n",
      "1788/1788 [==============================] - 1s 304us/step - loss: 0.5317 - accuracy: 0.7237\n",
      "Epoch 83/100\n",
      "1788/1788 [==============================] - 1s 303us/step - loss: 0.5316 - accuracy: 0.7215\n",
      "Epoch 84/100\n",
      "1788/1788 [==============================] - 1s 313us/step - loss: 0.5314 - accuracy: 0.7204\n",
      "Epoch 85/100\n",
      "1788/1788 [==============================] - 1s 298us/step - loss: 0.5314 - accuracy: 0.7192\n",
      "Epoch 86/100\n",
      "1788/1788 [==============================] - 1s 303us/step - loss: 0.5314 - accuracy: 0.7215\n",
      "Epoch 87/100\n",
      "1788/1788 [==============================] - 1s 302us/step - loss: 0.5312 - accuracy: 0.7204\n",
      "Epoch 88/100\n",
      "1788/1788 [==============================] - 1s 306us/step - loss: 0.5310 - accuracy: 0.7181\n",
      "Epoch 89/100\n",
      "1788/1788 [==============================] - 1s 307us/step - loss: 0.5310 - accuracy: 0.7192\n",
      "Epoch 90/100\n",
      "1788/1788 [==============================] - 1s 304us/step - loss: 0.5310 - accuracy: 0.7187\n",
      "Epoch 91/100\n",
      "1788/1788 [==============================] - 1s 304us/step - loss: 0.5310 - accuracy: 0.7192\n",
      "Epoch 92/100\n",
      "1788/1788 [==============================] - 1s 306us/step - loss: 0.5308 - accuracy: 0.7209\n",
      "Epoch 93/100\n",
      "1788/1788 [==============================] - 1s 303us/step - loss: 0.5308 - accuracy: 0.7232\n",
      "Epoch 94/100\n",
      "1788/1788 [==============================] - 1s 301us/step - loss: 0.5309 - accuracy: 0.7198\n",
      "Epoch 95/100\n",
      "1788/1788 [==============================] - 1s 303us/step - loss: 0.5305 - accuracy: 0.7204\n",
      "Epoch 96/100\n",
      "1788/1788 [==============================] - 1s 305us/step - loss: 0.5305 - accuracy: 0.7248\n",
      "Epoch 97/100\n",
      "1788/1788 [==============================] - 1s 302us/step - loss: 0.5304 - accuracy: 0.7220\n",
      "Epoch 98/100\n",
      "1788/1788 [==============================] - 1s 309us/step - loss: 0.5305 - accuracy: 0.7215\n",
      "Epoch 99/100\n",
      "1788/1788 [==============================] - 1s 301us/step - loss: 0.5304 - accuracy: 0.7220\n",
      "Epoch 100/100\n",
      "1788/1788 [==============================] - 1s 306us/step - loss: 0.5305 - accuracy: 0.7187\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x22efc552dc8>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the ANN to the Training set\n",
    "cnn2.fit(X_train, y_train, batch_size = 10, nb_epoch = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred7 = cnn2.predict(X_test)\n",
    "y_pred7 = (y_pred7 > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[194  54]\n",
      " [ 73 126]]\n"
     ]
    }
   ],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm2 = confusion_matrix(y_test, y_pred7)\n",
    "print(cm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\38095\\anaconda3\\envs\\labvika\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=4, units=3, kernel_initializer=\"uniform\")`\n",
      "  \"\"\"\n",
      "C:\\Users\\38095\\anaconda3\\envs\\labvika\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=2, kernel_initializer=\"uniform\")`\n",
      "  \n",
      "C:\\Users\\38095\\anaconda3\\envs\\labvika\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "# Initialising the ANN 4-3-2-1\n",
    "cnn3 = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "cnn3.add(Dense(output_dim = 3, init = 'uniform', activation = 'relu', input_dim = 4))\n",
    "\n",
    "# Adding the hidden layer\n",
    "cnn3.add(Dense(output_dim = 2, init = 'uniform', activation = 'relu'))\n",
    "\n",
    "# Adding the output layer\n",
    "cnn3.add(Dense(output_dim = 1, init = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "# Compiling the ANN\n",
    "cnn3.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\38095\\anaconda3\\envs\\labvika\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1788/1788 [==============================] - 0s 179us/step - loss: 0.6890 - accuracy: 0.5660\n",
      "Epoch 2/100\n",
      "1788/1788 [==============================] - 0s 133us/step - loss: 0.6586 - accuracy: 0.5660\n",
      "Epoch 3/100\n",
      "1788/1788 [==============================] - 0s 130us/step - loss: 0.6190 - accuracy: 0.5660\n",
      "Epoch 4/100\n",
      "1788/1788 [==============================] - 0s 158us/step - loss: 0.5999 - accuracy: 0.6281\n",
      "Epoch 5/100\n",
      "1788/1788 [==============================] - 0s 145us/step - loss: 0.5916 - accuracy: 0.6823\n",
      "Epoch 6/100\n",
      "1788/1788 [==============================] - 0s 133us/step - loss: 0.5861 - accuracy: 0.6868\n",
      "Epoch 7/100\n",
      "1788/1788 [==============================] - 0s 134us/step - loss: 0.5817 - accuracy: 0.6935\n",
      "Epoch 8/100\n",
      "1788/1788 [==============================] - 0s 133us/step - loss: 0.5781 - accuracy: 0.6997\n",
      "Epoch 9/100\n",
      "1788/1788 [==============================] - 0s 133us/step - loss: 0.5748 - accuracy: 0.7002\n",
      "Epoch 10/100\n",
      "1788/1788 [==============================] - 0s 147us/step - loss: 0.5715 - accuracy: 0.7075\n",
      "Epoch 11/100\n",
      "1788/1788 [==============================] - 0s 155us/step - loss: 0.5682 - accuracy: 0.7092\n",
      "Epoch 12/100\n",
      "1788/1788 [==============================] - 0s 135us/step - loss: 0.5646 - accuracy: 0.7164\n",
      "Epoch 13/100\n",
      "1788/1788 [==============================] - 0s 135us/step - loss: 0.5607 - accuracy: 0.7181\n",
      "Epoch 14/100\n",
      "1788/1788 [==============================] - 0s 150us/step - loss: 0.5577 - accuracy: 0.7226\n",
      "Epoch 15/100\n",
      "1788/1788 [==============================] - 0s 149us/step - loss: 0.5547 - accuracy: 0.7237\n",
      "Epoch 16/100\n",
      "1788/1788 [==============================] - 0s 149us/step - loss: 0.5520 - accuracy: 0.7282\n",
      "Epoch 17/100\n",
      "1788/1788 [==============================] - 0s 141us/step - loss: 0.5494 - accuracy: 0.7299\n",
      "Epoch 18/100\n",
      "1788/1788 [==============================] - 0s 171us/step - loss: 0.5470 - accuracy: 0.7315\n",
      "Epoch 19/100\n",
      "1788/1788 [==============================] - 0s 170us/step - loss: 0.5451 - accuracy: 0.7304\n",
      "Epoch 20/100\n",
      "1788/1788 [==============================] - 0s 144us/step - loss: 0.5434 - accuracy: 0.7315\n",
      "Epoch 21/100\n",
      "1788/1788 [==============================] - 0s 158us/step - loss: 0.5419 - accuracy: 0.7310\n",
      "Epoch 22/100\n",
      "1788/1788 [==============================] - 0s 156us/step - loss: 0.5406 - accuracy: 0.7327\n",
      "Epoch 23/100\n",
      "1788/1788 [==============================] - 0s 148us/step - loss: 0.5391 - accuracy: 0.7332\n",
      "Epoch 24/100\n",
      "1788/1788 [==============================] - 0s 161us/step - loss: 0.5379 - accuracy: 0.7287\n",
      "Epoch 25/100\n",
      "1788/1788 [==============================] - 0s 161us/step - loss: 0.5368 - accuracy: 0.7287\n",
      "Epoch 26/100\n",
      "1788/1788 [==============================] - 0s 166us/step - loss: 0.5357 - accuracy: 0.7315\n",
      "Epoch 27/100\n",
      "1788/1788 [==============================] - 0s 179us/step - loss: 0.5350 - accuracy: 0.7287\n",
      "Epoch 28/100\n",
      "1788/1788 [==============================] - 0s 156us/step - loss: 0.5342 - accuracy: 0.7293\n",
      "Epoch 29/100\n",
      "1788/1788 [==============================] - 0s 168us/step - loss: 0.5335 - accuracy: 0.7260\n",
      "Epoch 30/100\n",
      "1788/1788 [==============================] - 0s 153us/step - loss: 0.5327 - accuracy: 0.7260\n",
      "Epoch 31/100\n",
      "1788/1788 [==============================] - 0s 137us/step - loss: 0.5323 - accuracy: 0.7248\n",
      "Epoch 32/100\n",
      "1788/1788 [==============================] - 0s 147us/step - loss: 0.5320 - accuracy: 0.7260\n",
      "Epoch 33/100\n",
      "1788/1788 [==============================] - 0s 147us/step - loss: 0.5316 - accuracy: 0.7237\n",
      "Epoch 34/100\n",
      "1788/1788 [==============================] - 0s 135us/step - loss: 0.5311 - accuracy: 0.7260\n",
      "Epoch 35/100\n",
      "1788/1788 [==============================] - 0s 139us/step - loss: 0.5309 - accuracy: 0.7248\n",
      "Epoch 36/100\n",
      "1788/1788 [==============================] - 0s 137us/step - loss: 0.5306 - accuracy: 0.7248\n",
      "Epoch 37/100\n",
      "1788/1788 [==============================] - 0s 146us/step - loss: 0.5305 - accuracy: 0.7243\n",
      "Epoch 38/100\n",
      "1788/1788 [==============================] - 0s 130us/step - loss: 0.5300 - accuracy: 0.7237\n",
      "Epoch 39/100\n",
      "1788/1788 [==============================] - 0s 132us/step - loss: 0.5297 - accuracy: 0.7271\n",
      "Epoch 40/100\n",
      "1788/1788 [==============================] - 0s 132us/step - loss: 0.5298 - accuracy: 0.7254\n",
      "Epoch 41/100\n",
      "1788/1788 [==============================] - 0s 168us/step - loss: 0.5295 - accuracy: 0.7254\n",
      "Epoch 42/100\n",
      "1788/1788 [==============================] - 0s 153us/step - loss: 0.5292 - accuracy: 0.7276\n",
      "Epoch 43/100\n",
      "1788/1788 [==============================] - 0s 143us/step - loss: 0.5293 - accuracy: 0.7243\n",
      "Epoch 44/100\n",
      "1788/1788 [==============================] - 0s 138us/step - loss: 0.5291 - accuracy: 0.7282\n",
      "Epoch 45/100\n",
      "1788/1788 [==============================] - 0s 137us/step - loss: 0.5288 - accuracy: 0.7282\n",
      "Epoch 46/100\n",
      "1788/1788 [==============================] - 0s 131us/step - loss: 0.5291 - accuracy: 0.7237\n",
      "Epoch 47/100\n",
      "1788/1788 [==============================] - 0s 127us/step - loss: 0.5288 - accuracy: 0.7287\n",
      "Epoch 48/100\n",
      "1788/1788 [==============================] - 0s 136us/step - loss: 0.5284 - accuracy: 0.7260\n",
      "Epoch 49/100\n",
      "1788/1788 [==============================] - 0s 136us/step - loss: 0.5289 - accuracy: 0.7276\n",
      "Epoch 50/100\n",
      "1788/1788 [==============================] - 0s 134us/step - loss: 0.5284 - accuracy: 0.7276\n",
      "Epoch 51/100\n",
      "1788/1788 [==============================] - 0s 157us/step - loss: 0.5282 - accuracy: 0.7282\n",
      "Epoch 52/100\n",
      "1788/1788 [==============================] - 0s 137us/step - loss: 0.5287 - accuracy: 0.7282\n",
      "Epoch 53/100\n",
      "1788/1788 [==============================] - 0s 135us/step - loss: 0.5285 - accuracy: 0.7315\n",
      "Epoch 54/100\n",
      "1788/1788 [==============================] - 0s 144us/step - loss: 0.5282 - accuracy: 0.7282\n",
      "Epoch 55/100\n",
      "1788/1788 [==============================] - 0s 136us/step - loss: 0.5281 - accuracy: 0.7271\n",
      "Epoch 56/100\n",
      "1788/1788 [==============================] - 0s 132us/step - loss: 0.5280 - accuracy: 0.7271\n",
      "Epoch 57/100\n",
      "1788/1788 [==============================] - 0s 134us/step - loss: 0.5280 - accuracy: 0.7287\n",
      "Epoch 58/100\n",
      "1788/1788 [==============================] - 0s 137us/step - loss: 0.5281 - accuracy: 0.7276\n",
      "Epoch 59/100\n",
      "1788/1788 [==============================] - 0s 146us/step - loss: 0.5279 - accuracy: 0.7271\n",
      "Epoch 60/100\n",
      "1788/1788 [==============================] - 0s 131us/step - loss: 0.5277 - accuracy: 0.7265\n",
      "Epoch 61/100\n",
      "1788/1788 [==============================] - 0s 134us/step - loss: 0.5276 - accuracy: 0.7265\n",
      "Epoch 62/100\n",
      "1788/1788 [==============================] - 0s 128us/step - loss: 0.5280 - accuracy: 0.7276\n",
      "Epoch 63/100\n",
      "1788/1788 [==============================] - 0s 135us/step - loss: 0.5277 - accuracy: 0.7282\n",
      "Epoch 64/100\n",
      "1788/1788 [==============================] - 0s 132us/step - loss: 0.5278 - accuracy: 0.7271\n",
      "Epoch 65/100\n",
      "1788/1788 [==============================] - 0s 135us/step - loss: 0.5276 - accuracy: 0.7276\n",
      "Epoch 66/100\n",
      "1788/1788 [==============================] - 0s 138us/step - loss: 0.5276 - accuracy: 0.7276\n",
      "Epoch 67/100\n",
      "1788/1788 [==============================] - 0s 127us/step - loss: 0.5273 - accuracy: 0.7282\n",
      "Epoch 68/100\n",
      "1788/1788 [==============================] - 0s 155us/step - loss: 0.5274 - accuracy: 0.7287\n",
      "Epoch 69/100\n",
      "1788/1788 [==============================] - 0s 150us/step - loss: 0.5274 - accuracy: 0.7293\n",
      "Epoch 70/100\n",
      "1788/1788 [==============================] - 0s 170us/step - loss: 0.5272 - accuracy: 0.7315\n",
      "Epoch 71/100\n",
      "1788/1788 [==============================] - 0s 156us/step - loss: 0.5271 - accuracy: 0.7287\n",
      "Epoch 72/100\n",
      "1788/1788 [==============================] - 0s 148us/step - loss: 0.5272 - accuracy: 0.7293\n",
      "Epoch 73/100\n",
      "1788/1788 [==============================] - 0s 172us/step - loss: 0.5270 - accuracy: 0.7287\n",
      "Epoch 74/100\n",
      "1788/1788 [==============================] - 0s 155us/step - loss: 0.5268 - accuracy: 0.7304\n",
      "Epoch 75/100\n",
      "1788/1788 [==============================] - 0s 134us/step - loss: 0.5268 - accuracy: 0.7293\n",
      "Epoch 76/100\n",
      "1788/1788 [==============================] - 0s 132us/step - loss: 0.5271 - accuracy: 0.7271\n",
      "Epoch 77/100\n",
      "1788/1788 [==============================] - 0s 152us/step - loss: 0.5268 - accuracy: 0.7293\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1788/1788 [==============================] - 0s 143us/step - loss: 0.5271 - accuracy: 0.7304\n",
      "Epoch 79/100\n",
      "1788/1788 [==============================] - 0s 160us/step - loss: 0.5267 - accuracy: 0.7310\n",
      "Epoch 80/100\n",
      "1788/1788 [==============================] - 0s 149us/step - loss: 0.5267 - accuracy: 0.7327\n",
      "Epoch 81/100\n",
      "1788/1788 [==============================] - 0s 140us/step - loss: 0.5269 - accuracy: 0.7310\n",
      "Epoch 82/100\n",
      "1788/1788 [==============================] - 0s 154us/step - loss: 0.5264 - accuracy: 0.7304\n",
      "Epoch 83/100\n",
      "1788/1788 [==============================] - 0s 182us/step - loss: 0.5267 - accuracy: 0.7287\n",
      "Epoch 84/100\n",
      "1788/1788 [==============================] - 0s 148us/step - loss: 0.5264 - accuracy: 0.7315\n",
      "Epoch 85/100\n",
      "1788/1788 [==============================] - 0s 157us/step - loss: 0.5266 - accuracy: 0.7310\n",
      "Epoch 86/100\n",
      "1788/1788 [==============================] - 0s 158us/step - loss: 0.5267 - accuracy: 0.7293\n",
      "Epoch 87/100\n",
      "1788/1788 [==============================] - 0s 177us/step - loss: 0.5265 - accuracy: 0.7287\n",
      "Epoch 88/100\n",
      "1788/1788 [==============================] - 0s 178us/step - loss: 0.5264 - accuracy: 0.7321\n",
      "Epoch 89/100\n",
      "1788/1788 [==============================] - 0s 151us/step - loss: 0.5267 - accuracy: 0.7299\n",
      "Epoch 90/100\n",
      "1788/1788 [==============================] - 0s 168us/step - loss: 0.5265 - accuracy: 0.7299\n",
      "Epoch 91/100\n",
      "1788/1788 [==============================] - 0s 162us/step - loss: 0.5266 - accuracy: 0.7315\n",
      "Epoch 92/100\n",
      "1788/1788 [==============================] - 0s 149us/step - loss: 0.5266 - accuracy: 0.7293\n",
      "Epoch 93/100\n",
      "1788/1788 [==============================] - 0s 161us/step - loss: 0.5263 - accuracy: 0.7287\n",
      "Epoch 94/100\n",
      "1788/1788 [==============================] - 0s 159us/step - loss: 0.5266 - accuracy: 0.7282\n",
      "Epoch 95/100\n",
      "1788/1788 [==============================] - 0s 140us/step - loss: 0.5262 - accuracy: 0.7293\n",
      "Epoch 96/100\n",
      "1788/1788 [==============================] - 0s 157us/step - loss: 0.5263 - accuracy: 0.7260\n",
      "Epoch 97/100\n",
      "1788/1788 [==============================] - 0s 127us/step - loss: 0.5264 - accuracy: 0.7265\n",
      "Epoch 98/100\n",
      "1788/1788 [==============================] - 0s 135us/step - loss: 0.5262 - accuracy: 0.7271\n",
      "Epoch 99/100\n",
      "1788/1788 [==============================] - 0s 149us/step - loss: 0.5262 - accuracy: 0.7299\n",
      "Epoch 100/100\n",
      "1788/1788 [==============================] - 0s 157us/step - loss: 0.5263 - accuracy: 0.7287\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x22efdb94188>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the ANN to the Training set\n",
    "cnn3.fit(X_train, y_train, batch_size = 10, nb_epoch = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred8 = cnn3.predict(X_test)\n",
    "y_pred8 = (y_pred8 > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[192  56]\n",
      " [ 66 133]]\n"
     ]
    }
   ],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm3 = confusion_matrix(y_test, y_pred8)\n",
    "print(cm3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\38095\\anaconda3\\envs\\labvika\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=4, units=2, kernel_initializer=\"uniform\")`\n",
      "  \"\"\"\n",
      "C:\\Users\\38095\\anaconda3\\envs\\labvika\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=2, kernel_initializer=\"uniform\")`\n",
      "  \n",
      "C:\\Users\\38095\\anaconda3\\envs\\labvika\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "# Initialising the ANN 4-2-2-1\n",
    "cnn4 = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "cnn4.add(Dense(output_dim = 2, init = 'uniform', activation = 'relu', input_dim = 4))\n",
    "\n",
    "# Adding the hidden layer\n",
    "cnn4.add(Dense(output_dim = 2, init = 'uniform', activation = 'relu'))\n",
    "\n",
    "# Adding the output layer\n",
    "cnn4.add(Dense(output_dim = 1, init = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "# Compiling the ANN\n",
    "cnn4.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\38095\\anaconda3\\envs\\labvika\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1788/1788 [==============================] - 0s 195us/step - loss: 0.6892 - accuracy: 0.5660\n",
      "Epoch 2/100\n",
      "1788/1788 [==============================] - 0s 137us/step - loss: 0.6529 - accuracy: 0.5660\n",
      "Epoch 3/100\n",
      "1788/1788 [==============================] - 0s 158us/step - loss: 0.6102 - accuracy: 0.5677\n",
      "Epoch 4/100\n",
      "1788/1788 [==============================] - 0s 149us/step - loss: 0.5923 - accuracy: 0.6902\n",
      "Epoch 5/100\n",
      "1788/1788 [==============================] - 0s 137us/step - loss: 0.5842 - accuracy: 0.7036\n",
      "Epoch 6/100\n",
      "1788/1788 [==============================] - 0s 150us/step - loss: 0.5774 - accuracy: 0.7103\n",
      "Epoch 7/100\n",
      "1788/1788 [==============================] - 0s 146us/step - loss: 0.5717 - accuracy: 0.7153\n",
      "Epoch 8/100\n",
      "1788/1788 [==============================] - 0s 163us/step - loss: 0.5663 - accuracy: 0.7181\n",
      "Epoch 9/100\n",
      "1788/1788 [==============================] - 0s 147us/step - loss: 0.5619 - accuracy: 0.7209\n",
      "Epoch 10/100\n",
      "1788/1788 [==============================] - 0s 151us/step - loss: 0.5577 - accuracy: 0.7248\n",
      "Epoch 11/100\n",
      "1788/1788 [==============================] - 0s 145us/step - loss: 0.5541 - accuracy: 0.7271\n",
      "Epoch 12/100\n",
      "1788/1788 [==============================] - 0s 154us/step - loss: 0.5512 - accuracy: 0.7287\n",
      "Epoch 13/100\n",
      "1788/1788 [==============================] - 0s 177us/step - loss: 0.5486 - accuracy: 0.7299\n",
      "Epoch 14/100\n",
      "1788/1788 [==============================] - 0s 189us/step - loss: 0.5458 - accuracy: 0.7327\n",
      "Epoch 15/100\n",
      "1788/1788 [==============================] - 0s 168us/step - loss: 0.5438 - accuracy: 0.7293\n",
      "Epoch 16/100\n",
      "1788/1788 [==============================] - 0s 164us/step - loss: 0.5421 - accuracy: 0.7327\n",
      "Epoch 17/100\n",
      "1788/1788 [==============================] - 0s 161us/step - loss: 0.5402 - accuracy: 0.7304\n",
      "Epoch 18/100\n",
      "1788/1788 [==============================] - 0s 181us/step - loss: 0.5388 - accuracy: 0.7276\n",
      "Epoch 19/100\n",
      "1788/1788 [==============================] - 0s 169us/step - loss: 0.5373 - accuracy: 0.7299\n",
      "Epoch 20/100\n",
      "1788/1788 [==============================] - 0s 183us/step - loss: 0.5364 - accuracy: 0.7293\n",
      "Epoch 21/100\n",
      "1788/1788 [==============================] - 0s 158us/step - loss: 0.5358 - accuracy: 0.7248\n",
      "Epoch 22/100\n",
      "1788/1788 [==============================] - 0s 175us/step - loss: 0.5346 - accuracy: 0.7315\n",
      "Epoch 23/100\n",
      "1788/1788 [==============================] - 0s 167us/step - loss: 0.5342 - accuracy: 0.7232\n",
      "Epoch 24/100\n",
      "1788/1788 [==============================] - 0s 177us/step - loss: 0.5334 - accuracy: 0.7287\n",
      "Epoch 25/100\n",
      "1788/1788 [==============================] - 0s 176us/step - loss: 0.5330 - accuracy: 0.7327\n",
      "Epoch 26/100\n",
      "1788/1788 [==============================] - 0s 179us/step - loss: 0.5325 - accuracy: 0.7271\n",
      "Epoch 27/100\n",
      "1788/1788 [==============================] - 0s 186us/step - loss: 0.5323 - accuracy: 0.7276\n",
      "Epoch 28/100\n",
      "1788/1788 [==============================] - 0s 226us/step - loss: 0.5318 - accuracy: 0.7271\n",
      "Epoch 29/100\n",
      "1788/1788 [==============================] - 0s 182us/step - loss: 0.5313 - accuracy: 0.7260\n",
      "Epoch 30/100\n",
      "1788/1788 [==============================] - 0s 180us/step - loss: 0.5314 - accuracy: 0.7248\n",
      "Epoch 31/100\n",
      "1788/1788 [==============================] - 0s 141us/step - loss: 0.5308 - accuracy: 0.7265\n",
      "Epoch 32/100\n",
      "1788/1788 [==============================] - 0s 148us/step - loss: 0.5306 - accuracy: 0.7265\n",
      "Epoch 33/100\n",
      "1788/1788 [==============================] - 0s 186us/step - loss: 0.5302 - accuracy: 0.7327\n",
      "Epoch 34/100\n",
      "1788/1788 [==============================] - 0s 181us/step - loss: 0.5302 - accuracy: 0.7299\n",
      "Epoch 35/100\n",
      "1788/1788 [==============================] - 0s 152us/step - loss: 0.5303 - accuracy: 0.7304\n",
      "Epoch 36/100\n",
      "1788/1788 [==============================] - 0s 165us/step - loss: 0.5301 - accuracy: 0.7310\n",
      "Epoch 37/100\n",
      "1788/1788 [==============================] - 0s 171us/step - loss: 0.5298 - accuracy: 0.7282\n",
      "Epoch 38/100\n",
      "1788/1788 [==============================] - 0s 153us/step - loss: 0.5298 - accuracy: 0.7265\n",
      "Epoch 39/100\n",
      "1788/1788 [==============================] - 0s 142us/step - loss: 0.5298 - accuracy: 0.7287\n",
      "Epoch 40/100\n",
      "1788/1788 [==============================] - 0s 155us/step - loss: 0.5293 - accuracy: 0.7271\n",
      "Epoch 41/100\n",
      "1788/1788 [==============================] - 0s 143us/step - loss: 0.5291 - accuracy: 0.7287\n",
      "Epoch 42/100\n",
      "1788/1788 [==============================] - 0s 131us/step - loss: 0.5290 - accuracy: 0.7293\n",
      "Epoch 43/100\n",
      "1788/1788 [==============================] - 0s 149us/step - loss: 0.5293 - accuracy: 0.7299\n",
      "Epoch 44/100\n",
      "1788/1788 [==============================] - 0s 151us/step - loss: 0.5285 - accuracy: 0.7287\n",
      "Epoch 45/100\n",
      "1788/1788 [==============================] - 0s 159us/step - loss: 0.5288 - accuracy: 0.7254\n",
      "Epoch 46/100\n",
      "1788/1788 [==============================] - 0s 139us/step - loss: 0.5291 - accuracy: 0.7299\n",
      "Epoch 47/100\n",
      "1788/1788 [==============================] - 0s 145us/step - loss: 0.5286 - accuracy: 0.7299\n",
      "Epoch 48/100\n",
      "1788/1788 [==============================] - 0s 132us/step - loss: 0.5281 - accuracy: 0.7260\n",
      "Epoch 49/100\n",
      "1788/1788 [==============================] - 0s 132us/step - loss: 0.5283 - accuracy: 0.7310\n",
      "Epoch 50/100\n",
      "1788/1788 [==============================] - 0s 156us/step - loss: 0.5284 - accuracy: 0.7299\n",
      "Epoch 51/100\n",
      "1788/1788 [==============================] - 0s 142us/step - loss: 0.5284 - accuracy: 0.7304\n",
      "Epoch 52/100\n",
      "1788/1788 [==============================] - 0s 142us/step - loss: 0.5281 - accuracy: 0.7265\n",
      "Epoch 53/100\n",
      "1788/1788 [==============================] - 0s 132us/step - loss: 0.5282 - accuracy: 0.7276\n",
      "Epoch 54/100\n",
      "1788/1788 [==============================] - 0s 132us/step - loss: 0.5280 - accuracy: 0.7299\n",
      "Epoch 55/100\n",
      "1788/1788 [==============================] - 0s 143us/step - loss: 0.5281 - accuracy: 0.7282\n",
      "Epoch 56/100\n",
      "1788/1788 [==============================] - 0s 139us/step - loss: 0.5282 - accuracy: 0.7287\n",
      "Epoch 57/100\n",
      "1788/1788 [==============================] - 0s 140us/step - loss: 0.5278 - accuracy: 0.7293\n",
      "Epoch 58/100\n",
      "1788/1788 [==============================] - 0s 155us/step - loss: 0.5277 - accuracy: 0.7299\n",
      "Epoch 59/100\n",
      "1788/1788 [==============================] - 0s 140us/step - loss: 0.5277 - accuracy: 0.7310\n",
      "Epoch 60/100\n",
      "1788/1788 [==============================] - 0s 145us/step - loss: 0.5276 - accuracy: 0.7287\n",
      "Epoch 61/100\n",
      "1788/1788 [==============================] - 0s 145us/step - loss: 0.5276 - accuracy: 0.7276\n",
      "Epoch 62/100\n",
      "1788/1788 [==============================] - 0s 138us/step - loss: 0.5275 - accuracy: 0.7304\n",
      "Epoch 63/100\n",
      "1788/1788 [==============================] - 0s 139us/step - loss: 0.5272 - accuracy: 0.7287\n",
      "Epoch 64/100\n",
      "1788/1788 [==============================] - 0s 129us/step - loss: 0.5276 - accuracy: 0.7276\n",
      "Epoch 65/100\n",
      "1788/1788 [==============================] - 0s 135us/step - loss: 0.5272 - accuracy: 0.7293\n",
      "Epoch 66/100\n",
      "1788/1788 [==============================] - 0s 133us/step - loss: 0.5272 - accuracy: 0.7287\n",
      "Epoch 67/100\n",
      "1788/1788 [==============================] - 0s 137us/step - loss: 0.5273 - accuracy: 0.7293\n",
      "Epoch 68/100\n",
      "1788/1788 [==============================] - 0s 143us/step - loss: 0.5273 - accuracy: 0.7332\n",
      "Epoch 69/100\n",
      "1788/1788 [==============================] - 0s 131us/step - loss: 0.5272 - accuracy: 0.7299\n",
      "Epoch 70/100\n",
      "1788/1788 [==============================] - 0s 145us/step - loss: 0.5273 - accuracy: 0.7299\n",
      "Epoch 71/100\n",
      "1788/1788 [==============================] - 0s 133us/step - loss: 0.5271 - accuracy: 0.7304\n",
      "Epoch 72/100\n",
      "1788/1788 [==============================] - 0s 132us/step - loss: 0.5272 - accuracy: 0.7293\n",
      "Epoch 73/100\n",
      "1788/1788 [==============================] - 0s 136us/step - loss: 0.5269 - accuracy: 0.7332\n",
      "Epoch 74/100\n",
      "1788/1788 [==============================] - 0s 131us/step - loss: 0.5269 - accuracy: 0.7321\n",
      "Epoch 75/100\n",
      "1788/1788 [==============================] - 0s 135us/step - loss: 0.5270 - accuracy: 0.7304\n",
      "Epoch 76/100\n",
      "1788/1788 [==============================] - 0s 140us/step - loss: 0.5268 - accuracy: 0.7299\n",
      "Epoch 77/100\n",
      "1788/1788 [==============================] - 0s 133us/step - loss: 0.5270 - accuracy: 0.7310\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1788/1788 [==============================] - 0s 139us/step - loss: 0.5268 - accuracy: 0.7304\n",
      "Epoch 79/100\n",
      "1788/1788 [==============================] - 0s 134us/step - loss: 0.5267 - accuracy: 0.7310\n",
      "Epoch 80/100\n",
      "1788/1788 [==============================] - 0s 126us/step - loss: 0.5268 - accuracy: 0.7287\n",
      "Epoch 81/100\n",
      "1788/1788 [==============================] - 0s 136us/step - loss: 0.5271 - accuracy: 0.7293\n",
      "Epoch 82/100\n",
      "1788/1788 [==============================] - 0s 128us/step - loss: 0.5268 - accuracy: 0.7315\n",
      "Epoch 83/100\n",
      "1788/1788 [==============================] - 0s 133us/step - loss: 0.5267 - accuracy: 0.7304\n",
      "Epoch 84/100\n",
      "1788/1788 [==============================] - 0s 138us/step - loss: 0.5267 - accuracy: 0.7310\n",
      "Epoch 85/100\n",
      "1788/1788 [==============================] - 0s 135us/step - loss: 0.5267 - accuracy: 0.7315\n",
      "Epoch 86/100\n",
      "1788/1788 [==============================] - 0s 135us/step - loss: 0.5270 - accuracy: 0.7287\n",
      "Epoch 87/100\n",
      "1788/1788 [==============================] - 0s 132us/step - loss: 0.5264 - accuracy: 0.7315\n",
      "Epoch 88/100\n",
      "1788/1788 [==============================] - 0s 129us/step - loss: 0.5263 - accuracy: 0.7310\n",
      "Epoch 89/100\n",
      "1788/1788 [==============================] - 0s 126us/step - loss: 0.5265 - accuracy: 0.7287\n",
      "Epoch 90/100\n",
      "1788/1788 [==============================] - 0s 148us/step - loss: 0.5267 - accuracy: 0.7304\n",
      "Epoch 91/100\n",
      "1788/1788 [==============================] - 0s 148us/step - loss: 0.5266 - accuracy: 0.7304\n",
      "Epoch 92/100\n",
      "1788/1788 [==============================] - 0s 145us/step - loss: 0.5265 - accuracy: 0.7310\n",
      "Epoch 93/100\n",
      "1788/1788 [==============================] - 0s 134us/step - loss: 0.5265 - accuracy: 0.7282\n",
      "Epoch 94/100\n",
      "1788/1788 [==============================] - 0s 128us/step - loss: 0.5263 - accuracy: 0.7304\n",
      "Epoch 95/100\n",
      "1788/1788 [==============================] - 0s 134us/step - loss: 0.5267 - accuracy: 0.7304\n",
      "Epoch 96/100\n",
      "1788/1788 [==============================] - 0s 134us/step - loss: 0.5263 - accuracy: 0.7304\n",
      "Epoch 97/100\n",
      "1788/1788 [==============================] - 0s 145us/step - loss: 0.5265 - accuracy: 0.7293\n",
      "Epoch 98/100\n",
      "1788/1788 [==============================] - 0s 146us/step - loss: 0.5265 - accuracy: 0.7321\n",
      "Epoch 99/100\n",
      "1788/1788 [==============================] - 0s 140us/step - loss: 0.5265 - accuracy: 0.7293\n",
      "Epoch 100/100\n",
      "1788/1788 [==============================] - 0s 136us/step - loss: 0.5262 - accuracy: 0.7304\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x22efdec2b48>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the ANN to the Training set\n",
    "cnn4.fit(X_train, y_train, batch_size = 10, nb_epoch = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred9 = cnn4.predict(X_test)\n",
    "y_pred9 = (y_pred9 > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[189  59]\n",
      " [ 66 133]]\n"
     ]
    }
   ],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm4 = confusion_matrix(y_test, y_pred9)\n",
    "print(cm4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\38095\\anaconda3\\envs\\labvika\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=4, units=4, kernel_initializer=\"uniform\")`\n",
      "  \"\"\"\n",
      "C:\\Users\\38095\\anaconda3\\envs\\labvika\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Initialising the ANN 4-4-1\n",
    "cnn5 = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "cnn5.add(Dense(output_dim = 4, init = 'uniform', activation = 'relu', input_dim = 4))\n",
    "\n",
    "# Adding the output layer\n",
    "cnn5.add(Dense(output_dim = 1, init = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "# Compiling the ANN\n",
    "cnn5.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\38095\\anaconda3\\envs\\labvika\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1788/1788 [==============================] - 0s 176us/step - loss: 0.6856 - accuracy: 0.5839\n",
      "Epoch 2/100\n",
      "1788/1788 [==============================] - 0s 130us/step - loss: 0.6407 - accuracy: 0.6879\n",
      "Epoch 3/100\n",
      "1788/1788 [==============================] - 0s 128us/step - loss: 0.5932 - accuracy: 0.6963\n",
      "Epoch 4/100\n",
      "1788/1788 [==============================] - 0s 130us/step - loss: 0.5737 - accuracy: 0.6969\n",
      "Epoch 5/100\n",
      "1788/1788 [==============================] - 0s 148us/step - loss: 0.5666 - accuracy: 0.7075\n",
      "Epoch 6/100\n",
      "1788/1788 [==============================] - 0s 128us/step - loss: 0.5627 - accuracy: 0.7086\n",
      "Epoch 7/100\n",
      "1788/1788 [==============================] - 0s 130us/step - loss: 0.5598 - accuracy: 0.7114\n",
      "Epoch 8/100\n",
      "1788/1788 [==============================] - 0s 126us/step - loss: 0.5574 - accuracy: 0.7114\n",
      "Epoch 9/100\n",
      "1788/1788 [==============================] - 0s 139us/step - loss: 0.5542 - accuracy: 0.7086\n",
      "Epoch 10/100\n",
      "1788/1788 [==============================] - 0s 132us/step - loss: 0.5515 - accuracy: 0.7153\n",
      "Epoch 11/100\n",
      "1788/1788 [==============================] - 0s 132us/step - loss: 0.5481 - accuracy: 0.7142\n",
      "Epoch 12/100\n",
      "1788/1788 [==============================] - 0s 126us/step - loss: 0.5455 - accuracy: 0.7159\n",
      "Epoch 13/100\n",
      "1788/1788 [==============================] - 0s 123us/step - loss: 0.5430 - accuracy: 0.7181\n",
      "Epoch 14/100\n",
      "1788/1788 [==============================] - 0s 128us/step - loss: 0.5406 - accuracy: 0.7181\n",
      "Epoch 15/100\n",
      "1788/1788 [==============================] - 0s 131us/step - loss: 0.5389 - accuracy: 0.7220\n",
      "Epoch 16/100\n",
      "1788/1788 [==============================] - 0s 128us/step - loss: 0.5370 - accuracy: 0.7271\n",
      "Epoch 17/100\n",
      "1788/1788 [==============================] - 0s 135us/step - loss: 0.5356 - accuracy: 0.7248\n",
      "Epoch 18/100\n",
      "1788/1788 [==============================] - 0s 129us/step - loss: 0.5342 - accuracy: 0.7282\n",
      "Epoch 19/100\n",
      "1788/1788 [==============================] - 0s 126us/step - loss: 0.5328 - accuracy: 0.7271\n",
      "Epoch 20/100\n",
      "1788/1788 [==============================] - 0s 121us/step - loss: 0.5317 - accuracy: 0.7276\n",
      "Epoch 21/100\n",
      "1788/1788 [==============================] - 0s 127us/step - loss: 0.5308 - accuracy: 0.7265\n",
      "Epoch 22/100\n",
      "1788/1788 [==============================] - 0s 134us/step - loss: 0.5301 - accuracy: 0.7260\n",
      "Epoch 23/100\n",
      "1788/1788 [==============================] - 0s 149us/step - loss: 0.5293 - accuracy: 0.7315\n",
      "Epoch 24/100\n",
      "1788/1788 [==============================] - 0s 144us/step - loss: 0.5287 - accuracy: 0.7282\n",
      "Epoch 25/100\n",
      "1788/1788 [==============================] - 0s 134us/step - loss: 0.5279 - accuracy: 0.7293\n",
      "Epoch 26/100\n",
      "1788/1788 [==============================] - 0s 145us/step - loss: 0.5272 - accuracy: 0.7271\n",
      "Epoch 27/100\n",
      "1788/1788 [==============================] - 0s 160us/step - loss: 0.5267 - accuracy: 0.7276\n",
      "Epoch 28/100\n",
      "1788/1788 [==============================] - 0s 164us/step - loss: 0.5261 - accuracy: 0.7321\n",
      "Epoch 29/100\n",
      "1788/1788 [==============================] - 0s 154us/step - loss: 0.5257 - accuracy: 0.7260\n",
      "Epoch 30/100\n",
      "1788/1788 [==============================] - 0s 159us/step - loss: 0.5253 - accuracy: 0.7343\n",
      "Epoch 31/100\n",
      "1788/1788 [==============================] - 0s 171us/step - loss: 0.5250 - accuracy: 0.7293\n",
      "Epoch 32/100\n",
      "1788/1788 [==============================] - 0s 150us/step - loss: 0.5250 - accuracy: 0.7260\n",
      "Epoch 33/100\n",
      "1788/1788 [==============================] - 0s 166us/step - loss: 0.5246 - accuracy: 0.7299\n",
      "Epoch 34/100\n",
      "1788/1788 [==============================] - 0s 177us/step - loss: 0.5245 - accuracy: 0.7293\n",
      "Epoch 35/100\n",
      "1788/1788 [==============================] - 0s 159us/step - loss: 0.5239 - accuracy: 0.7276\n",
      "Epoch 36/100\n",
      "1788/1788 [==============================] - 0s 176us/step - loss: 0.5238 - accuracy: 0.7232\n",
      "Epoch 37/100\n",
      "1788/1788 [==============================] - 0s 162us/step - loss: 0.5235 - accuracy: 0.7276\n",
      "Epoch 38/100\n",
      "1788/1788 [==============================] - 0s 153us/step - loss: 0.5233 - accuracy: 0.7282\n",
      "Epoch 39/100\n",
      "1788/1788 [==============================] - 0s 165us/step - loss: 0.5235 - accuracy: 0.7237\n",
      "Epoch 40/100\n",
      "1788/1788 [==============================] - 0s 162us/step - loss: 0.5231 - accuracy: 0.7243\n",
      "Epoch 41/100\n",
      "1788/1788 [==============================] - 0s 131us/step - loss: 0.5230 - accuracy: 0.7243\n",
      "Epoch 42/100\n",
      "1788/1788 [==============================] - 0s 135us/step - loss: 0.5230 - accuracy: 0.7254\n",
      "Epoch 43/100\n",
      "1788/1788 [==============================] - 0s 140us/step - loss: 0.5227 - accuracy: 0.7248\n",
      "Epoch 44/100\n",
      "1788/1788 [==============================] - 0s 133us/step - loss: 0.5226 - accuracy: 0.7254\n",
      "Epoch 45/100\n",
      "1788/1788 [==============================] - 0s 128us/step - loss: 0.5226 - accuracy: 0.7254\n",
      "Epoch 46/100\n",
      "1788/1788 [==============================] - 0s 134us/step - loss: 0.5224 - accuracy: 0.7276\n",
      "Epoch 47/100\n",
      "1788/1788 [==============================] - 0s 154us/step - loss: 0.5223 - accuracy: 0.7254\n",
      "Epoch 48/100\n",
      "1788/1788 [==============================] - 0s 148us/step - loss: 0.5224 - accuracy: 0.7254\n",
      "Epoch 49/100\n",
      "1788/1788 [==============================] - 0s 150us/step - loss: 0.5223 - accuracy: 0.7260\n",
      "Epoch 50/100\n",
      "1788/1788 [==============================] - 0s 172us/step - loss: 0.5222 - accuracy: 0.7248\n",
      "Epoch 51/100\n",
      "1788/1788 [==============================] - 0s 196us/step - loss: 0.5223 - accuracy: 0.7254\n",
      "Epoch 52/100\n",
      "1788/1788 [==============================] - 0s 140us/step - loss: 0.5222 - accuracy: 0.7248\n",
      "Epoch 53/100\n",
      "1788/1788 [==============================] - 0s 183us/step - loss: 0.5221 - accuracy: 0.7243\n",
      "Epoch 54/100\n",
      "1788/1788 [==============================] - 0s 156us/step - loss: 0.5221 - accuracy: 0.7243\n",
      "Epoch 55/100\n",
      "1788/1788 [==============================] - 0s 181us/step - loss: 0.5219 - accuracy: 0.7260\n",
      "Epoch 56/100\n",
      "1788/1788 [==============================] - 0s 159us/step - loss: 0.5218 - accuracy: 0.7271\n",
      "Epoch 57/100\n",
      "1788/1788 [==============================] - 0s 175us/step - loss: 0.5220 - accuracy: 0.7293\n",
      "Epoch 58/100\n",
      "1788/1788 [==============================] - 0s 149us/step - loss: 0.5220 - accuracy: 0.7260\n",
      "Epoch 59/100\n",
      "1788/1788 [==============================] - 0s 152us/step - loss: 0.5218 - accuracy: 0.7254\n",
      "Epoch 60/100\n",
      "1788/1788 [==============================] - 0s 138us/step - loss: 0.5218 - accuracy: 0.7293\n",
      "Epoch 61/100\n",
      "1788/1788 [==============================] - 0s 162us/step - loss: 0.5217 - accuracy: 0.7299\n",
      "Epoch 62/100\n",
      "1788/1788 [==============================] - 0s 149us/step - loss: 0.5214 - accuracy: 0.7248\n",
      "Epoch 63/100\n",
      "1788/1788 [==============================] - 0s 125us/step - loss: 0.5217 - accuracy: 0.7260\n",
      "Epoch 64/100\n",
      "1788/1788 [==============================] - 0s 133us/step - loss: 0.5213 - accuracy: 0.7276\n",
      "Epoch 65/100\n",
      "1788/1788 [==============================] - 0s 135us/step - loss: 0.5214 - accuracy: 0.7260\n",
      "Epoch 66/100\n",
      "1788/1788 [==============================] - 0s 132us/step - loss: 0.5214 - accuracy: 0.7282\n",
      "Epoch 67/100\n",
      "1788/1788 [==============================] - 0s 122us/step - loss: 0.5217 - accuracy: 0.7271\n",
      "Epoch 68/100\n",
      "1788/1788 [==============================] - 0s 160us/step - loss: 0.5211 - accuracy: 0.7276\n",
      "Epoch 69/100\n",
      "1788/1788 [==============================] - 0s 178us/step - loss: 0.5212 - accuracy: 0.7254\n",
      "Epoch 70/100\n",
      "1788/1788 [==============================] - 0s 162us/step - loss: 0.5214 - accuracy: 0.7254\n",
      "Epoch 71/100\n",
      "1788/1788 [==============================] - 0s 178us/step - loss: 0.5214 - accuracy: 0.7243\n",
      "Epoch 72/100\n",
      "1788/1788 [==============================] - 0s 126us/step - loss: 0.5211 - accuracy: 0.7299\n",
      "Epoch 73/100\n",
      "1788/1788 [==============================] - 0s 187us/step - loss: 0.5210 - accuracy: 0.7299\n",
      "Epoch 74/100\n",
      "1788/1788 [==============================] - 0s 158us/step - loss: 0.5211 - accuracy: 0.7287\n",
      "Epoch 75/100\n",
      "1788/1788 [==============================] - 0s 186us/step - loss: 0.5212 - accuracy: 0.7254\n",
      "Epoch 76/100\n",
      "1788/1788 [==============================] - 0s 162us/step - loss: 0.5211 - accuracy: 0.7321\n",
      "Epoch 77/100\n",
      "1788/1788 [==============================] - 0s 175us/step - loss: 0.5210 - accuracy: 0.7282\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1788/1788 [==============================] - 0s 186us/step - loss: 0.5209 - accuracy: 0.7293\n",
      "Epoch 79/100\n",
      "1788/1788 [==============================] - 0s 159us/step - loss: 0.5210 - accuracy: 0.7260\n",
      "Epoch 80/100\n",
      "1788/1788 [==============================] - 0s 174us/step - loss: 0.5210 - accuracy: 0.7287\n",
      "Epoch 81/100\n",
      "1788/1788 [==============================] - 0s 139us/step - loss: 0.5208 - accuracy: 0.7299\n",
      "Epoch 82/100\n",
      "1788/1788 [==============================] - 0s 138us/step - loss: 0.5209 - accuracy: 0.7299\n",
      "Epoch 83/100\n",
      "1788/1788 [==============================] - 0s 130us/step - loss: 0.5211 - accuracy: 0.7310\n",
      "Epoch 84/100\n",
      "1788/1788 [==============================] - 0s 130us/step - loss: 0.5209 - accuracy: 0.7260\n",
      "Epoch 85/100\n",
      "1788/1788 [==============================] - 0s 134us/step - loss: 0.5206 - accuracy: 0.7276\n",
      "Epoch 86/100\n",
      "1788/1788 [==============================] - 0s 124us/step - loss: 0.5207 - accuracy: 0.7299\n",
      "Epoch 87/100\n",
      "1788/1788 [==============================] - 0s 148us/step - loss: 0.5208 - accuracy: 0.7299\n",
      "Epoch 88/100\n",
      "1788/1788 [==============================] - 0s 141us/step - loss: 0.5208 - accuracy: 0.7327\n",
      "Epoch 89/100\n",
      "1788/1788 [==============================] - 0s 126us/step - loss: 0.5207 - accuracy: 0.7299\n",
      "Epoch 90/100\n",
      "1788/1788 [==============================] - 0s 126us/step - loss: 0.5206 - accuracy: 0.7315\n",
      "Epoch 91/100\n",
      "1788/1788 [==============================] - 0s 149us/step - loss: 0.5208 - accuracy: 0.7315\n",
      "Epoch 92/100\n",
      "1788/1788 [==============================] - 0s 196us/step - loss: 0.5207 - accuracy: 0.7287\n",
      "Epoch 93/100\n",
      "1788/1788 [==============================] - 0s 188us/step - loss: 0.5206 - accuracy: 0.7343\n",
      "Epoch 94/100\n",
      "1788/1788 [==============================] - 0s 177us/step - loss: 0.5205 - accuracy: 0.7293\n",
      "Epoch 95/100\n",
      "1788/1788 [==============================] - 0s 158us/step - loss: 0.5205 - accuracy: 0.7304\n",
      "Epoch 96/100\n",
      "1788/1788 [==============================] - 0s 154us/step - loss: 0.5208 - accuracy: 0.7321\n",
      "Epoch 97/100\n",
      "1788/1788 [==============================] - 0s 158us/step - loss: 0.5208 - accuracy: 0.7327\n",
      "Epoch 98/100\n",
      "1788/1788 [==============================] - 0s 159us/step - loss: 0.5206 - accuracy: 0.7315\n",
      "Epoch 99/100\n",
      "1788/1788 [==============================] - 0s 145us/step - loss: 0.5204 - accuracy: 0.7276\n",
      "Epoch 100/100\n",
      "1788/1788 [==============================] - 0s 139us/step - loss: 0.5206 - accuracy: 0.7321\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x22eff37ff08>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the ANN to the Training set\n",
    "cnn5.fit(X_train, y_train, batch_size = 10, nb_epoch = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred10 = cnn5.predict(X_test)\n",
    "y_pred10 = (y_pred10 > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[191  57]\n",
      " [ 68 131]]\n"
     ]
    }
   ],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm5 = confusion_matrix(y_test, y_pred10)\n",
    "print(cm5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "За кількістю помилково розпізнаних данних дана модель не виявилась найкращою. Кількість помилково розпізнаних даних є більше, ніж у моделі KNN.\n",
    "Якщо ж порівняти між собою розглянуті архітектури нейронних мереж за кількістю помилково розпізнаних даних, то найкращою виявилась модель 4-3-2-1. Вона має лише 122 помилково розпізнаних спостереження. Найгіршою є 4-2-2-1. Вона має 127 неправильно визначених результата.\n",
    "Найкращою з усіх розглянутих моделей виявилась модель KNN. Саме її варто застосовувати при визначенні того чи буде користувач надавати більше переваги вину чи ні."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
