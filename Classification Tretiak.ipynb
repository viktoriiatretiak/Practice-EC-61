{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the dataset\n",
    "df = pd.read_csv('marketing_prep.csv', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Необхідно виконати певні перетворення данних. Необхідно додати новий стовпець до нашого датафрейму. В даному стовпці буде записано вихідне значення порівняння витрат користувачів на вино з сумою значень трат користувача на інші категорії товарів. Оскільки на етапі підготовки даних, виконувалось логарифмування даних, то при порівнянні та сумуванні даних необхідно скористатись зворотною функцією - еспоненціюванням. Якщо трати на вино користувача будуть більшими, ніж трати на інші продукти, то в стовпці споживачів вина буде записуватись 1, в зворотньому випадку - 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['WineCons']=np.where((np.exp(df['MntWines'])-1) > ((np.exp(df['AllSpends'])-1)-(np.exp(df['MntWines'])-1)), 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для класифікації в якості залежної змінної буде використовуватись останній стовпець, який демонструє чи є користувачем переважно споживачем вина чи ні. Тобто задача класифікації полягає в тому, щоб за віком, освітою, статусом особистого життя, доходом, кількістю дітей, місяцем здійснення першої покупки визначити чи буде користувач витрачати більше коштів на вино чи ні."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "X = df.iloc[:, :-8].values\n",
    "y = df.iloc[:, -1].values\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler().fit(X_train)\n",
    "X_train = sc_X.transform(X_train)\n",
    "X_test = sc_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.581826\n",
      "         Iterations 6\n",
      "                         Results: Logit\n",
      "=================================================================\n",
      "Model:              Logit            Pseudo R-squared: 0.150     \n",
      "Dependent Variable: y                AIC:              2092.6100 \n",
      "Date:               2020-10-28 19:35 BIC:              2125.5431 \n",
      "No. Observations:   1788             Log-Likelihood:   -1040.3   \n",
      "Df Model:           5                LL-Null:          -1223.7   \n",
      "Df Residuals:       1782             LLR p-value:      4.1311e-77\n",
      "Converged:          1.0000           Scale:            1.0000    \n",
      "No. Iterations:     6.0000                                       \n",
      "--------------------------------------------------------------------\n",
      "        Coef.     Std.Err.       z       P>|z|      [0.025    0.975]\n",
      "--------------------------------------------------------------------\n",
      "x1      0.3424      0.0563     6.0816    0.0000     0.2321    0.4528\n",
      "x2      0.6574      0.0587    11.1905    0.0000     0.5422    0.7725\n",
      "x3     -0.0111      0.0532    -0.2084    0.8350    -0.1153    0.0931\n",
      "x4      0.5199      0.0631     8.2459    0.0000     0.3964    0.6435\n",
      "x5      0.5775      0.0632     9.1417    0.0000     0.4537    0.7013\n",
      "x6      0.0496      0.0530     0.9360    0.3493    -0.0542    0.1534\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Baseline model\n",
    "import statsmodels.api as sm\n",
    "lr = sm.Logit(y_train, X_train).fit()\n",
    "print(lr.summary2())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Як бачимо з побудованої базової моделі, статистично значимими є 1-ша, 2-га, 4-та, 5-та змінні, так як у них значення p-value менше 1. При побудові моделей в якості класифікаторів буде використовувати виключно ці фактори. Перетворимо наші тренувальну та тестові вибірки таким чином, щоб в них залишились виключно ті дані, які будуть використовуватись при побудові моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features selection\n",
    "X_train = X_train[:,[0,1,3,4]]\n",
    "X_test = X_test[:,[0,1,3,4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Logistic Regression to the Training set (2 variables)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "slr = LogisticRegression(random_state = 13).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7114093959731543"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = slr.predict(X_test)\n",
    "slr.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[200  48]\n",
      " [ 81 118]]\n"
     ]
    }
   ],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дана модель має точність прогнозу 71.14%. Має 10.88% хибно негативних значень та 18.37% хибно негативних значень. Вцілому модель є досить непоганою."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum error:- 0.25279642058165547 at K = 42\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Optimal K \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "error_rate = []\n",
    "for i in range(1,50):\n",
    "     knn = KNeighborsClassifier(n_neighbors=i)\n",
    "     knn.fit(X_train,y_train)\n",
    "     pred_i = knn.predict(X_test)\n",
    "     error_rate.append(np.mean(pred_i != y_test))\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(range(1,50),error_rate,color='blue', linestyle='dashed', \n",
    "         marker='o',markerfacecolor='red', markersize=10)\n",
    "plt.title('Error Rate vs. K Value')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Error Rate')\n",
    "print(\"Minimum error:-\",min(error_rate),\"at K =\",error_rate.index(min(error_rate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting K-NN to the Training set (4 variables)\n",
    "knn = KNeighborsClassifier(n_neighbors = 42, metric = 'minkowski', p = 2).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7404921700223713"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred1 = knn.predict(X_test)\n",
    "knn.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[207  41]\n",
      " [ 75 124]]\n"
     ]
    }
   ],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred1)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель KNN є краще, ніж попередня модель логістичної регресії. Так як коефіцієнт точності розпізнавання збільшився майже на 3%, а кількість помилково розпізнаних даних скоротилась 13. Стало менше як хибно позитивних, так і хибно негативних."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting SVM to the Training set (4 variables)\n",
    "from sklearn.svm import SVC\n",
    "svm = SVC(kernel = 'rbf', random_state = 10).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7114093959731543"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred2 = svm.predict(X_test)\n",
    "svm.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[195  53]\n",
      " [ 76 123]]\n"
     ]
    }
   ],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred2)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дана модель є гіршою, ніж KNN як за коефіцієнтом детермінації, так і за кількістю помилково розпізнаних даних.\n",
    "А от якщо порівнювати з моделлю логістичної регресії, то в них коефіцієнт розпізнавання даних є однаковим. Також однакова загальна кількість помилково розпізнаних даних. Але SVM має меншу кіл-сть хибно негативних значень, проте має більшу кіл-сть хибно позитивних значень."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Naive Bayes to the Training set (4 variables)\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb = GaussianNB().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70917225950783"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred3 = nb.predict(X_test)\n",
    "nb.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[196  52]\n",
      " [ 78 121]]\n"
     ]
    }
   ],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred3)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "З усіх розглянутих на даний момент моделей, дана модель є найгіршою. Про це свідчить найменше значення точності та найбільша кіль-сть помилково розізнаних даних."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function Max Leaf\n",
    "def max_leaf_nodes(X_train, X_test, y_train, y_test, n):\n",
    "    mse_train = []\n",
    "    mse_test = []\n",
    "    for i in n:\n",
    "        rf = DecisionTreeRegressor(max_leaf_nodes = i, random_state=10).fit(X_train, y_train)\n",
    "        mse_train.append(mean_squared_error(y_train, rf.predict(X_train)))\n",
    "        mse_test.append(mean_squared_error(y_test, rf.predict(X_test)))\n",
    "    fig, ax = plt.subplots(figsize=(8, 4))\n",
    "    ax.plot(n, mse_train, alpha=0.5, color='blue', label='train')\n",
    "    ax.plot(n, mse_test, alpha=0.5, color='red', label='test')\n",
    "    ax.set_ylabel(\"MSE\")\n",
    "    ax.set_xlabel(\"max_leaf_nodes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The optimal number of max_leaf_nodes\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "max_leaf_nodes(X_train, X_test, y_train, y_test, [2, 4, 6, 8, 10, 12, 14])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так як найменше значення помилки на тестовій вибіркі спостерігається при max_leaf_nodes=10, то візбмемо в якості даного параметро саме число 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Classification Tree to the Training set (2 variables)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "ct = DecisionTreeClassifier(max_leaf_nodes = 10, criterion = 'entropy', random_state = 10).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7158836689038032"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred4 = ct.predict(X_test)\n",
    "ct.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[187  61]\n",
      " [ 66 133]]\n"
     ]
    }
   ],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred4)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дана модель не є найкращою з усіх розглянутих. За коефіцієнтом детермінації вона поступається моделі KNN. В порівнянні з усіма іншими моделаями вона є трохи кращою за точністю прогнохування класу. Що стосується кіл-сті помилково розпізнаних данних, то вона має максимальну кількість хибно позитивних значень та мінімальну кіл-сть хибно негативних значень в порівнянні з усіма іншими моделями\n",
    "\n",
    "Тепер побудуємо модель випадкового лісу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_best_n_estimator(X_train, X_test, y_train, y_test, n):\n",
    "    mse_train = []\n",
    "    mse_test = []\n",
    "    for i in n:\n",
    "        rf = RandomForestClassifier(n_estimators=i, random_state=10).fit(X_train, y_train)\n",
    "        mse_train.append(mean_squared_error(y_train, rf.predict(X_train)))\n",
    "        mse_test.append(mean_squared_error(y_test, rf.predict(X_test)))\n",
    "    fig, ax = plt.subplots(figsize=(8, 4))\n",
    "    ax.plot(n, mse_train, alpha=0.5, color='blue', label='train')\n",
    "    ax.plot(n, mse_test, alpha=0.5, color='red', label='test')\n",
    "    ax.set_ylabel(\"MSE\")\n",
    "    ax.set_xlabel(\"N_estimators\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The optimal number of trees \n",
    "from sklearn.ensemble import RandomForestClassifier    \n",
    "rf_best_n_estimator(X_train, X_test, y_train, y_test, [2, 5, 10, 15, 20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для моделі випадкового лісу в якості кількості дерев можна обрати 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_max_leaf_nodes(X_train, X_test, y_train, y_test, n):\n",
    "    mse_train = []\n",
    "    mse_test = []\n",
    "    for i in n:\n",
    "        rf = RandomForestClassifier(n_estimators=5, max_leaf_nodes =i, random_state=10).fit(X_train, y_train)\n",
    "        mse_train.append(mean_squared_error(y_train, rf.predict(X_train)))\n",
    "        mse_test.append(mean_squared_error(y_test, rf.predict(X_test)))\n",
    "    fig, ax = plt.subplots(figsize=(8, 4))\n",
    "    ax.plot(n, mse_train, alpha=0.5, color='blue', label='train')\n",
    "    ax.plot(n, mse_test, alpha=0.5, color='red', label='test')\n",
    "    ax.set_ylabel(\"MSE\")\n",
    "    ax.set_xlabel(\"max_leaf_nodes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The optimal number of max_leaf_nodes\n",
    "rf_max_leaf_nodes(X_train, X_test, y_train, y_test, [2, 4, 6, 8, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так як найменше значення помилки на тестовій вибіркі при відносно невеликій розбіжності значень помилок на тренувальній та тестовій вибірках спостерігається при max_leaf_nodes=4, то візьмемо в якості даного параметро саме число 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Random Forest to the Training set\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators = 5, max_leaf_nodes = 4, random_state = 10).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7046979865771812"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred5 = rf.predict(X_test)\n",
    "y_pred5 = (y_pred5 > 0.5)\n",
    "rf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[197  51]\n",
      " [ 81 118]]\n"
     ]
    }
   ],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred5)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "За коефіцієнтом правильно розпізнаних данних, дана модель є найгіршою проте, точність моделі скадає трохи більше 70%, тому може бути застосована на практиці"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Install Tensorflow\n",
    "# Install Keras\n",
    "# Importing the Keras libraries and packages\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Побудуємо декілька нейронних мереж для класифікації. Будемо розглядати 5 різних архітектур - '4-3-1', '4-2-1', '4-3-2-1', '4-2-2-1', '4-4-1'. Кількість спостережнь в тренувальній вибірці дозволяє нам проекспериментувати з вказаними архітектурами моделі. Також кількість нейронів на прихованих шарах в даних моделях не перевищує подвоєнної кіл-сті пояснюючих змінних"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\38095\\anaconda3\\envs\\labvika\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=4, units=3, kernel_initializer=\"uniform\")`\n",
      "  \"\"\"\n",
      "C:\\Users\\38095\\anaconda3\\envs\\labvika\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Initialising the ANN 4-3-1\n",
    "cnn1 = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "cnn1.add(Dense(output_dim = 3, init = 'uniform', activation = 'relu', input_dim = 4))\n",
    "\n",
    "# Adding the output layer\n",
    "cnn1.add(Dense(output_dim = 1, init = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "# Compiling the ANN\n",
    "cnn1.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\38095\\anaconda3\\envs\\labvika\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1788/1788 [==============================] - 0s 266us/step - loss: 0.6854 - accuracy: 0.5638\n",
      "Epoch 2/100\n",
      "1788/1788 [==============================] - 0s 132us/step - loss: 0.6394 - accuracy: 0.6521\n",
      "Epoch 3/100\n",
      "1788/1788 [==============================] - 0s 143us/step - loss: 0.5967 - accuracy: 0.6868\n",
      "Epoch 4/100\n",
      "1788/1788 [==============================] - 0s 136us/step - loss: 0.5765 - accuracy: 0.6946\n",
      "Epoch 5/100\n",
      "1788/1788 [==============================] - 0s 131us/step - loss: 0.5679 - accuracy: 0.6969\n",
      "Epoch 6/100\n",
      "1788/1788 [==============================] - 0s 150us/step - loss: 0.5641 - accuracy: 0.6991\n",
      "Epoch 7/100\n",
      "1788/1788 [==============================] - 0s 131us/step - loss: 0.5618 - accuracy: 0.7025\n",
      "Epoch 8/100\n",
      "1788/1788 [==============================] - 0s 124us/step - loss: 0.5604 - accuracy: 0.7047\n",
      "Epoch 9/100\n",
      "1788/1788 [==============================] - 0s 134us/step - loss: 0.5592 - accuracy: 0.7058\n",
      "Epoch 10/100\n",
      "1788/1788 [==============================] - 0s 134us/step - loss: 0.5576 - accuracy: 0.7081\n",
      "Epoch 11/100\n",
      "1788/1788 [==============================] - 0s 125us/step - loss: 0.5563 - accuracy: 0.7114\n",
      "Epoch 12/100\n",
      "1788/1788 [==============================] - 0s 130us/step - loss: 0.5548 - accuracy: 0.7136\n",
      "Epoch 13/100\n",
      "1788/1788 [==============================] - 0s 147us/step - loss: 0.5530 - accuracy: 0.7148\n",
      "Epoch 14/100\n",
      "1788/1788 [==============================] - 0s 135us/step - loss: 0.5508 - accuracy: 0.7148\n",
      "Epoch 15/100\n",
      "1788/1788 [==============================] - 0s 132us/step - loss: 0.5490 - accuracy: 0.7164\n",
      "Epoch 16/100\n",
      "1788/1788 [==============================] - 0s 131us/step - loss: 0.5468 - accuracy: 0.7148\n",
      "Epoch 17/100\n",
      "1788/1788 [==============================] - 0s 151us/step - loss: 0.5444 - accuracy: 0.7181\n",
      "Epoch 18/100\n",
      "1788/1788 [==============================] - 0s 129us/step - loss: 0.5423 - accuracy: 0.7192\n",
      "Epoch 19/100\n",
      "1788/1788 [==============================] - 0s 121us/step - loss: 0.5403 - accuracy: 0.7254\n",
      "Epoch 20/100\n",
      "1788/1788 [==============================] - 0s 126us/step - loss: 0.5387 - accuracy: 0.7248\n",
      "Epoch 21/100\n",
      "1788/1788 [==============================] - 0s 160us/step - loss: 0.5368 - accuracy: 0.7260\n",
      "Epoch 22/100\n",
      "1788/1788 [==============================] - 0s 140us/step - loss: 0.5350 - accuracy: 0.7276\n",
      "Epoch 23/100\n",
      "1788/1788 [==============================] - 0s 153us/step - loss: 0.5336 - accuracy: 0.7271\n",
      "Epoch 24/100\n",
      "1788/1788 [==============================] - 0s 142us/step - loss: 0.5324 - accuracy: 0.7254\n",
      "Epoch 25/100\n",
      "1788/1788 [==============================] - 0s 148us/step - loss: 0.5313 - accuracy: 0.7282\n",
      "Epoch 26/100\n",
      "1788/1788 [==============================] - 0s 126us/step - loss: 0.5303 - accuracy: 0.7237\n",
      "Epoch 27/100\n",
      "1788/1788 [==============================] - 0s 124us/step - loss: 0.5294 - accuracy: 0.7282\n",
      "Epoch 28/100\n",
      "1788/1788 [==============================] - 0s 121us/step - loss: 0.5286 - accuracy: 0.7293\n",
      "Epoch 29/100\n",
      "1788/1788 [==============================] - 0s 120us/step - loss: 0.5281 - accuracy: 0.7327\n",
      "Epoch 30/100\n",
      "1788/1788 [==============================] - 0s 132us/step - loss: 0.5273 - accuracy: 0.7321\n",
      "Epoch 31/100\n",
      "1788/1788 [==============================] - 0s 126us/step - loss: 0.5269 - accuracy: 0.7315\n",
      "Epoch 32/100\n",
      "1788/1788 [==============================] - 0s 130us/step - loss: 0.5262 - accuracy: 0.7321\n",
      "Epoch 33/100\n",
      "1788/1788 [==============================] - 0s 123us/step - loss: 0.5257 - accuracy: 0.7360\n",
      "Epoch 34/100\n",
      "1788/1788 [==============================] - 0s 127us/step - loss: 0.5256 - accuracy: 0.7304\n",
      "Epoch 35/100\n",
      "1788/1788 [==============================] - 0s 125us/step - loss: 0.5251 - accuracy: 0.7304\n",
      "Epoch 36/100\n",
      "1788/1788 [==============================] - 0s 127us/step - loss: 0.5247 - accuracy: 0.7293\n",
      "Epoch 37/100\n",
      "1788/1788 [==============================] - 0s 123us/step - loss: 0.5248 - accuracy: 0.7293\n",
      "Epoch 38/100\n",
      "1788/1788 [==============================] - 0s 124us/step - loss: 0.5244 - accuracy: 0.7293\n",
      "Epoch 39/100\n",
      "1788/1788 [==============================] - 0s 130us/step - loss: 0.5243 - accuracy: 0.7282\n",
      "Epoch 40/100\n",
      "1788/1788 [==============================] - 0s 127us/step - loss: 0.5238 - accuracy: 0.7293\n",
      "Epoch 41/100\n",
      "1788/1788 [==============================] - 0s 147us/step - loss: 0.5238 - accuracy: 0.7287\n",
      "Epoch 42/100\n",
      "1788/1788 [==============================] - 0s 127us/step - loss: 0.5234 - accuracy: 0.7265\n",
      "Epoch 43/100\n",
      "1788/1788 [==============================] - 0s 123us/step - loss: 0.5234 - accuracy: 0.7282\n",
      "Epoch 44/100\n",
      "1788/1788 [==============================] - 0s 119us/step - loss: 0.5233 - accuracy: 0.7304\n",
      "Epoch 45/100\n",
      "1788/1788 [==============================] - 0s 125us/step - loss: 0.5231 - accuracy: 0.7287\n",
      "Epoch 46/100\n",
      "1788/1788 [==============================] - 0s 133us/step - loss: 0.5231 - accuracy: 0.7321\n",
      "Epoch 47/100\n",
      "1788/1788 [==============================] - 0s 128us/step - loss: 0.5232 - accuracy: 0.7265\n",
      "Epoch 48/100\n",
      "1788/1788 [==============================] - 0s 132us/step - loss: 0.5226 - accuracy: 0.7276\n",
      "Epoch 49/100\n",
      "1788/1788 [==============================] - 0s 125us/step - loss: 0.5226 - accuracy: 0.7282\n",
      "Epoch 50/100\n",
      "1788/1788 [==============================] - 0s 122us/step - loss: 0.5227 - accuracy: 0.7310\n",
      "Epoch 51/100\n",
      "1788/1788 [==============================] - 0s 121us/step - loss: 0.5224 - accuracy: 0.7287\n",
      "Epoch 52/100\n",
      "1788/1788 [==============================] - 0s 123us/step - loss: 0.5223 - accuracy: 0.7271\n",
      "Epoch 53/100\n",
      "1788/1788 [==============================] - 0s 122us/step - loss: 0.5223 - accuracy: 0.7271\n",
      "Epoch 54/100\n",
      "1788/1788 [==============================] - 0s 127us/step - loss: 0.5221 - accuracy: 0.7276\n",
      "Epoch 55/100\n",
      "1788/1788 [==============================] - 0s 139us/step - loss: 0.5222 - accuracy: 0.7282\n",
      "Epoch 56/100\n",
      "1788/1788 [==============================] - 0s 120us/step - loss: 0.5220 - accuracy: 0.7237\n",
      "Epoch 57/100\n",
      "1788/1788 [==============================] - 0s 121us/step - loss: 0.5220 - accuracy: 0.7260\n",
      "Epoch 58/100\n",
      "1788/1788 [==============================] - 0s 119us/step - loss: 0.5219 - accuracy: 0.7260\n",
      "Epoch 59/100\n",
      "1788/1788 [==============================] - 0s 122us/step - loss: 0.5218 - accuracy: 0.7293\n",
      "Epoch 60/100\n",
      "1788/1788 [==============================] - 0s 123us/step - loss: 0.5218 - accuracy: 0.7271\n",
      "Epoch 61/100\n",
      "1788/1788 [==============================] - 0s 133us/step - loss: 0.5217 - accuracy: 0.7276\n",
      "Epoch 62/100\n",
      "1788/1788 [==============================] - 0s 125us/step - loss: 0.5215 - accuracy: 0.7287\n",
      "Epoch 63/100\n",
      "1788/1788 [==============================] - 0s 133us/step - loss: 0.5218 - accuracy: 0.7310\n",
      "Epoch 64/100\n",
      "1788/1788 [==============================] - 0s 128us/step - loss: 0.5215 - accuracy: 0.7271\n",
      "Epoch 65/100\n",
      "1788/1788 [==============================] - 0s 123us/step - loss: 0.5215 - accuracy: 0.7276\n",
      "Epoch 66/100\n",
      "1788/1788 [==============================] - 0s 127us/step - loss: 0.5213 - accuracy: 0.7327\n",
      "Epoch 67/100\n",
      "1788/1788 [==============================] - 0s 129us/step - loss: 0.5213 - accuracy: 0.7293\n",
      "Epoch 68/100\n",
      "1788/1788 [==============================] - 0s 130us/step - loss: 0.5212 - accuracy: 0.7299\n",
      "Epoch 69/100\n",
      "1788/1788 [==============================] - 0s 122us/step - loss: 0.5212 - accuracy: 0.7293\n",
      "Epoch 70/100\n",
      "1788/1788 [==============================] - 0s 127us/step - loss: 0.5212 - accuracy: 0.7293\n",
      "Epoch 71/100\n",
      "1788/1788 [==============================] - 0s 122us/step - loss: 0.5211 - accuracy: 0.7310\n",
      "Epoch 72/100\n",
      "1788/1788 [==============================] - 0s 124us/step - loss: 0.5210 - accuracy: 0.7310\n",
      "Epoch 73/100\n",
      "1788/1788 [==============================] - 0s 124us/step - loss: 0.5211 - accuracy: 0.7299\n",
      "Epoch 74/100\n",
      "1788/1788 [==============================] - 0s 137us/step - loss: 0.5211 - accuracy: 0.7282\n",
      "Epoch 75/100\n",
      "1788/1788 [==============================] - 0s 130us/step - loss: 0.5210 - accuracy: 0.7282\n",
      "Epoch 76/100\n",
      "1788/1788 [==============================] - 0s 124us/step - loss: 0.5208 - accuracy: 0.7287\n",
      "Epoch 77/100\n",
      "1788/1788 [==============================] - 0s 123us/step - loss: 0.5210 - accuracy: 0.7276\n",
      "Epoch 78/100\n",
      "1788/1788 [==============================] - 0s 130us/step - loss: 0.5209 - accuracy: 0.7276\n",
      "Epoch 79/100\n",
      "1788/1788 [==============================] - 0s 121us/step - loss: 0.5208 - accuracy: 0.7276\n",
      "Epoch 80/100\n",
      "1788/1788 [==============================] - 0s 125us/step - loss: 0.5210 - accuracy: 0.7293\n",
      "Epoch 81/100\n",
      "1788/1788 [==============================] - 0s 128us/step - loss: 0.5212 - accuracy: 0.7299\n",
      "Epoch 82/100\n",
      "1788/1788 [==============================] - 0s 121us/step - loss: 0.5207 - accuracy: 0.7287\n",
      "Epoch 83/100\n",
      "1788/1788 [==============================] - 0s 123us/step - loss: 0.5207 - accuracy: 0.7287\n",
      "Epoch 84/100\n",
      "1788/1788 [==============================] - 0s 123us/step - loss: 0.5211 - accuracy: 0.7271\n",
      "Epoch 85/100\n",
      "1788/1788 [==============================] - 0s 130us/step - loss: 0.5209 - accuracy: 0.7271\n",
      "Epoch 86/100\n",
      "1788/1788 [==============================] - 0s 133us/step - loss: 0.5208 - accuracy: 0.7304\n",
      "Epoch 87/100\n",
      "1788/1788 [==============================] - 0s 143us/step - loss: 0.5205 - accuracy: 0.7282\n",
      "Epoch 88/100\n",
      "1788/1788 [==============================] - 0s 123us/step - loss: 0.5206 - accuracy: 0.7299\n",
      "Epoch 89/100\n",
      "1788/1788 [==============================] - 0s 126us/step - loss: 0.5206 - accuracy: 0.7299\n",
      "Epoch 90/100\n",
      "1788/1788 [==============================] - 0s 125us/step - loss: 0.5206 - accuracy: 0.7315\n",
      "Epoch 91/100\n",
      "1788/1788 [==============================] - 0s 130us/step - loss: 0.5206 - accuracy: 0.7304\n",
      "Epoch 92/100\n",
      "1788/1788 [==============================] - 0s 125us/step - loss: 0.5207 - accuracy: 0.7315\n",
      "Epoch 93/100\n",
      "1788/1788 [==============================] - 0s 127us/step - loss: 0.5205 - accuracy: 0.7293\n",
      "Epoch 94/100\n",
      "1788/1788 [==============================] - 0s 120us/step - loss: 0.5206 - accuracy: 0.7287\n",
      "Epoch 95/100\n",
      "1788/1788 [==============================] - 0s 128us/step - loss: 0.5206 - accuracy: 0.7315\n",
      "Epoch 96/100\n",
      "1788/1788 [==============================] - 0s 128us/step - loss: 0.5204 - accuracy: 0.7315\n",
      "Epoch 97/100\n",
      "1788/1788 [==============================] - 0s 128us/step - loss: 0.5207 - accuracy: 0.7315\n",
      "Epoch 98/100\n",
      "1788/1788 [==============================] - 0s 132us/step - loss: 0.5205 - accuracy: 0.7304\n",
      "Epoch 99/100\n",
      "1788/1788 [==============================] - 0s 132us/step - loss: 0.5203 - accuracy: 0.7310\n",
      "Epoch 100/100\n",
      "1788/1788 [==============================] - 0s 127us/step - loss: 0.5206 - accuracy: 0.7304\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x22efb16a6c8>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the ANN to the Training set\n",
    "cnn1.fit(X_train, y_train, batch_size = 10, nb_epoch = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred6 = cnn1.predict(X_test)\n",
    "y_pred6 = (y_pred6 > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[190  58]\n",
      " [ 68 131]]\n"
     ]
    }
   ],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm1 = confusion_matrix(y_test, y_pred6)\n",
    "print(cm1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\38095\\anaconda3\\envs\\labvika\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=4, units=2, kernel_initializer=\"uniform\")`\n",
      "  \"\"\"\n",
      "C:\\Users\\38095\\anaconda3\\envs\\labvika\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Initialising the ANN 4-2-1\n",
    "cnn2 = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "cnn2.add(Dense(output_dim = 2, init = 'uniform', activation = 'relu', input_dim = 4))\n",
    "\n",
    "# Adding the output layer\n",
    "cnn2.add(Dense(output_dim = 1, init = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "# Compiling the ANN\n",
    "cnn2.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\38095\\anaconda3\\envs\\labvika\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1788/1788 [==============================] - 0s 168us/step - loss: 0.6861 - accuracy: 0.5666\n",
      "Epoch 2/100\n",
      "1788/1788 [==============================] - 0s 123us/step - loss: 0.6531 - accuracy: 0.6572\n",
      "Epoch 3/100\n",
      "1788/1788 [==============================] - 0s 123us/step - loss: 0.6140 - accuracy: 0.6885\n",
      "Epoch 4/100\n",
      "1788/1788 [==============================] - 0s 124us/step - loss: 0.5878 - accuracy: 0.6924\n",
      "Epoch 5/100\n",
      "1788/1788 [==============================] - 0s 124us/step - loss: 0.5745 - accuracy: 0.6946\n",
      "Epoch 6/100\n",
      "1788/1788 [==============================] - 0s 127us/step - loss: 0.5677 - accuracy: 0.69850s - loss: 0.5739 - accuracy: 0.\n",
      "Epoch 7/100\n",
      "1788/1788 [==============================] - 0s 135us/step - loss: 0.5643 - accuracy: 0.6980\n",
      "Epoch 8/100\n",
      "1788/1788 [==============================] - 0s 127us/step - loss: 0.5624 - accuracy: 0.7013\n",
      "Epoch 9/100\n",
      "1788/1788 [==============================] - 0s 127us/step - loss: 0.5612 - accuracy: 0.7092\n",
      "Epoch 10/100\n",
      "1788/1788 [==============================] - 0s 128us/step - loss: 0.5603 - accuracy: 0.7092\n",
      "Epoch 11/100\n",
      "1788/1788 [==============================] - 0s 131us/step - loss: 0.5593 - accuracy: 0.7136\n",
      "Epoch 12/100\n",
      "1788/1788 [==============================] - 0s 133us/step - loss: 0.5584 - accuracy: 0.7103\n",
      "Epoch 13/100\n",
      "1788/1788 [==============================] - 0s 128us/step - loss: 0.5577 - accuracy: 0.7125\n",
      "Epoch 14/100\n",
      "1788/1788 [==============================] - 0s 128us/step - loss: 0.5571 - accuracy: 0.7097\n",
      "Epoch 15/100\n",
      "1788/1788 [==============================] - 0s 127us/step - loss: 0.5564 - accuracy: 0.7120\n",
      "Epoch 16/100\n",
      "1788/1788 [==============================] - 0s 122us/step - loss: 0.5558 - accuracy: 0.7092\n",
      "Epoch 17/100\n",
      "1788/1788 [==============================] - 0s 134us/step - loss: 0.5553 - accuracy: 0.7058\n",
      "Epoch 18/100\n",
      "1788/1788 [==============================] - 0s 123us/step - loss: 0.5545 - accuracy: 0.7081\n",
      "Epoch 19/100\n",
      "1788/1788 [==============================] - 0s 136us/step - loss: 0.5542 - accuracy: 0.7064\n",
      "Epoch 20/100\n",
      "1788/1788 [==============================] - 0s 134us/step - loss: 0.5542 - accuracy: 0.7075\n",
      "Epoch 21/100\n",
      "1788/1788 [==============================] - 0s 124us/step - loss: 0.5534 - accuracy: 0.7097\n",
      "Epoch 22/100\n",
      "1788/1788 [==============================] - 0s 128us/step - loss: 0.5531 - accuracy: 0.7092\n",
      "Epoch 23/100\n",
      "1788/1788 [==============================] - 0s 130us/step - loss: 0.5526 - accuracy: 0.7109\n",
      "Epoch 24/100\n",
      "1788/1788 [==============================] - 0s 138us/step - loss: 0.5522 - accuracy: 0.7086\n",
      "Epoch 25/100\n",
      "1788/1788 [==============================] - 0s 133us/step - loss: 0.5519 - accuracy: 0.7109\n",
      "Epoch 26/100\n",
      "1788/1788 [==============================] - 0s 168us/step - loss: 0.5517 - accuracy: 0.7120\n",
      "Epoch 27/100\n",
      "1788/1788 [==============================] - 0s 164us/step - loss: 0.5511 - accuracy: 0.7148\n",
      "Epoch 28/100\n",
      "1788/1788 [==============================] - 0s 181us/step - loss: 0.5506 - accuracy: 0.7142\n",
      "Epoch 29/100\n",
      "1788/1788 [==============================] - 0s 182us/step - loss: 0.5505 - accuracy: 0.7181\n",
      "Epoch 30/100\n",
      "1788/1788 [==============================] - 0s 155us/step - loss: 0.5500 - accuracy: 0.7164\n",
      "Epoch 31/100\n",
      "1788/1788 [==============================] - 0s 169us/step - loss: 0.5495 - accuracy: 0.7142\n",
      "Epoch 32/100\n",
      "1788/1788 [==============================] - 0s 161us/step - loss: 0.5492 - accuracy: 0.7170\n",
      "Epoch 33/100\n",
      "1788/1788 [==============================] - 0s 212us/step - loss: 0.5487 - accuracy: 0.7181\n",
      "Epoch 34/100\n",
      "1788/1788 [==============================] - 0s 219us/step - loss: 0.5482 - accuracy: 0.7226\n",
      "Epoch 35/100\n",
      "1788/1788 [==============================] - 1s 410us/step - loss: 0.5481 - accuracy: 0.7187\n",
      "Epoch 36/100\n",
      "1788/1788 [==============================] - 1s 419us/step - loss: 0.5476 - accuracy: 0.7215\n",
      "Epoch 37/100\n",
      "1788/1788 [==============================] - 1s 411us/step - loss: 0.5473 - accuracy: 0.7237\n",
      "Epoch 38/100\n",
      "1788/1788 [==============================] - 1s 301us/step - loss: 0.5467 - accuracy: 0.7237\n",
      "Epoch 39/100\n",
      "1788/1788 [==============================] - 0s 167us/step - loss: 0.5462 - accuracy: 0.7220\n",
      "Epoch 40/100\n",
      "1788/1788 [==============================] - 1s 283us/step - loss: 0.5457 - accuracy: 0.7232\n",
      "Epoch 41/100\n",
      "1788/1788 [==============================] - 1s 408us/step - loss: 0.5453 - accuracy: 0.7260\n",
      "Epoch 42/100\n",
      "1788/1788 [==============================] - 1s 453us/step - loss: 0.5444 - accuracy: 0.7243\n",
      "Epoch 43/100\n",
      "1788/1788 [==============================] - 1s 371us/step - loss: 0.5441 - accuracy: 0.7220\n",
      "Epoch 44/100\n",
      "1788/1788 [==============================] - 1s 400us/step - loss: 0.5436 - accuracy: 0.7226\n",
      "Epoch 45/100\n",
      "1788/1788 [==============================] - 1s 365us/step - loss: 0.5434 - accuracy: 0.7243\n",
      "Epoch 46/100\n",
      "1788/1788 [==============================] - 1s 361us/step - loss: 0.5429 - accuracy: 0.7209\n",
      "Epoch 47/100\n",
      "1788/1788 [==============================] - 1s 359us/step - loss: 0.5425 - accuracy: 0.7220\n",
      "Epoch 48/100\n",
      "1788/1788 [==============================] - 1s 342us/step - loss: 0.5422 - accuracy: 0.7209\n",
      "Epoch 49/100\n",
      "1788/1788 [==============================] - 1s 312us/step - loss: 0.5417 - accuracy: 0.7232\n",
      "Epoch 50/100\n",
      "1788/1788 [==============================] - 1s 314us/step - loss: 0.5415 - accuracy: 0.7215\n",
      "Epoch 51/100\n",
      "1788/1788 [==============================] - 1s 308us/step - loss: 0.5412 - accuracy: 0.7226\n",
      "Epoch 52/100\n",
      "1788/1788 [==============================] - 0s 269us/step - loss: 0.5407 - accuracy: 0.7204\n",
      "Epoch 53/100\n",
      "1788/1788 [==============================] - 0s 220us/step - loss: 0.5403 - accuracy: 0.7220\n",
      "Epoch 54/100\n",
      "1788/1788 [==============================] - 1s 292us/step - loss: 0.5398 - accuracy: 0.7237\n",
      "Epoch 55/100\n",
      "1788/1788 [==============================] - 1s 304us/step - loss: 0.5394 - accuracy: 0.7248\n",
      "Epoch 56/100\n",
      "1788/1788 [==============================] - 1s 301us/step - loss: 0.5386 - accuracy: 0.7265\n",
      "Epoch 57/100\n",
      "1788/1788 [==============================] - 1s 306us/step - loss: 0.5383 - accuracy: 0.7237\n",
      "Epoch 58/100\n",
      "1788/1788 [==============================] - 1s 304us/step - loss: 0.5379 - accuracy: 0.7226\n",
      "Epoch 59/100\n",
      "1788/1788 [==============================] - 1s 309us/step - loss: 0.5375 - accuracy: 0.7287\n",
      "Epoch 60/100\n",
      "1788/1788 [==============================] - 1s 313us/step - loss: 0.5370 - accuracy: 0.7287\n",
      "Epoch 61/100\n",
      "1788/1788 [==============================] - 1s 306us/step - loss: 0.5365 - accuracy: 0.7260\n",
      "Epoch 62/100\n",
      "1788/1788 [==============================] - 1s 306us/step - loss: 0.5359 - accuracy: 0.7271\n",
      "Epoch 63/100\n",
      "1788/1788 [==============================] - 1s 306us/step - loss: 0.5357 - accuracy: 0.7260\n",
      "Epoch 64/100\n",
      "1788/1788 [==============================] - 1s 301us/step - loss: 0.5354 - accuracy: 0.7265\n",
      "Epoch 65/100\n",
      "1788/1788 [==============================] - 1s 305us/step - loss: 0.5351 - accuracy: 0.7254\n",
      "Epoch 66/100\n",
      "1788/1788 [==============================] - 1s 305us/step - loss: 0.5348 - accuracy: 0.7243\n",
      "Epoch 67/100\n",
      "1788/1788 [==============================] - 1s 305us/step - loss: 0.5344 - accuracy: 0.7248\n",
      "Epoch 68/100\n",
      "1788/1788 [==============================] - 1s 311us/step - loss: 0.5342 - accuracy: 0.7254\n",
      "Epoch 69/100\n",
      "1788/1788 [==============================] - 1s 308us/step - loss: 0.5338 - accuracy: 0.7254\n",
      "Epoch 70/100\n",
      "1788/1788 [==============================] - 1s 306us/step - loss: 0.5337 - accuracy: 0.7237\n",
      "Epoch 71/100\n",
      "1788/1788 [==============================] - 1s 310us/step - loss: 0.5335 - accuracy: 0.7220\n",
      "Epoch 72/100\n",
      "1788/1788 [==============================] - 1s 307us/step - loss: 0.5334 - accuracy: 0.7243\n",
      "Epoch 73/100\n",
      "1788/1788 [==============================] - 1s 309us/step - loss: 0.5330 - accuracy: 0.7248\n",
      "Epoch 74/100\n",
      "1788/1788 [==============================] - 1s 309us/step - loss: 0.5327 - accuracy: 0.7232\n",
      "Epoch 75/100\n",
      "1788/1788 [==============================] - 1s 304us/step - loss: 0.5326 - accuracy: 0.7220\n",
      "Epoch 76/100\n",
      "1788/1788 [==============================] - 1s 306us/step - loss: 0.5325 - accuracy: 0.7248\n",
      "Epoch 77/100\n",
      "1788/1788 [==============================] - 1s 325us/step - loss: 0.5324 - accuracy: 0.7215\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1788/1788 [==============================] - 1s 303us/step - loss: 0.5321 - accuracy: 0.7232\n",
      "Epoch 79/100\n",
      "1788/1788 [==============================] - 1s 305us/step - loss: 0.5320 - accuracy: 0.7220\n",
      "Epoch 80/100\n",
      "1788/1788 [==============================] - 1s 305us/step - loss: 0.5320 - accuracy: 0.7232\n",
      "Epoch 81/100\n",
      "1788/1788 [==============================] - 1s 302us/step - loss: 0.5321 - accuracy: 0.7209\n",
      "Epoch 82/100\n",
      "1788/1788 [==============================] - 1s 304us/step - loss: 0.5317 - accuracy: 0.7237\n",
      "Epoch 83/100\n",
      "1788/1788 [==============================] - 1s 303us/step - loss: 0.5316 - accuracy: 0.7215\n",
      "Epoch 84/100\n",
      "1788/1788 [==============================] - 1s 313us/step - loss: 0.5314 - accuracy: 0.7204\n",
      "Epoch 85/100\n",
      "1788/1788 [==============================] - 1s 298us/step - loss: 0.5314 - accuracy: 0.7192\n",
      "Epoch 86/100\n",
      "1788/1788 [==============================] - 1s 303us/step - loss: 0.5314 - accuracy: 0.7215\n",
      "Epoch 87/100\n",
      "1788/1788 [==============================] - 1s 302us/step - loss: 0.5312 - accuracy: 0.7204\n",
      "Epoch 88/100\n",
      "1788/1788 [==============================] - 1s 306us/step - loss: 0.5310 - accuracy: 0.7181\n",
      "Epoch 89/100\n",
      "1788/1788 [==============================] - 1s 307us/step - loss: 0.5310 - accuracy: 0.7192\n",
      "Epoch 90/100\n",
      "1788/1788 [==============================] - 1s 304us/step - loss: 0.5310 - accuracy: 0.7187\n",
      "Epoch 91/100\n",
      "1788/1788 [==============================] - 1s 304us/step - loss: 0.5310 - accuracy: 0.7192\n",
      "Epoch 92/100\n",
      "1788/1788 [==============================] - 1s 306us/step - loss: 0.5308 - accuracy: 0.7209\n",
      "Epoch 93/100\n",
      "1788/1788 [==============================] - 1s 303us/step - loss: 0.5308 - accuracy: 0.7232\n",
      "Epoch 94/100\n",
      "1788/1788 [==============================] - 1s 301us/step - loss: 0.5309 - accuracy: 0.7198\n",
      "Epoch 95/100\n",
      "1788/1788 [==============================] - 1s 303us/step - loss: 0.5305 - accuracy: 0.7204\n",
      "Epoch 96/100\n",
      "1788/1788 [==============================] - 1s 305us/step - loss: 0.5305 - accuracy: 0.7248\n",
      "Epoch 97/100\n",
      "1788/1788 [==============================] - 1s 302us/step - loss: 0.5304 - accuracy: 0.7220\n",
      "Epoch 98/100\n",
      "1788/1788 [==============================] - 1s 309us/step - loss: 0.5305 - accuracy: 0.7215\n",
      "Epoch 99/100\n",
      "1788/1788 [==============================] - 1s 301us/step - loss: 0.5304 - accuracy: 0.7220\n",
      "Epoch 100/100\n",
      "1788/1788 [==============================] - 1s 306us/step - loss: 0.5305 - accuracy: 0.7187\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x22efc552dc8>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the ANN to the Training set\n",
    "cnn2.fit(X_train, y_train, batch_size = 10, nb_epoch = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred7 = cnn2.predict(X_test)\n",
    "y_pred7 = (y_pred7 > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[194  54]\n",
      " [ 73 126]]\n"
     ]
    }
   ],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm2 = confusion_matrix(y_test, y_pred7)\n",
    "print(cm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\38095\\anaconda3\\envs\\labvika\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=4, units=3, kernel_initializer=\"uniform\")`\n",
      "  \"\"\"\n",
      "C:\\Users\\38095\\anaconda3\\envs\\labvika\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=2, kernel_initializer=\"uniform\")`\n",
      "  \n",
      "C:\\Users\\38095\\anaconda3\\envs\\labvika\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "# Initialising the ANN 4-3-2-1\n",
    "cnn3 = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "cnn3.add(Dense(output_dim = 3, init = 'uniform', activation = 'relu', input_dim = 4))\n",
    "\n",
    "# Adding the hidden layer\n",
    "cnn3.add(Dense(output_dim = 2, init = 'uniform', activation = 'relu'))\n",
    "\n",
    "# Adding the output layer\n",
    "cnn3.add(Dense(output_dim = 1, init = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "# Compiling the ANN\n",
    "cnn3.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\38095\\anaconda3\\envs\\labvika\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1788/1788 [==============================] - 0s 179us/step - loss: 0.6890 - accuracy: 0.5660\n",
      "Epoch 2/100\n",
      "1788/1788 [==============================] - 0s 133us/step - loss: 0.6586 - accuracy: 0.5660\n",
      "Epoch 3/100\n",
      "1788/1788 [==============================] - 0s 130us/step - loss: 0.6190 - accuracy: 0.5660\n",
      "Epoch 4/100\n",
      "1788/1788 [==============================] - 0s 158us/step - loss: 0.5999 - accuracy: 0.6281\n",
      "Epoch 5/100\n",
      "1788/1788 [==============================] - 0s 145us/step - loss: 0.5916 - accuracy: 0.6823\n",
      "Epoch 6/100\n",
      "1788/1788 [==============================] - 0s 133us/step - loss: 0.5861 - accuracy: 0.6868\n",
      "Epoch 7/100\n",
      "1788/1788 [==============================] - 0s 134us/step - loss: 0.5817 - accuracy: 0.6935\n",
      "Epoch 8/100\n",
      "1788/1788 [==============================] - 0s 133us/step - loss: 0.5781 - accuracy: 0.6997\n",
      "Epoch 9/100\n",
      "1788/1788 [==============================] - 0s 133us/step - loss: 0.5748 - accuracy: 0.7002\n",
      "Epoch 10/100\n",
      "1788/1788 [==============================] - 0s 147us/step - loss: 0.5715 - accuracy: 0.7075\n",
      "Epoch 11/100\n",
      "1788/1788 [==============================] - 0s 155us/step - loss: 0.5682 - accuracy: 0.7092\n",
      "Epoch 12/100\n",
      "1788/1788 [==============================] - 0s 135us/step - loss: 0.5646 - accuracy: 0.7164\n",
      "Epoch 13/100\n",
      "1788/1788 [==============================] - 0s 135us/step - loss: 0.5607 - accuracy: 0.7181\n",
      "Epoch 14/100\n",
      "1788/1788 [==============================] - 0s 150us/step - loss: 0.5577 - accuracy: 0.7226\n",
      "Epoch 15/100\n",
      "1788/1788 [==============================] - 0s 149us/step - loss: 0.5547 - accuracy: 0.7237\n",
      "Epoch 16/100\n",
      "1788/1788 [==============================] - 0s 149us/step - loss: 0.5520 - accuracy: 0.7282\n",
      "Epoch 17/100\n",
      "1788/1788 [==============================] - 0s 141us/step - loss: 0.5494 - accuracy: 0.7299\n",
      "Epoch 18/100\n",
      "1788/1788 [==============================] - 0s 171us/step - loss: 0.5470 - accuracy: 0.7315\n",
      "Epoch 19/100\n",
      "1788/1788 [==============================] - 0s 170us/step - loss: 0.5451 - accuracy: 0.7304\n",
      "Epoch 20/100\n",
      "1788/1788 [==============================] - 0s 144us/step - loss: 0.5434 - accuracy: 0.7315\n",
      "Epoch 21/100\n",
      "1788/1788 [==============================] - 0s 158us/step - loss: 0.5419 - accuracy: 0.7310\n",
      "Epoch 22/100\n",
      "1788/1788 [==============================] - 0s 156us/step - loss: 0.5406 - accuracy: 0.7327\n",
      "Epoch 23/100\n",
      "1788/1788 [==============================] - 0s 148us/step - loss: 0.5391 - accuracy: 0.7332\n",
      "Epoch 24/100\n",
      "1788/1788 [==============================] - 0s 161us/step - loss: 0.5379 - accuracy: 0.7287\n",
      "Epoch 25/100\n",
      "1788/1788 [==============================] - 0s 161us/step - loss: 0.5368 - accuracy: 0.7287\n",
      "Epoch 26/100\n",
      "1788/1788 [==============================] - 0s 166us/step - loss: 0.5357 - accuracy: 0.7315\n",
      "Epoch 27/100\n",
      "1788/1788 [==============================] - 0s 179us/step - loss: 0.5350 - accuracy: 0.7287\n",
      "Epoch 28/100\n",
      "1788/1788 [==============================] - 0s 156us/step - loss: 0.5342 - accuracy: 0.7293\n",
      "Epoch 29/100\n",
      "1788/1788 [==============================] - 0s 168us/step - loss: 0.5335 - accuracy: 0.7260\n",
      "Epoch 30/100\n",
      "1788/1788 [==============================] - 0s 153us/step - loss: 0.5327 - accuracy: 0.7260\n",
      "Epoch 31/100\n",
      "1788/1788 [==============================] - 0s 137us/step - loss: 0.5323 - accuracy: 0.7248\n",
      "Epoch 32/100\n",
      "1788/1788 [==============================] - 0s 147us/step - loss: 0.5320 - accuracy: 0.7260\n",
      "Epoch 33/100\n",
      "1788/1788 [==============================] - 0s 147us/step - loss: 0.5316 - accuracy: 0.7237\n",
      "Epoch 34/100\n",
      "1788/1788 [==============================] - 0s 135us/step - loss: 0.5311 - accuracy: 0.7260\n",
      "Epoch 35/100\n",
      "1788/1788 [==============================] - 0s 139us/step - loss: 0.5309 - accuracy: 0.7248\n",
      "Epoch 36/100\n",
      "1788/1788 [==============================] - 0s 137us/step - loss: 0.5306 - accuracy: 0.7248\n",
      "Epoch 37/100\n",
      "1788/1788 [==============================] - 0s 146us/step - loss: 0.5305 - accuracy: 0.7243\n",
      "Epoch 38/100\n",
      "1788/1788 [==============================] - 0s 130us/step - loss: 0.5300 - accuracy: 0.7237\n",
      "Epoch 39/100\n",
      "1788/1788 [==============================] - 0s 132us/step - loss: 0.5297 - accuracy: 0.7271\n",
      "Epoch 40/100\n",
      "1788/1788 [==============================] - 0s 132us/step - loss: 0.5298 - accuracy: 0.7254\n",
      "Epoch 41/100\n",
      "1788/1788 [==============================] - 0s 168us/step - loss: 0.5295 - accuracy: 0.7254\n",
      "Epoch 42/100\n",
      "1788/1788 [==============================] - 0s 153us/step - loss: 0.5292 - accuracy: 0.7276\n",
      "Epoch 43/100\n",
      "1788/1788 [==============================] - 0s 143us/step - loss: 0.5293 - accuracy: 0.7243\n",
      "Epoch 44/100\n",
      "1788/1788 [==============================] - 0s 138us/step - loss: 0.5291 - accuracy: 0.7282\n",
      "Epoch 45/100\n",
      "1788/1788 [==============================] - 0s 137us/step - loss: 0.5288 - accuracy: 0.7282\n",
      "Epoch 46/100\n",
      "1788/1788 [==============================] - 0s 131us/step - loss: 0.5291 - accuracy: 0.7237\n",
      "Epoch 47/100\n",
      "1788/1788 [==============================] - 0s 127us/step - loss: 0.5288 - accuracy: 0.7287\n",
      "Epoch 48/100\n",
      "1788/1788 [==============================] - 0s 136us/step - loss: 0.5284 - accuracy: 0.7260\n",
      "Epoch 49/100\n",
      "1788/1788 [==============================] - 0s 136us/step - loss: 0.5289 - accuracy: 0.7276\n",
      "Epoch 50/100\n",
      "1788/1788 [==============================] - 0s 134us/step - loss: 0.5284 - accuracy: 0.7276\n",
      "Epoch 51/100\n",
      "1788/1788 [==============================] - 0s 157us/step - loss: 0.5282 - accuracy: 0.7282\n",
      "Epoch 52/100\n",
      "1788/1788 [==============================] - 0s 137us/step - loss: 0.5287 - accuracy: 0.7282\n",
      "Epoch 53/100\n",
      "1788/1788 [==============================] - 0s 135us/step - loss: 0.5285 - accuracy: 0.7315\n",
      "Epoch 54/100\n",
      "1788/1788 [==============================] - 0s 144us/step - loss: 0.5282 - accuracy: 0.7282\n",
      "Epoch 55/100\n",
      "1788/1788 [==============================] - 0s 136us/step - loss: 0.5281 - accuracy: 0.7271\n",
      "Epoch 56/100\n",
      "1788/1788 [==============================] - 0s 132us/step - loss: 0.5280 - accuracy: 0.7271\n",
      "Epoch 57/100\n",
      "1788/1788 [==============================] - 0s 134us/step - loss: 0.5280 - accuracy: 0.7287\n",
      "Epoch 58/100\n",
      "1788/1788 [==============================] - 0s 137us/step - loss: 0.5281 - accuracy: 0.7276\n",
      "Epoch 59/100\n",
      "1788/1788 [==============================] - 0s 146us/step - loss: 0.5279 - accuracy: 0.7271\n",
      "Epoch 60/100\n",
      "1788/1788 [==============================] - 0s 131us/step - loss: 0.5277 - accuracy: 0.7265\n",
      "Epoch 61/100\n",
      "1788/1788 [==============================] - 0s 134us/step - loss: 0.5276 - accuracy: 0.7265\n",
      "Epoch 62/100\n",
      "1788/1788 [==============================] - 0s 128us/step - loss: 0.5280 - accuracy: 0.7276\n",
      "Epoch 63/100\n",
      "1788/1788 [==============================] - 0s 135us/step - loss: 0.5277 - accuracy: 0.7282\n",
      "Epoch 64/100\n",
      "1788/1788 [==============================] - 0s 132us/step - loss: 0.5278 - accuracy: 0.7271\n",
      "Epoch 65/100\n",
      "1788/1788 [==============================] - 0s 135us/step - loss: 0.5276 - accuracy: 0.7276\n",
      "Epoch 66/100\n",
      "1788/1788 [==============================] - 0s 138us/step - loss: 0.5276 - accuracy: 0.7276\n",
      "Epoch 67/100\n",
      "1788/1788 [==============================] - 0s 127us/step - loss: 0.5273 - accuracy: 0.7282\n",
      "Epoch 68/100\n",
      "1788/1788 [==============================] - 0s 155us/step - loss: 0.5274 - accuracy: 0.7287\n",
      "Epoch 69/100\n",
      "1788/1788 [==============================] - 0s 150us/step - loss: 0.5274 - accuracy: 0.7293\n",
      "Epoch 70/100\n",
      "1788/1788 [==============================] - 0s 170us/step - loss: 0.5272 - accuracy: 0.7315\n",
      "Epoch 71/100\n",
      "1788/1788 [==============================] - 0s 156us/step - loss: 0.5271 - accuracy: 0.7287\n",
      "Epoch 72/100\n",
      "1788/1788 [==============================] - 0s 148us/step - loss: 0.5272 - accuracy: 0.7293\n",
      "Epoch 73/100\n",
      "1788/1788 [==============================] - 0s 172us/step - loss: 0.5270 - accuracy: 0.7287\n",
      "Epoch 74/100\n",
      "1788/1788 [==============================] - 0s 155us/step - loss: 0.5268 - accuracy: 0.7304\n",
      "Epoch 75/100\n",
      "1788/1788 [==============================] - 0s 134us/step - loss: 0.5268 - accuracy: 0.7293\n",
      "Epoch 76/100\n",
      "1788/1788 [==============================] - 0s 132us/step - loss: 0.5271 - accuracy: 0.7271\n",
      "Epoch 77/100\n",
      "1788/1788 [==============================] - 0s 152us/step - loss: 0.5268 - accuracy: 0.7293\n",
      "Epoch 78/100\n",
      "1788/1788 [==============================] - 0s 143us/step - loss: 0.5271 - accuracy: 0.7304\n",
      "Epoch 79/100\n",
      "1788/1788 [==============================] - 0s 160us/step - loss: 0.5267 - accuracy: 0.7310\n",
      "Epoch 80/100\n",
      "1788/1788 [==============================] - 0s 149us/step - loss: 0.5267 - accuracy: 0.7327\n",
      "Epoch 81/100\n",
      "1788/1788 [==============================] - 0s 140us/step - loss: 0.5269 - accuracy: 0.7310\n",
      "Epoch 82/100\n",
      "1788/1788 [==============================] - 0s 154us/step - loss: 0.5264 - accuracy: 0.7304\n",
      "Epoch 83/100\n",
      "1788/1788 [==============================] - 0s 182us/step - loss: 0.5267 - accuracy: 0.7287\n",
      "Epoch 84/100\n",
      "1788/1788 [==============================] - 0s 148us/step - loss: 0.5264 - accuracy: 0.7315\n",
      "Epoch 85/100\n",
      "1788/1788 [==============================] - 0s 157us/step - loss: 0.5266 - accuracy: 0.7310\n",
      "Epoch 86/100\n",
      "1788/1788 [==============================] - 0s 158us/step - loss: 0.5267 - accuracy: 0.7293\n",
      "Epoch 87/100\n",
      "1788/1788 [==============================] - 0s 177us/step - loss: 0.5265 - accuracy: 0.7287\n",
      "Epoch 88/100\n",
      "1788/1788 [==============================] - 0s 178us/step - loss: 0.5264 - accuracy: 0.7321\n",
      "Epoch 89/100\n",
      "1788/1788 [==============================] - 0s 151us/step - loss: 0.5267 - accuracy: 0.7299\n",
      "Epoch 90/100\n",
      "1788/1788 [==============================] - 0s 168us/step - loss: 0.5265 - accuracy: 0.7299\n",
      "Epoch 91/100\n",
      "1788/1788 [==============================] - 0s 162us/step - loss: 0.5266 - accuracy: 0.7315\n",
      "Epoch 92/100\n",
      "1788/1788 [==============================] - 0s 149us/step - loss: 0.5266 - accuracy: 0.7293\n",
      "Epoch 93/100\n",
      "1788/1788 [==============================] - 0s 161us/step - loss: 0.5263 - accuracy: 0.7287\n",
      "Epoch 94/100\n",
      "1788/1788 [==============================] - 0s 159us/step - loss: 0.5266 - accuracy: 0.7282\n",
      "Epoch 95/100\n",
      "1788/1788 [==============================] - 0s 140us/step - loss: 0.5262 - accuracy: 0.7293\n",
      "Epoch 96/100\n",
      "1788/1788 [==============================] - 0s 157us/step - loss: 0.5263 - accuracy: 0.7260\n",
      "Epoch 97/100\n",
      "1788/1788 [==============================] - 0s 127us/step - loss: 0.5264 - accuracy: 0.7265\n",
      "Epoch 98/100\n",
      "1788/1788 [==============================] - 0s 135us/step - loss: 0.5262 - accuracy: 0.7271\n",
      "Epoch 99/100\n",
      "1788/1788 [==============================] - 0s 149us/step - loss: 0.5262 - accuracy: 0.7299\n",
      "Epoch 100/100\n",
      "1788/1788 [==============================] - 0s 157us/step - loss: 0.5263 - accuracy: 0.7287\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x22efdb94188>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the ANN to the Training set\n",
    "cnn3.fit(X_train, y_train, batch_size = 10, nb_epoch = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred8 = cnn3.predict(X_test)\n",
    "y_pred8 = (y_pred8 > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[192  56]\n",
      " [ 66 133]]\n"
     ]
    }
   ],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm3 = confusion_matrix(y_test, y_pred8)\n",
    "print(cm3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\38095\\anaconda3\\envs\\labvika\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=4, units=2, kernel_initializer=\"uniform\")`\n",
      "  \"\"\"\n",
      "C:\\Users\\38095\\anaconda3\\envs\\labvika\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=2, kernel_initializer=\"uniform\")`\n",
      "  \n",
      "C:\\Users\\38095\\anaconda3\\envs\\labvika\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "# Initialising the ANN 4-2-2-1\n",
    "cnn4 = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "cnn4.add(Dense(output_dim = 2, init = 'uniform', activation = 'relu', input_dim = 4))\n",
    "\n",
    "# Adding the hidden layer\n",
    "cnn4.add(Dense(output_dim = 2, init = 'uniform', activation = 'relu'))\n",
    "\n",
    "# Adding the output layer\n",
    "cnn4.add(Dense(output_dim = 1, init = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "# Compiling the ANN\n",
    "cnn4.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\38095\\anaconda3\\envs\\labvika\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1788/1788 [==============================] - 0s 195us/step - loss: 0.6892 - accuracy: 0.5660\n",
      "Epoch 2/100\n",
      "1788/1788 [==============================] - 0s 137us/step - loss: 0.6529 - accuracy: 0.5660\n",
      "Epoch 3/100\n",
      "1788/1788 [==============================] - 0s 158us/step - loss: 0.6102 - accuracy: 0.5677\n",
      "Epoch 4/100\n",
      "1788/1788 [==============================] - 0s 149us/step - loss: 0.5923 - accuracy: 0.6902\n",
      "Epoch 5/100\n",
      "1788/1788 [==============================] - 0s 137us/step - loss: 0.5842 - accuracy: 0.7036\n",
      "Epoch 6/100\n",
      "1788/1788 [==============================] - 0s 150us/step - loss: 0.5774 - accuracy: 0.7103\n",
      "Epoch 7/100\n",
      "1788/1788 [==============================] - 0s 146us/step - loss: 0.5717 - accuracy: 0.7153\n",
      "Epoch 8/100\n",
      "1788/1788 [==============================] - 0s 163us/step - loss: 0.5663 - accuracy: 0.7181\n",
      "Epoch 9/100\n",
      "1788/1788 [==============================] - 0s 147us/step - loss: 0.5619 - accuracy: 0.7209\n",
      "Epoch 10/100\n",
      "1788/1788 [==============================] - 0s 151us/step - loss: 0.5577 - accuracy: 0.7248\n",
      "Epoch 11/100\n",
      "1788/1788 [==============================] - 0s 145us/step - loss: 0.5541 - accuracy: 0.7271\n",
      "Epoch 12/100\n",
      "1788/1788 [==============================] - 0s 154us/step - loss: 0.5512 - accuracy: 0.7287\n",
      "Epoch 13/100\n",
      "1788/1788 [==============================] - 0s 177us/step - loss: 0.5486 - accuracy: 0.7299\n",
      "Epoch 14/100\n",
      "1788/1788 [==============================] - 0s 189us/step - loss: 0.5458 - accuracy: 0.7327\n",
      "Epoch 15/100\n",
      "1788/1788 [==============================] - 0s 168us/step - loss: 0.5438 - accuracy: 0.7293\n",
      "Epoch 16/100\n",
      "1788/1788 [==============================] - 0s 164us/step - loss: 0.5421 - accuracy: 0.7327\n",
      "Epoch 17/100\n",
      "1788/1788 [==============================] - 0s 161us/step - loss: 0.5402 - accuracy: 0.7304\n",
      "Epoch 18/100\n",
      "1788/1788 [==============================] - 0s 181us/step - loss: 0.5388 - accuracy: 0.7276\n",
      "Epoch 19/100\n",
      "1788/1788 [==============================] - 0s 169us/step - loss: 0.5373 - accuracy: 0.7299\n",
      "Epoch 20/100\n",
      "1788/1788 [==============================] - 0s 183us/step - loss: 0.5364 - accuracy: 0.7293\n",
      "Epoch 21/100\n",
      "1788/1788 [==============================] - 0s 158us/step - loss: 0.5358 - accuracy: 0.7248\n",
      "Epoch 22/100\n",
      "1788/1788 [==============================] - 0s 175us/step - loss: 0.5346 - accuracy: 0.7315\n",
      "Epoch 23/100\n",
      "1788/1788 [==============================] - 0s 167us/step - loss: 0.5342 - accuracy: 0.7232\n",
      "Epoch 24/100\n",
      "1788/1788 [==============================] - 0s 177us/step - loss: 0.5334 - accuracy: 0.7287\n",
      "Epoch 25/100\n",
      "1788/1788 [==============================] - 0s 176us/step - loss: 0.5330 - accuracy: 0.7327\n",
      "Epoch 26/100\n",
      "1788/1788 [==============================] - 0s 179us/step - loss: 0.5325 - accuracy: 0.7271\n",
      "Epoch 27/100\n",
      "1788/1788 [==============================] - 0s 186us/step - loss: 0.5323 - accuracy: 0.7276\n",
      "Epoch 28/100\n",
      "1788/1788 [==============================] - 0s 226us/step - loss: 0.5318 - accuracy: 0.7271\n",
      "Epoch 29/100\n",
      "1788/1788 [==============================] - 0s 182us/step - loss: 0.5313 - accuracy: 0.7260\n",
      "Epoch 30/100\n",
      "1788/1788 [==============================] - 0s 180us/step - loss: 0.5314 - accuracy: 0.7248\n",
      "Epoch 31/100\n",
      "1788/1788 [==============================] - 0s 141us/step - loss: 0.5308 - accuracy: 0.7265\n",
      "Epoch 32/100\n",
      "1788/1788 [==============================] - 0s 148us/step - loss: 0.5306 - accuracy: 0.7265\n",
      "Epoch 33/100\n",
      "1788/1788 [==============================] - 0s 186us/step - loss: 0.5302 - accuracy: 0.7327\n",
      "Epoch 34/100\n",
      "1788/1788 [==============================] - 0s 181us/step - loss: 0.5302 - accuracy: 0.7299\n",
      "Epoch 35/100\n",
      "1788/1788 [==============================] - 0s 152us/step - loss: 0.5303 - accuracy: 0.7304\n",
      "Epoch 36/100\n",
      "1788/1788 [==============================] - 0s 165us/step - loss: 0.5301 - accuracy: 0.7310\n",
      "Epoch 37/100\n",
      "1788/1788 [==============================] - 0s 171us/step - loss: 0.5298 - accuracy: 0.7282\n",
      "Epoch 38/100\n",
      "1788/1788 [==============================] - 0s 153us/step - loss: 0.5298 - accuracy: 0.7265\n",
      "Epoch 39/100\n",
      "1788/1788 [==============================] - 0s 142us/step - loss: 0.5298 - accuracy: 0.7287\n",
      "Epoch 40/100\n",
      "1788/1788 [==============================] - 0s 155us/step - loss: 0.5293 - accuracy: 0.7271\n",
      "Epoch 41/100\n",
      "1788/1788 [==============================] - 0s 143us/step - loss: 0.5291 - accuracy: 0.7287\n",
      "Epoch 42/100\n",
      "1788/1788 [==============================] - 0s 131us/step - loss: 0.5290 - accuracy: 0.7293\n",
      "Epoch 43/100\n",
      "1788/1788 [==============================] - 0s 149us/step - loss: 0.5293 - accuracy: 0.7299\n",
      "Epoch 44/100\n",
      "1788/1788 [==============================] - 0s 151us/step - loss: 0.5285 - accuracy: 0.7287\n",
      "Epoch 45/100\n",
      "1788/1788 [==============================] - 0s 159us/step - loss: 0.5288 - accuracy: 0.7254\n",
      "Epoch 46/100\n",
      "1788/1788 [==============================] - 0s 139us/step - loss: 0.5291 - accuracy: 0.7299\n",
      "Epoch 47/100\n",
      "1788/1788 [==============================] - 0s 145us/step - loss: 0.5286 - accuracy: 0.7299\n",
      "Epoch 48/100\n",
      "1788/1788 [==============================] - 0s 132us/step - loss: 0.5281 - accuracy: 0.7260\n",
      "Epoch 49/100\n",
      "1788/1788 [==============================] - 0s 132us/step - loss: 0.5283 - accuracy: 0.7310\n",
      "Epoch 50/100\n",
      "1788/1788 [==============================] - 0s 156us/step - loss: 0.5284 - accuracy: 0.7299\n",
      "Epoch 51/100\n",
      "1788/1788 [==============================] - 0s 142us/step - loss: 0.5284 - accuracy: 0.7304\n",
      "Epoch 52/100\n",
      "1788/1788 [==============================] - 0s 142us/step - loss: 0.5281 - accuracy: 0.7265\n",
      "Epoch 53/100\n",
      "1788/1788 [==============================] - 0s 132us/step - loss: 0.5282 - accuracy: 0.7276\n",
      "Epoch 54/100\n",
      "1788/1788 [==============================] - 0s 132us/step - loss: 0.5280 - accuracy: 0.7299\n",
      "Epoch 55/100\n",
      "1788/1788 [==============================] - 0s 143us/step - loss: 0.5281 - accuracy: 0.7282\n",
      "Epoch 56/100\n",
      "1788/1788 [==============================] - 0s 139us/step - loss: 0.5282 - accuracy: 0.7287\n",
      "Epoch 57/100\n",
      "1788/1788 [==============================] - 0s 140us/step - loss: 0.5278 - accuracy: 0.7293\n",
      "Epoch 58/100\n",
      "1788/1788 [==============================] - 0s 155us/step - loss: 0.5277 - accuracy: 0.7299\n",
      "Epoch 59/100\n",
      "1788/1788 [==============================] - 0s 140us/step - loss: 0.5277 - accuracy: 0.7310\n",
      "Epoch 60/100\n",
      "1788/1788 [==============================] - 0s 145us/step - loss: 0.5276 - accuracy: 0.7287\n",
      "Epoch 61/100\n",
      "1788/1788 [==============================] - 0s 145us/step - loss: 0.5276 - accuracy: 0.7276\n",
      "Epoch 62/100\n",
      "1788/1788 [==============================] - 0s 138us/step - loss: 0.5275 - accuracy: 0.7304\n",
      "Epoch 63/100\n",
      "1788/1788 [==============================] - 0s 139us/step - loss: 0.5272 - accuracy: 0.7287\n",
      "Epoch 64/100\n",
      "1788/1788 [==============================] - 0s 129us/step - loss: 0.5276 - accuracy: 0.7276\n",
      "Epoch 65/100\n",
      "1788/1788 [==============================] - 0s 135us/step - loss: 0.5272 - accuracy: 0.7293\n",
      "Epoch 66/100\n",
      "1788/1788 [==============================] - 0s 133us/step - loss: 0.5272 - accuracy: 0.7287\n",
      "Epoch 67/100\n",
      "1788/1788 [==============================] - 0s 137us/step - loss: 0.5273 - accuracy: 0.7293\n",
      "Epoch 68/100\n",
      "1788/1788 [==============================] - 0s 143us/step - loss: 0.5273 - accuracy: 0.7332\n",
      "Epoch 69/100\n",
      "1788/1788 [==============================] - 0s 131us/step - loss: 0.5272 - accuracy: 0.7299\n",
      "Epoch 70/100\n",
      "1788/1788 [==============================] - 0s 145us/step - loss: 0.5273 - accuracy: 0.7299\n",
      "Epoch 71/100\n",
      "1788/1788 [==============================] - 0s 133us/step - loss: 0.5271 - accuracy: 0.7304\n",
      "Epoch 72/100\n",
      "1788/1788 [==============================] - 0s 132us/step - loss: 0.5272 - accuracy: 0.7293\n",
      "Epoch 73/100\n",
      "1788/1788 [==============================] - 0s 136us/step - loss: 0.5269 - accuracy: 0.7332\n",
      "Epoch 74/100\n",
      "1788/1788 [==============================] - 0s 131us/step - loss: 0.5269 - accuracy: 0.7321\n",
      "Epoch 75/100\n",
      "1788/1788 [==============================] - 0s 135us/step - loss: 0.5270 - accuracy: 0.7304\n",
      "Epoch 76/100\n",
      "1788/1788 [==============================] - 0s 140us/step - loss: 0.5268 - accuracy: 0.7299\n",
      "Epoch 77/100\n",
      "1788/1788 [==============================] - 0s 133us/step - loss: 0.5270 - accuracy: 0.7310\n",
      "Epoch 78/100\n",
      "1788/1788 [==============================] - 0s 139us/step - loss: 0.5268 - accuracy: 0.7304\n",
      "Epoch 79/100\n",
      "1788/1788 [==============================] - 0s 134us/step - loss: 0.5267 - accuracy: 0.7310\n",
      "Epoch 80/100\n",
      "1788/1788 [==============================] - 0s 126us/step - loss: 0.5268 - accuracy: 0.7287\n",
      "Epoch 81/100\n",
      "1788/1788 [==============================] - 0s 136us/step - loss: 0.5271 - accuracy: 0.7293\n",
      "Epoch 82/100\n",
      "1788/1788 [==============================] - 0s 128us/step - loss: 0.5268 - accuracy: 0.7315\n",
      "Epoch 83/100\n",
      "1788/1788 [==============================] - 0s 133us/step - loss: 0.5267 - accuracy: 0.7304\n",
      "Epoch 84/100\n",
      "1788/1788 [==============================] - 0s 138us/step - loss: 0.5267 - accuracy: 0.7310\n",
      "Epoch 85/100\n",
      "1788/1788 [==============================] - 0s 135us/step - loss: 0.5267 - accuracy: 0.7315\n",
      "Epoch 86/100\n",
      "1788/1788 [==============================] - 0s 135us/step - loss: 0.5270 - accuracy: 0.7287\n",
      "Epoch 87/100\n",
      "1788/1788 [==============================] - 0s 132us/step - loss: 0.5264 - accuracy: 0.7315\n",
      "Epoch 88/100\n",
      "1788/1788 [==============================] - 0s 129us/step - loss: 0.5263 - accuracy: 0.7310\n",
      "Epoch 89/100\n",
      "1788/1788 [==============================] - 0s 126us/step - loss: 0.5265 - accuracy: 0.7287\n",
      "Epoch 90/100\n",
      "1788/1788 [==============================] - 0s 148us/step - loss: 0.5267 - accuracy: 0.7304\n",
      "Epoch 91/100\n",
      "1788/1788 [==============================] - 0s 148us/step - loss: 0.5266 - accuracy: 0.7304\n",
      "Epoch 92/100\n",
      "1788/1788 [==============================] - 0s 145us/step - loss: 0.5265 - accuracy: 0.7310\n",
      "Epoch 93/100\n",
      "1788/1788 [==============================] - 0s 134us/step - loss: 0.5265 - accuracy: 0.7282\n",
      "Epoch 94/100\n",
      "1788/1788 [==============================] - 0s 128us/step - loss: 0.5263 - accuracy: 0.7304\n",
      "Epoch 95/100\n",
      "1788/1788 [==============================] - 0s 134us/step - loss: 0.5267 - accuracy: 0.7304\n",
      "Epoch 96/100\n",
      "1788/1788 [==============================] - 0s 134us/step - loss: 0.5263 - accuracy: 0.7304\n",
      "Epoch 97/100\n",
      "1788/1788 [==============================] - 0s 145us/step - loss: 0.5265 - accuracy: 0.7293\n",
      "Epoch 98/100\n",
      "1788/1788 [==============================] - 0s 146us/step - loss: 0.5265 - accuracy: 0.7321\n",
      "Epoch 99/100\n",
      "1788/1788 [==============================] - 0s 140us/step - loss: 0.5265 - accuracy: 0.7293\n",
      "Epoch 100/100\n",
      "1788/1788 [==============================] - 0s 136us/step - loss: 0.5262 - accuracy: 0.7304\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x22efdec2b48>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the ANN to the Training set\n",
    "cnn4.fit(X_train, y_train, batch_size = 10, nb_epoch = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred9 = cnn4.predict(X_test)\n",
    "y_pred9 = (y_pred9 > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[189  59]\n",
      " [ 66 133]]\n"
     ]
    }
   ],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm4 = confusion_matrix(y_test, y_pred9)\n",
    "print(cm4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\38095\\anaconda3\\envs\\labvika\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=4, units=4, kernel_initializer=\"uniform\")`\n",
      "  \"\"\"\n",
      "C:\\Users\\38095\\anaconda3\\envs\\labvika\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Initialising the ANN 4-4-1\n",
    "cnn5 = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "cnn5.add(Dense(output_dim = 4, init = 'uniform', activation = 'relu', input_dim = 4))\n",
    "\n",
    "# Adding the output layer\n",
    "cnn5.add(Dense(output_dim = 1, init = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "# Compiling the ANN\n",
    "cnn5.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\38095\\anaconda3\\envs\\labvika\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1788/1788 [==============================] - 0s 176us/step - loss: 0.6856 - accuracy: 0.5839\n",
      "Epoch 2/100\n",
      "1788/1788 [==============================] - 0s 130us/step - loss: 0.6407 - accuracy: 0.6879\n",
      "Epoch 3/100\n",
      "1788/1788 [==============================] - 0s 128us/step - loss: 0.5932 - accuracy: 0.6963\n",
      "Epoch 4/100\n",
      "1788/1788 [==============================] - 0s 130us/step - loss: 0.5737 - accuracy: 0.6969\n",
      "Epoch 5/100\n",
      "1788/1788 [==============================] - 0s 148us/step - loss: 0.5666 - accuracy: 0.7075\n",
      "Epoch 6/100\n",
      "1788/1788 [==============================] - 0s 128us/step - loss: 0.5627 - accuracy: 0.7086\n",
      "Epoch 7/100\n",
      "1788/1788 [==============================] - 0s 130us/step - loss: 0.5598 - accuracy: 0.7114\n",
      "Epoch 8/100\n",
      "1788/1788 [==============================] - 0s 126us/step - loss: 0.5574 - accuracy: 0.7114\n",
      "Epoch 9/100\n",
      "1788/1788 [==============================] - 0s 139us/step - loss: 0.5542 - accuracy: 0.7086\n",
      "Epoch 10/100\n",
      "1788/1788 [==============================] - 0s 132us/step - loss: 0.5515 - accuracy: 0.7153\n",
      "Epoch 11/100\n",
      "1788/1788 [==============================] - 0s 132us/step - loss: 0.5481 - accuracy: 0.7142\n",
      "Epoch 12/100\n",
      "1788/1788 [==============================] - 0s 126us/step - loss: 0.5455 - accuracy: 0.7159\n",
      "Epoch 13/100\n",
      "1788/1788 [==============================] - 0s 123us/step - loss: 0.5430 - accuracy: 0.7181\n",
      "Epoch 14/100\n",
      "1788/1788 [==============================] - 0s 128us/step - loss: 0.5406 - accuracy: 0.7181\n",
      "Epoch 15/100\n",
      "1788/1788 [==============================] - 0s 131us/step - loss: 0.5389 - accuracy: 0.7220\n",
      "Epoch 16/100\n",
      "1788/1788 [==============================] - 0s 128us/step - loss: 0.5370 - accuracy: 0.7271\n",
      "Epoch 17/100\n",
      "1788/1788 [==============================] - 0s 135us/step - loss: 0.5356 - accuracy: 0.7248\n",
      "Epoch 18/100\n",
      "1788/1788 [==============================] - 0s 129us/step - loss: 0.5342 - accuracy: 0.7282\n",
      "Epoch 19/100\n",
      "1788/1788 [==============================] - 0s 126us/step - loss: 0.5328 - accuracy: 0.7271\n",
      "Epoch 20/100\n",
      "1788/1788 [==============================] - 0s 121us/step - loss: 0.5317 - accuracy: 0.7276\n",
      "Epoch 21/100\n",
      "1788/1788 [==============================] - 0s 127us/step - loss: 0.5308 - accuracy: 0.7265\n",
      "Epoch 22/100\n",
      "1788/1788 [==============================] - 0s 134us/step - loss: 0.5301 - accuracy: 0.7260\n",
      "Epoch 23/100\n",
      "1788/1788 [==============================] - 0s 149us/step - loss: 0.5293 - accuracy: 0.7315\n",
      "Epoch 24/100\n",
      "1788/1788 [==============================] - 0s 144us/step - loss: 0.5287 - accuracy: 0.7282\n",
      "Epoch 25/100\n",
      "1788/1788 [==============================] - 0s 134us/step - loss: 0.5279 - accuracy: 0.7293\n",
      "Epoch 26/100\n",
      "1788/1788 [==============================] - 0s 145us/step - loss: 0.5272 - accuracy: 0.7271\n",
      "Epoch 27/100\n",
      "1788/1788 [==============================] - 0s 160us/step - loss: 0.5267 - accuracy: 0.7276\n",
      "Epoch 28/100\n",
      "1788/1788 [==============================] - 0s 164us/step - loss: 0.5261 - accuracy: 0.7321\n",
      "Epoch 29/100\n",
      "1788/1788 [==============================] - 0s 154us/step - loss: 0.5257 - accuracy: 0.7260\n",
      "Epoch 30/100\n",
      "1788/1788 [==============================] - 0s 159us/step - loss: 0.5253 - accuracy: 0.7343\n",
      "Epoch 31/100\n",
      "1788/1788 [==============================] - 0s 171us/step - loss: 0.5250 - accuracy: 0.7293\n",
      "Epoch 32/100\n",
      "1788/1788 [==============================] - 0s 150us/step - loss: 0.5250 - accuracy: 0.7260\n",
      "Epoch 33/100\n",
      "1788/1788 [==============================] - 0s 166us/step - loss: 0.5246 - accuracy: 0.7299\n",
      "Epoch 34/100\n",
      "1788/1788 [==============================] - 0s 177us/step - loss: 0.5245 - accuracy: 0.7293\n",
      "Epoch 35/100\n",
      "1788/1788 [==============================] - 0s 159us/step - loss: 0.5239 - accuracy: 0.7276\n",
      "Epoch 36/100\n",
      "1788/1788 [==============================] - 0s 176us/step - loss: 0.5238 - accuracy: 0.7232\n",
      "Epoch 37/100\n",
      "1788/1788 [==============================] - 0s 162us/step - loss: 0.5235 - accuracy: 0.7276\n",
      "Epoch 38/100\n",
      "1788/1788 [==============================] - 0s 153us/step - loss: 0.5233 - accuracy: 0.7282\n",
      "Epoch 39/100\n",
      "1788/1788 [==============================] - 0s 165us/step - loss: 0.5235 - accuracy: 0.7237\n",
      "Epoch 40/100\n",
      "1788/1788 [==============================] - 0s 162us/step - loss: 0.5231 - accuracy: 0.7243\n",
      "Epoch 41/100\n",
      "1788/1788 [==============================] - 0s 131us/step - loss: 0.5230 - accuracy: 0.7243\n",
      "Epoch 42/100\n",
      "1788/1788 [==============================] - 0s 135us/step - loss: 0.5230 - accuracy: 0.7254\n",
      "Epoch 43/100\n",
      "1788/1788 [==============================] - 0s 140us/step - loss: 0.5227 - accuracy: 0.7248\n",
      "Epoch 44/100\n",
      "1788/1788 [==============================] - 0s 133us/step - loss: 0.5226 - accuracy: 0.7254\n",
      "Epoch 45/100\n",
      "1788/1788 [==============================] - 0s 128us/step - loss: 0.5226 - accuracy: 0.7254\n",
      "Epoch 46/100\n",
      "1788/1788 [==============================] - 0s 134us/step - loss: 0.5224 - accuracy: 0.7276\n",
      "Epoch 47/100\n",
      "1788/1788 [==============================] - 0s 154us/step - loss: 0.5223 - accuracy: 0.7254\n",
      "Epoch 48/100\n",
      "1788/1788 [==============================] - 0s 148us/step - loss: 0.5224 - accuracy: 0.7254\n",
      "Epoch 49/100\n",
      "1788/1788 [==============================] - 0s 150us/step - loss: 0.5223 - accuracy: 0.7260\n",
      "Epoch 50/100\n",
      "1788/1788 [==============================] - 0s 172us/step - loss: 0.5222 - accuracy: 0.7248\n",
      "Epoch 51/100\n",
      "1788/1788 [==============================] - 0s 196us/step - loss: 0.5223 - accuracy: 0.7254\n",
      "Epoch 52/100\n",
      "1788/1788 [==============================] - 0s 140us/step - loss: 0.5222 - accuracy: 0.7248\n",
      "Epoch 53/100\n",
      "1788/1788 [==============================] - 0s 183us/step - loss: 0.5221 - accuracy: 0.7243\n",
      "Epoch 54/100\n",
      "1788/1788 [==============================] - 0s 156us/step - loss: 0.5221 - accuracy: 0.7243\n",
      "Epoch 55/100\n",
      "1788/1788 [==============================] - 0s 181us/step - loss: 0.5219 - accuracy: 0.7260\n",
      "Epoch 56/100\n",
      "1788/1788 [==============================] - 0s 159us/step - loss: 0.5218 - accuracy: 0.7271\n",
      "Epoch 57/100\n",
      "1788/1788 [==============================] - 0s 175us/step - loss: 0.5220 - accuracy: 0.7293\n",
      "Epoch 58/100\n",
      "1788/1788 [==============================] - 0s 149us/step - loss: 0.5220 - accuracy: 0.7260\n",
      "Epoch 59/100\n",
      "1788/1788 [==============================] - 0s 152us/step - loss: 0.5218 - accuracy: 0.7254\n",
      "Epoch 60/100\n",
      "1788/1788 [==============================] - 0s 138us/step - loss: 0.5218 - accuracy: 0.7293\n",
      "Epoch 61/100\n",
      "1788/1788 [==============================] - 0s 162us/step - loss: 0.5217 - accuracy: 0.7299\n",
      "Epoch 62/100\n",
      "1788/1788 [==============================] - 0s 149us/step - loss: 0.5214 - accuracy: 0.7248\n",
      "Epoch 63/100\n",
      "1788/1788 [==============================] - 0s 125us/step - loss: 0.5217 - accuracy: 0.7260\n",
      "Epoch 64/100\n",
      "1788/1788 [==============================] - 0s 133us/step - loss: 0.5213 - accuracy: 0.7276\n",
      "Epoch 65/100\n",
      "1788/1788 [==============================] - 0s 135us/step - loss: 0.5214 - accuracy: 0.7260\n",
      "Epoch 66/100\n",
      "1788/1788 [==============================] - 0s 132us/step - loss: 0.5214 - accuracy: 0.7282\n",
      "Epoch 67/100\n",
      "1788/1788 [==============================] - 0s 122us/step - loss: 0.5217 - accuracy: 0.7271\n",
      "Epoch 68/100\n",
      "1788/1788 [==============================] - 0s 160us/step - loss: 0.5211 - accuracy: 0.7276\n",
      "Epoch 69/100\n",
      "1788/1788 [==============================] - 0s 178us/step - loss: 0.5212 - accuracy: 0.7254\n",
      "Epoch 70/100\n",
      "1788/1788 [==============================] - 0s 162us/step - loss: 0.5214 - accuracy: 0.7254\n",
      "Epoch 71/100\n",
      "1788/1788 [==============================] - 0s 178us/step - loss: 0.5214 - accuracy: 0.7243\n",
      "Epoch 72/100\n",
      "1788/1788 [==============================] - 0s 126us/step - loss: 0.5211 - accuracy: 0.7299\n",
      "Epoch 73/100\n",
      "1788/1788 [==============================] - 0s 187us/step - loss: 0.5210 - accuracy: 0.7299\n",
      "Epoch 74/100\n",
      "1788/1788 [==============================] - 0s 158us/step - loss: 0.5211 - accuracy: 0.7287\n",
      "Epoch 75/100\n",
      "1788/1788 [==============================] - 0s 186us/step - loss: 0.5212 - accuracy: 0.7254\n",
      "Epoch 76/100\n",
      "1788/1788 [==============================] - 0s 162us/step - loss: 0.5211 - accuracy: 0.7321\n",
      "Epoch 77/100\n",
      "1788/1788 [==============================] - 0s 175us/step - loss: 0.5210 - accuracy: 0.7282\n",
      "Epoch 78/100\n",
      "1788/1788 [==============================] - 0s 186us/step - loss: 0.5209 - accuracy: 0.7293\n",
      "Epoch 79/100\n",
      "1788/1788 [==============================] - 0s 159us/step - loss: 0.5210 - accuracy: 0.7260\n",
      "Epoch 80/100\n",
      "1788/1788 [==============================] - 0s 174us/step - loss: 0.5210 - accuracy: 0.7287\n",
      "Epoch 81/100\n",
      "1788/1788 [==============================] - 0s 139us/step - loss: 0.5208 - accuracy: 0.7299\n",
      "Epoch 82/100\n",
      "1788/1788 [==============================] - 0s 138us/step - loss: 0.5209 - accuracy: 0.7299\n",
      "Epoch 83/100\n",
      "1788/1788 [==============================] - 0s 130us/step - loss: 0.5211 - accuracy: 0.7310\n",
      "Epoch 84/100\n",
      "1788/1788 [==============================] - 0s 130us/step - loss: 0.5209 - accuracy: 0.7260\n",
      "Epoch 85/100\n",
      "1788/1788 [==============================] - 0s 134us/step - loss: 0.5206 - accuracy: 0.7276\n",
      "Epoch 86/100\n",
      "1788/1788 [==============================] - 0s 124us/step - loss: 0.5207 - accuracy: 0.7299\n",
      "Epoch 87/100\n",
      "1788/1788 [==============================] - 0s 148us/step - loss: 0.5208 - accuracy: 0.7299\n",
      "Epoch 88/100\n",
      "1788/1788 [==============================] - 0s 141us/step - loss: 0.5208 - accuracy: 0.7327\n",
      "Epoch 89/100\n",
      "1788/1788 [==============================] - 0s 126us/step - loss: 0.5207 - accuracy: 0.7299\n",
      "Epoch 90/100\n",
      "1788/1788 [==============================] - 0s 126us/step - loss: 0.5206 - accuracy: 0.7315\n",
      "Epoch 91/100\n",
      "1788/1788 [==============================] - 0s 149us/step - loss: 0.5208 - accuracy: 0.7315\n",
      "Epoch 92/100\n",
      "1788/1788 [==============================] - 0s 196us/step - loss: 0.5207 - accuracy: 0.7287\n",
      "Epoch 93/100\n",
      "1788/1788 [==============================] - 0s 188us/step - loss: 0.5206 - accuracy: 0.7343\n",
      "Epoch 94/100\n",
      "1788/1788 [==============================] - 0s 177us/step - loss: 0.5205 - accuracy: 0.7293\n",
      "Epoch 95/100\n",
      "1788/1788 [==============================] - 0s 158us/step - loss: 0.5205 - accuracy: 0.7304\n",
      "Epoch 96/100\n",
      "1788/1788 [==============================] - 0s 154us/step - loss: 0.5208 - accuracy: 0.7321\n",
      "Epoch 97/100\n",
      "1788/1788 [==============================] - 0s 158us/step - loss: 0.5208 - accuracy: 0.7327\n",
      "Epoch 98/100\n",
      "1788/1788 [==============================] - 0s 159us/step - loss: 0.5206 - accuracy: 0.7315\n",
      "Epoch 99/100\n",
      "1788/1788 [==============================] - 0s 145us/step - loss: 0.5204 - accuracy: 0.7276\n",
      "Epoch 100/100\n",
      "1788/1788 [==============================] - 0s 139us/step - loss: 0.5206 - accuracy: 0.7321\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x22eff37ff08>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the ANN to the Training set\n",
    "cnn5.fit(X_train, y_train, batch_size = 10, nb_epoch = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred10 = cnn5.predict(X_test)\n",
    "y_pred10 = (y_pred10 > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[191  57]\n",
      " [ 68 131]]\n"
     ]
    }
   ],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm5 = confusion_matrix(y_test, y_pred10)\n",
    "print(cm5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "За кількістю помилково розпізнаних данних дана модель не виявилась найкращою. Кількість помилково розпізнаних даних є більше, ніж у моделі KNN.\n",
    "Якщо ж порівняти між собою розглянуті архітектури нейронних мереж за кількістю помилково розпізнаних даних, то найкращою виявилась модель 4-3-2-1. Вона має лише 122 помилково розпізнаних спостереження. Найгіршою є 4-2-2-1. Вона має 127 неправильно визначених результата.\n",
    "Найкращою з усіх розглянутих моделей виявилась модель KNN. Саме її варто застосовувати при визначенні того чи буде користувач надавати більше переваги вину чи ні."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
